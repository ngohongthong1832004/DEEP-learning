{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9c72a9",
   "metadata": {
    "papermill": {
     "duration": 0.012258,
     "end_time": "2025-09-09T07:46:18.101152",
     "exception": false,
     "start_time": "2025-09-09T07:46:18.088894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56227bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:18.124679Z",
     "iopub.status.busy": "2025-09-09T07:46:18.124415Z",
     "iopub.status.idle": "2025-09-09T07:46:27.583152Z",
     "shell.execute_reply": "2025-09-09T07:46:27.582561Z"
    },
    "papermill": {
     "duration": 9.472664,
     "end_time": "2025-09-09T07:46:27.584616",
     "exception": false,
     "start_time": "2025-09-09T07:46:18.111952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.amp import GradScaler, autocast\n",
    "    _NEW_AMP = True\n",
    "except Exception:\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    _NEW_AMP = False\n",
    "\n",
    "from torchvision.models import (\n",
    "    resnet18, ResNet18_Weights,\n",
    "    resnet50, ResNet50_Weights,\n",
    "    efficientnet_b0, EfficientNet_B0_Weights,\n",
    "    mobilenet_v2, MobileNet_V2_Weights,\n",
    ")\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8029a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:27.607403Z",
     "iopub.status.busy": "2025-09-09T07:46:27.606829Z",
     "iopub.status.idle": "2025-09-09T07:46:30.692664Z",
     "shell.execute_reply": "2025-09-09T07:46:30.692059Z"
    },
    "papermill": {
     "duration": 3.098259,
     "end_time": "2025-09-09T07:46:30.694067",
     "exception": false,
     "start_time": "2025-09-09T07:46:27.595808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, re, shutil, random, pathlib, cv2, torch, gc, time, math \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "from contextlib import nullcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb8d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:30.718579Z",
     "iopub.status.busy": "2025-09-09T07:46:30.718047Z",
     "iopub.status.idle": "2025-09-09T07:46:34.690122Z",
     "shell.execute_reply": "2025-09-09T07:46:34.689135Z"
    },
    "papermill": {
     "duration": 3.984433,
     "end_time": "2025-09-09T07:46:34.691527",
     "exception": false,
     "start_time": "2025-09-09T07:46:30.707094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow[and-cuda]\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f8031",
   "metadata": {
    "papermill": {
     "duration": 0.010355,
     "end_time": "2025-09-09T07:46:34.712774",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.702419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357776b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:34.735820Z",
     "iopub.status.busy": "2025-09-09T07:46:34.735543Z",
     "iopub.status.idle": "2025-09-09T07:46:34.741721Z",
     "shell.execute_reply": "2025-09-09T07:46:34.741171Z"
    },
    "papermill": {
     "duration": 0.019713,
     "end_time": "2025-09-09T07:46:34.742832",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.723119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0: brown spot (Đốm nâu)\n",
    "# 01: leaf blast (Đạo ôn)\n",
    "# 02: leaf blight (Cháy lá)\n",
    "# 03: normal (bình thường)\n",
    "\n",
    "LABELS = {\n",
    "    0: {\n",
    "        \"name\": \"brown_spot\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/rice-disease-dataset/Rice_Leaf_AUG/Brown Spot\",\n",
    "            \"/kaggle/input/rice-leaf-disease-image/Brownspot\",\n",
    "            \"/kaggle/input/rice-leaf-diseases/rice_leaf_diseases/Brown spot\",\n",
    "            \"/kaggle/input/rice-leafs-disease-dataset/RiceLeafsDisease/train/brown_spot\",\n",
    "            \"/kaggle/input/rice-leaf-images/rice_images/_BrownSpot\",\n",
    "            \"/kaggle/input/rice-diseases-image-dataset/RiceDiseaseDataset/train/BrownSpot\",\n",
    "        ]\n",
    "    },\n",
    "    1: {\n",
    "        \"name\": \"leaf_blast\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/rice-disease-dataset/Rice_Leaf_AUG/Leaf Blast\",\n",
    "            \"/kaggle/input/rice-leafs-disease-dataset/RiceLeafsDisease/train/leaf_blast\",\n",
    "            \"/kaggle/input/rice-leaf-images/rice_images/_LeafBlast\",\n",
    "            \"/kaggle/input/rice-diseases-image-dataset/RiceDiseaseDataset/train/LeafBlast\",\n",
    "\n",
    "        ]\n",
    "    },\n",
    "    2: {\n",
    "        \"name\": \"leaf_blight\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/rice-disease-dataset/Rice_Leaf_AUG/Sheath Blight\",\n",
    "            \"/kaggle/input/rice-leaf-diseases/rice_leaf_diseases/Bacterial leaf blight\",\n",
    "            \"/kaggle/input/rice-leaf-disease-image/Bacterialblight\",\n",
    "            \"/kaggle/input/rice-leafs-disease-dataset/RiceLeafsDisease/train/bacterial_leaf_blight\",\n",
    "        ]\n",
    "    },\n",
    "    3: {\n",
    "        \"name\": \"healthy\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/rice-disease-dataset/Rice_Leaf_AUG/Healthy Rice Leaf\",\n",
    "            \"/kaggle/input/rice-leafs-disease-dataset/RiceLeafsDisease/train/healthy\",\n",
    "            \"/kaggle/input/rice-leaf-images/rice_images/_Healthy\",\n",
    "            \"/kaggle/input/rice-diseases-image-dataset/RiceDiseaseDataset/train/Healthy\",\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASET_SOURCES = {\n",
    "    \"rice-disease-dataset\": \"dataset_1\",\n",
    "    \"rice-leaf-disease-image\": \"dataset_2\",\n",
    "    \"rice-leaf-diseases\": \"dataset_3\", \n",
    "    \"rice-leafs-disease-dataset\": \"dataset_4\",\n",
    "    \"rice-leaf-images\": \"dataset_5\",\n",
    "    \"rice-diseases-image-dataset\": \"dataset_6\"\n",
    "}\n",
    "\n",
    "LABELS_TEST = {\n",
    "    0: {\n",
    "        \"name\": \"brown_spot\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/mendeley-rice-disease-dataset/Augmented Images/Brown Spot\"\n",
    "        ]\n",
    "    },\n",
    "    1: {\n",
    "        \"name\": \"leaf_blast\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/mendeley-rice-disease-dataset/Augmented Images/Leaf Blast\",\n",
    "        ]\n",
    "    },\n",
    "    2: {\n",
    "        \"name\": \"leaf_blight\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/mendeley-rice-disease-dataset/Augmented Images/Bacterial Leaf Blight\",\n",
    "        ]\n",
    "    },\n",
    "    3: {\n",
    "        \"name\": \"healthy\",\n",
    "        \"match_substrings\": [\n",
    "            \"/kaggle/input/mendeley-rice-disease-dataset/Augmented Images/Healthy Rice Leaf\",\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASET_SOURCES_TEST = {\n",
    "    \"mendeley-rice-disease-dataset\": \"dataset_7\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95547bd4",
   "metadata": {
    "papermill": {
     "duration": 0.010407,
     "end_time": "2025-09-09T07:46:34.763605",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.753198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Thu thập ảnh chỉ từ các đường dẫn khớp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2eae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:34.785912Z",
     "iopub.status.busy": "2025-09-09T07:46:34.785636Z",
     "iopub.status.idle": "2025-09-09T07:46:34.790344Z",
     "shell.execute_reply": "2025-09-09T07:46:34.789785Z"
    },
    "papermill": {
     "duration": 0.017329,
     "end_time": "2025-09-09T07:46:34.791461",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.774132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ALL_SUBS = []\n",
    "for lid, info in LABELS.items():\n",
    "    # print(lid, info)\n",
    "    # print(info[\"match_substrings\"])\n",
    "    for s in info[\"match_substrings\"]:\n",
    "        for src, src_id in DATASET_SOURCES.items():\n",
    "            if src in s:\n",
    "                ALL_SUBS.append((lid, info[\"name\"], s, src_id))\n",
    "\n",
    "ALL_SUBS_TEST = []\n",
    "for lid, info in LABELS_TEST.items():\n",
    "    for s in info[\"match_substrings\"]:\n",
    "        for src, src_id in DATASET_SOURCES_TEST.items():\n",
    "            if src in s:\n",
    "                ALL_SUBS_TEST.append((lid, info[\"name\"], s, src_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d933e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:34.814262Z",
     "iopub.status.busy": "2025-09-09T07:46:34.814027Z",
     "iopub.status.idle": "2025-09-09T07:46:34.817852Z",
     "shell.execute_reply": "2025-09-09T07:46:34.816988Z"
    },
    "papermill": {
     "duration": 0.016941,
     "end_time": "2025-09-09T07:46:34.819002",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.802061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in ALL_SUBS:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b0c76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:34.840755Z",
     "iopub.status.busy": "2025-09-09T07:46:34.840526Z",
     "iopub.status.idle": "2025-09-09T07:46:34.844352Z",
     "shell.execute_reply": "2025-09-09T07:46:34.843641Z"
    },
    "papermill": {
     "duration": 0.015941,
     "end_time": "2025-09-09T07:46:34.845426",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.829485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in ALL_SUBS_TEST:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093a3ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:34.866890Z",
     "iopub.status.busy": "2025-09-09T07:46:34.866676Z",
     "iopub.status.idle": "2025-09-09T07:46:34.870710Z",
     "shell.execute_reply": "2025-09-09T07:46:34.870192Z"
    },
    "papermill": {
     "duration": 0.015801,
     "end_time": "2025-09-09T07:46:34.871655",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.855854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_class(image_dir):\n",
    "    print(image_dir)\n",
    "    image_dirs = os.listdir(image_dir)\n",
    "    images_path = []\n",
    "    for file in image_dirs:\n",
    "        if file.endswith('.jpg') or file.endswith('.JPG'):\n",
    "            image_path = os.path.join(image_dir, file)\n",
    "            images_path.append(image_path)\n",
    "    print(len(image_dirs))\n",
    "    return images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171993b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:34.942435Z",
     "iopub.status.busy": "2025-09-09T07:46:34.941900Z",
     "iopub.status.idle": "2025-09-09T07:46:41.789082Z",
     "shell.execute_reply": "2025-09-09T07:46:41.788217Z"
    },
    "papermill": {
     "duration": 6.908695,
     "end_time": "2025-09-09T07:46:41.790623",
     "exception": false,
     "start_time": "2025-09-09T07:46:34.881928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['path', 'label_id', 'label_name', 'dataset_source'])\n",
    "df_test = pd.DataFrame(columns=['path', 'label_id', 'label_name', 'dataset_source'])\n",
    " \n",
    "for abel_id, class_name, path, dataset_tag in ALL_SUBS:\n",
    "    print(abel_id, class_name, path, dataset_tag)\n",
    "    images_path = load_image_class(path)\n",
    "    for image_path in images_path:\n",
    "        new_row = pd.DataFrame([[image_path, abel_id, class_name, dataset_tag]]                     \n",
    "                             , columns=df.columns)\n",
    "        df = pd.concat([df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1d1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:41.814411Z",
     "iopub.status.busy": "2025-09-09T07:46:41.814036Z",
     "iopub.status.idle": "2025-09-09T07:46:43.162597Z",
     "shell.execute_reply": "2025-09-09T07:46:43.162042Z"
    },
    "papermill": {
     "duration": 1.361618,
     "end_time": "2025-09-09T07:46:43.163845",
     "exception": false,
     "start_time": "2025-09-09T07:46:41.802227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for abel_id, class_name, path, dataset_tag in ALL_SUBS_TEST:\n",
    "    print(abel_id, class_name, path, dataset_tag)\n",
    "    images_path = load_image_class(path)\n",
    "    for image_path in images_path:\n",
    "        new_row = pd.DataFrame([[image_path, abel_id, class_name, dataset_tag]]                     \n",
    "                             , columns=df_test.columns)\n",
    "        df_test = pd.concat([df_test, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004ffa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:43.188063Z",
     "iopub.status.busy": "2025-09-09T07:46:43.187842Z",
     "iopub.status.idle": "2025-09-09T07:46:43.213587Z",
     "shell.execute_reply": "2025-09-09T07:46:43.212887Z"
    },
    "papermill": {
     "duration": 0.038735,
     "end_time": "2025-09-09T07:46:43.214684",
     "exception": false,
     "start_time": "2025-09-09T07:46:43.175949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf334d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:43.238941Z",
     "iopub.status.busy": "2025-09-09T07:46:43.238722Z",
     "iopub.status.idle": "2025-09-09T07:46:43.247220Z",
     "shell.execute_reply": "2025-09-09T07:46:43.246472Z"
    },
    "papermill": {
     "duration": 0.021834,
     "end_time": "2025-09-09T07:46:43.248301",
     "exception": false,
     "start_time": "2025-09-09T07:46:43.226467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0a0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:43.272042Z",
     "iopub.status.busy": "2025-09-09T07:46:43.271823Z",
     "iopub.status.idle": "2025-09-09T07:46:43.285539Z",
     "shell.execute_reply": "2025-09-09T07:46:43.284880Z"
    },
    "papermill": {
     "duration": 0.026847,
     "end_time": "2025-09-09T07:46:43.286626",
     "exception": false,
     "start_time": "2025-09-09T07:46:43.259779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Tổng số ảnh test extend lấy được:\", len(df_test))\n",
    "print(df_test.groupby([\"label_id\",\"label_name\"]).size())\n",
    "print(\"\\nPhân bố theo nguồn dataset:\")\n",
    "print(df_test.groupby([\"dataset_source\", \"label_name\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a085eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:43.311063Z",
     "iopub.status.busy": "2025-09-09T07:46:43.310876Z",
     "iopub.status.idle": "2025-09-09T07:46:43.320977Z",
     "shell.execute_reply": "2025-09-09T07:46:43.320159Z"
    },
    "papermill": {
     "duration": 0.023773,
     "end_time": "2025-09-09T07:46:43.322106",
     "exception": false,
     "start_time": "2025-09-09T07:46:43.298333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Tổng số ảnh lấy được:\", len(df))\n",
    "print(df.groupby([\"label_id\",\"label_name\"]).size())\n",
    "print(\"\\nPhân bố theo nguồn dataset:\")\n",
    "print(df.groupby([\"dataset_source\", \"label_name\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afbdf8",
   "metadata": {
    "papermill": {
     "duration": 0.01175,
     "end_time": "2025-09-09T07:46:43.345715",
     "exception": false,
     "start_time": "2025-09-09T07:46:43.333965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e4c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:43.370492Z",
     "iopub.status.busy": "2025-09-09T07:46:43.370216Z",
     "iopub.status.idle": "2025-09-09T07:46:44.075722Z",
     "shell.execute_reply": "2025-09-09T07:46:44.074993Z"
    },
    "papermill": {
     "duration": 0.719487,
     "end_time": "2025-09-09T07:46:44.077014",
     "exception": false,
     "start_time": "2025-09-09T07:46:43.357527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_label_counts(df, name, ax):\n",
    "    label_counts = df.groupby(\"label_name\")[\"path\"].count().sort_values(ascending=False)\n",
    "    label_counts.plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(f\"Số lượng ảnh theo từng nhãn bệnh\\n{name} trên lá lúa\")\n",
    "    ax.set_xlabel(\"Label (Tên bệnh)\")\n",
    "    ax.set_ylabel(\"Số lượng ảnh\")\n",
    "    ax.set_xticklabels(label_counts.index, rotation=0, ha=\"right\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,6), sharey=True)\n",
    "\n",
    "plot_label_counts(df, \"Dataset Train/Val\", axes[0])\n",
    "plot_label_counts(df_test, \"Dataset Test\", axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9441863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:44.103892Z",
     "iopub.status.busy": "2025-09-09T07:46:44.103636Z",
     "iopub.status.idle": "2025-09-09T07:46:44.111707Z",
     "shell.execute_reply": "2025-09-09T07:46:44.110963Z"
    },
    "papermill": {
     "duration": 0.022805,
     "end_time": "2025-09-09T07:46:44.112835",
     "exception": false,
     "start_time": "2025-09-09T07:46:44.090030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_by_source(df, num_samples=2, img_size=(128,128), ncols=4):\n",
    "    sources = sorted(df['dataset_source'].dropna().unique())\n",
    "    for source in sources:\n",
    "        source_df = df[df['dataset_source'] == source]\n",
    "        if len(source_df) == 0:\n",
    "            continue\n",
    "\n",
    "        unique_labels = sorted(source_df['label_name'].dropna().unique())\n",
    "        if len(unique_labels) == 0:\n",
    "            continue\n",
    "        samples_all = []\n",
    "        for label_name in unique_labels:\n",
    "            label_imgs = source_df[source_df['label_name'] == label_name]['path'].values\n",
    "            if len(label_imgs) == 0:\n",
    "                continue\n",
    "            samples = np.random.choice(label_imgs, \n",
    "                                       min(num_samples, len(label_imgs)), \n",
    "                                       replace=False)\n",
    "            for img_path in samples:\n",
    "                samples_all.append((img_path, label_name))\n",
    "\n",
    "        if len(samples_all) == 0:\n",
    "            continue\n",
    "\n",
    "        nrows = math.ceil(len(samples_all) / ncols)\n",
    "        plt.figure(figsize=(ncols*3, nrows*3))\n",
    "        plt.suptitle(f\"Samples data prepare train from {source}\", fontsize=16)\n",
    "\n",
    "        for idx, (img_path, label_name) in enumerate(samples_all):\n",
    "            plt.subplot(nrows, ncols, idx+1)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img = img.resize(img_size)\n",
    "                plt.imshow(img)\n",
    "                plt.title(label_name, fontsize=10)\n",
    "                plt.axis('off')\n",
    "            except Exception as e:\n",
    "                plt.text(0.5, 0.5, \"Error\", ha='center', va='center')\n",
    "                plt.axis('off')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d263e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:44.139050Z",
     "iopub.status.busy": "2025-09-09T07:46:44.138804Z",
     "iopub.status.idle": "2025-09-09T07:46:49.046078Z",
     "shell.execute_reply": "2025-09-09T07:46:49.045274Z"
    },
    "papermill": {
     "duration": 4.925848,
     "end_time": "2025-09-09T07:46:49.051532",
     "exception": false,
     "start_time": "2025-09-09T07:46:44.125684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_by_source(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16e643",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:49.154531Z",
     "iopub.status.busy": "2025-09-09T07:46:49.153557Z",
     "iopub.status.idle": "2025-09-09T07:46:50.440405Z",
     "shell.execute_reply": "2025-09-09T07:46:50.439664Z"
    },
    "papermill": {
     "duration": 1.350762,
     "end_time": "2025-09-09T07:46:50.453468",
     "exception": false,
     "start_time": "2025-09-09T07:46:49.102706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_by_source(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726db224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:50.583011Z",
     "iopub.status.busy": "2025-09-09T07:46:50.582717Z",
     "iopub.status.idle": "2025-09-09T07:46:50.609947Z",
     "shell.execute_reply": "2025-09-09T07:46:50.609262Z"
    },
    "papermill": {
     "duration": 0.092649,
     "end_time": "2025-09-09T07:46:50.611185",
     "exception": false,
     "start_time": "2025-09-09T07:46:50.518536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stat = df.groupby([\"dataset_source\", \"label_name\"]).size().reset_index(name=\"Count\")\n",
    "pivot_df = df_stat.pivot_table(\n",
    "    index=\"label_name\", \n",
    "    columns=\"dataset_source\", \n",
    "    values=\"Count\", \n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ")\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3752527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:50.746123Z",
     "iopub.status.busy": "2025-09-09T07:46:50.745174Z",
     "iopub.status.idle": "2025-09-09T07:46:51.098001Z",
     "shell.execute_reply": "2025-09-09T07:46:51.097275Z"
    },
    "papermill": {
     "duration": 0.424203,
     "end_time": "2025-09-09T07:46:51.099365",
     "exception": false,
     "start_time": "2025-09-09T07:46:50.675162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REVERSE_SOURCES = {v: k for k, v in DATASET_SOURCES.items()}\n",
    "pivot_df_renamed = pivot_df.rename(columns=REVERSE_SOURCES)\n",
    "\n",
    "ax = pivot_df_renamed.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    figsize=(10, 6),\n",
    "    colormap=\"Set2\"\n",
    ")\n",
    "\n",
    "plt.title(\"Số lượng ảnh theo nhãn bệnh và nguồn dữ liệu\", fontsize=14)\n",
    "plt.xlabel(\"Nhãn bệnh (Label)\", fontsize=12)\n",
    "plt.ylabel(\"Số lượng ảnh\", fontsize=12)\n",
    "\n",
    "plt.legend(title=\"Nguồn dữ liệu\", loc=\"center left\", bbox_to_anchor=(1.02, 0.5))\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e1d56",
   "metadata": {
    "papermill": {
     "duration": 0.060966,
     "end_time": "2025-09-09T07:46:51.228198",
     "exception": false,
     "start_time": "2025-09-09T07:46:51.167232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Chia train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b5896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:51.352086Z",
     "iopub.status.busy": "2025-09-09T07:46:51.351795Z",
     "iopub.status.idle": "2025-09-09T07:46:51.360212Z",
     "shell.execute_reply": "2025-09-09T07:46:51.359653Z"
    },
    "papermill": {
     "duration": 0.071177,
     "end_time": "2025-09-09T07:46:51.361383",
     "exception": false,
     "start_time": "2025-09-09T07:46:51.290206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_df(df, seed=42, test_size=0.2, val_size=0.2):\n",
    "    df_trainval, df_test = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=seed,\n",
    "        stratify=df['label_id'] if 'label_id' in df.columns else None\n",
    "    )\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_trainval,\n",
    "        test_size=val_size,\n",
    "        random_state=seed,\n",
    "        stratify=df_trainval['label_id'] if 'label_id' in df_trainval.columns else None\n",
    "    )\n",
    "    train_df = df_train.assign(split=\"train\").reset_index(drop=True)\n",
    "    val_df   = df_val.assign(split=\"val\").reset_index(drop=True)\n",
    "    test_df  = df_test.assign(split=\"test\").reset_index(drop=True)\n",
    "\n",
    "    return pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "def create_filtered_datasets(df, sources=None, test_size=0.2, val_size=0.2, seed=42):\n",
    "    if sources is not None:\n",
    "        filtered_df = df[df['dataset_source'].isin(sources)].copy()\n",
    "    else:\n",
    "        filtered_df = df.copy()\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        print(f\"Warning: No data found for sources {sources}\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    split_df_result = split_df(filtered_df, seed=seed, test_size=test_size, val_size=val_size)\n",
    "\n",
    "    train_df = split_df_result[split_df_result[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "    val_df   = split_df_result[split_df_result[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "    test_df  = split_df_result[split_df_result[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "    source_str = \"+\".join(sources) if sources else \"all_sources\"\n",
    "    print(f\"Dataset sources: {source_str}\")\n",
    "    print(f\"Split sizes: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c93a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:51.492778Z",
     "iopub.status.busy": "2025-09-09T07:46:51.492472Z",
     "iopub.status.idle": "2025-09-09T07:46:51.521866Z",
     "shell.execute_reply": "2025-09-09T07:46:51.521065Z"
    },
    "papermill": {
     "duration": 0.09812,
     "end_time": "2025-09-09T07:46:51.522966",
     "exception": false,
     "start_time": "2025-09-09T07:46:51.424846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_split = split_df(df, seed=42)\n",
    "print(df_split.groupby([\"split\",\"label_id\",\"label_name\"]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66835f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:51.644520Z",
     "iopub.status.busy": "2025-09-09T07:46:51.644206Z",
     "iopub.status.idle": "2025-09-09T07:46:52.081893Z",
     "shell.execute_reply": "2025-09-09T07:46:52.081127Z"
    },
    "papermill": {
     "duration": 0.498934,
     "end_time": "2025-09-09T07:46:52.083199",
     "exception": false,
     "start_time": "2025-09-09T07:46:51.584265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_counts = df_split.groupby([\"split\", \"label_name\"])[\"path\"].count().unstack(fill_value=0)\n",
    "split_counts.plot(kind=\"bar\", figsize=(12,6))\n",
    "plt.title(\"Số lượng ảnh theo split và label\")\n",
    "plt.xlabel(\"Label (Tên bệnh)\")\n",
    "plt.ylabel(\"Số lượng ảnh\")\n",
    "plt.xticks(rotation=0, ha=\"right\")\n",
    "plt.legend(title=\"Split\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03815e2b",
   "metadata": {
    "papermill": {
     "duration": 0.060949,
     "end_time": "2025-09-09T07:46:52.205539",
     "exception": false,
     "start_time": "2025-09-09T07:46:52.144590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lưu CSV meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc71c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:52.328487Z",
     "iopub.status.busy": "2025-09-09T07:46:52.328081Z",
     "iopub.status.idle": "2025-09-09T07:46:52.380449Z",
     "shell.execute_reply": "2025-09-09T07:46:52.379635Z"
    },
    "papermill": {
     "duration": 0.115073,
     "end_time": "2025-09-09T07:46:52.381659",
     "exception": false,
     "start_time": "2025-09-09T07:46:52.266586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_meta = \"/kaggle/working/riceleaf_meta.csv\"\n",
    "df_split.to_csv(out_meta, index=False)\n",
    "print(\"lưu meta leafrice:\", out_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9cea0",
   "metadata": {
    "papermill": {
     "duration": 0.059692,
     "end_time": "2025-09-09T07:46:52.502076",
     "exception": false,
     "start_time": "2025-09-09T07:46:52.442384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lưu output ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30c60a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:46:52.624800Z",
     "iopub.status.busy": "2025-09-09T07:46:52.624510Z",
     "iopub.status.idle": "2025-09-09T07:48:46.684049Z",
     "shell.execute_reply": "2025-09-09T07:48:46.683218Z"
    },
    "papermill": {
     "duration": 114.184712,
     "end_time": "2025-09-09T07:48:46.747555",
     "exception": false,
     "start_time": "2025-09-09T07:46:52.562843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DO_COPY = True\n",
    "OUTROOT = \"/kaggle/working/rice_dataset\"\n",
    "\n",
    "if DO_COPY:\n",
    "    for _, row in df_split.iterrows():\n",
    "        d = os.path.join(OUTROOT, row[\"split\"], f'{row[\"label_id\"]:02d}_{row[\"label_name\"]}')\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "        dst = os.path.join(d, os.path.basename(row[\"path\"]))\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy2(row[\"path\"], dst)\n",
    "    print(\"Đã copy ảnh vào:\", OUTROOT)\n",
    "else:\n",
    "    print(\"Dùng trực tiếp path từ df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436245e2",
   "metadata": {
    "papermill": {
     "duration": 0.063595,
     "end_time": "2025-09-09T07:48:46.874270",
     "exception": false,
     "start_time": "2025-09-09T07:48:46.810675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f198c18",
   "metadata": {
    "papermill": {
     "duration": 0.059222,
     "end_time": "2025-09-09T07:48:46.993393",
     "exception": false,
     "start_time": "2025-09-09T07:48:46.934171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Đọc dữ liệu từ CSV meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfd0ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:48:47.115426Z",
     "iopub.status.busy": "2025-09-09T07:48:47.114977Z",
     "iopub.status.idle": "2025-09-09T07:48:47.143367Z",
     "shell.execute_reply": "2025-09-09T07:48:47.142515Z"
    },
    "papermill": {
     "duration": 0.090551,
     "end_time": "2025-09-09T07:48:47.144484",
     "exception": false,
     "start_time": "2025-09-09T07:48:47.053933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"/kaggle/working/riceleaf_meta.csv\")\n",
    "\n",
    "train_df = meta[meta[\"split\"]==\"train\"]\n",
    "val_df   = meta[meta[\"split\"]==\"val\"]\n",
    "test_df  = meta[meta[\"split\"]==\"test\"]\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394ffbc",
   "metadata": {
    "papermill": {
     "duration": 0.060685,
     "end_time": "2025-09-09T07:48:47.266137",
     "exception": false,
     "start_time": "2025-09-09T07:48:47.205452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### CLAHE (Contrast Limited Adaptive Histogram Equalization) để tăng tương phản vùng lá lúa → giúp rõ vết bệnh hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35421b",
   "metadata": {
    "papermill": {
     "duration": 0.060226,
     "end_time": "2025-09-09T07:48:47.387706",
     "exception": false,
     "start_time": "2025-09-09T07:48:47.327480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| **Khía cạnh**           | **Lợi ích**                                                         | **Bất lợi**                                                                                   |\n",
    "| ----------------------- | ------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |\n",
    "| **Tương phản**          | Tăng cường chi tiết ở cả vùng sáng và tối, làm rõ vân lá, đốm bệnh. | Có thể làm **nhiễu** trở nên rõ ràng hơn ở vùng nền phẳng.                                    |\n",
    "| **Ánh sáng môi trường** | Giảm sự khác biệt giữa ảnh chụp ở điều kiện ánh sáng khác nhau.     | Nếu ảnh gốc đã có ánh sáng tốt, CLAHE có thể gây **quá sắc nét**.                             |\n",
    "| **Tính ổn định**        | Giúp model học feature rõ ràng hơn, đặc biệt với dataset nhỏ.       | Model có thể **overfit vào hình ảnh đã xử lý CLAHE**, kém robust với ảnh thực tế không xử lý. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6aad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:48:47.511424Z",
     "iopub.status.busy": "2025-09-09T07:48:47.510964Z",
     "iopub.status.idle": "2025-09-09T07:48:47.515711Z",
     "shell.execute_reply": "2025-09-09T07:48:47.515158Z"
    },
    "papermill": {
     "duration": 0.067427,
     "end_time": "2025-09-09T07:48:47.516820",
     "exception": false,
     "start_time": "2025-09-09T07:48:47.449393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_clahe_pil(pil_img):\n",
    "    \"\"\"Áp dụng CLAHE lên ảnh PIL\"\"\"\n",
    "    img = np.array(pil_img.convert(\"RGB\"))  # PIL -> numpy\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)  # sang không gian LAB\n",
    "    \n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    \n",
    "    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "    return Image.fromarray(enhanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be747c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:48:47.639339Z",
     "iopub.status.busy": "2025-09-09T07:48:47.638464Z",
     "iopub.status.idle": "2025-09-09T07:48:51.285593Z",
     "shell.execute_reply": "2025-09-09T07:48:51.284790Z"
    },
    "papermill": {
     "duration": 3.723148,
     "end_time": "2025-09-09T07:48:51.300198",
     "exception": false,
     "start_time": "2025-09-09T07:48:47.577050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = train_df.sample(5, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, (path, label) in enumerate(zip(samples['path'], samples['label_name'])):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img_clahe = apply_clahe_pil(img)\n",
    "\n",
    "    # Ảnh gốc\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{label}\\nOriginal\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Ảnh CLAHE\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    plt.imshow(img_clahe)\n",
    "    plt.title(\"CLAHE\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"So sánh ảnh gốc và sau CLAHE\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa0818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:48:51.474860Z",
     "iopub.status.busy": "2025-09-09T07:48:51.474042Z",
     "iopub.status.idle": "2025-09-09T07:48:51.480181Z",
     "shell.execute_reply": "2025-09-09T07:48:51.479436Z"
    },
    "papermill": {
     "duration": 0.097702,
     "end_time": "2025-09-09T07:48:51.481705",
     "exception": false,
     "start_time": "2025-09-09T07:48:51.384003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_clahe_in_batches(df, out_dir, batch_size=200):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    new_paths = []\n",
    "    n = len(df)\n",
    "    for i in tqdm(range(0, n, batch_size), desc=f\"Processing {out_dir}\"):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        for path, label in zip(batch['path'], batch['label_name']):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img_clahe = apply_clahe_pil(img)\n",
    "\n",
    "            # thư mục theo nhãn\n",
    "            label_dir = os.path.join(out_dir, label)\n",
    "            os.makedirs(label_dir, exist_ok=True)\n",
    "            # Lưu ảnh CLAHE\n",
    "            fname = os.path.basename(path)\n",
    "            save_path = os.path.join(label_dir, fname)\n",
    "            img_clahe.save(save_path)\n",
    "            new_paths.append(save_path)\n",
    "    return new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada7994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:48:51.643179Z",
     "iopub.status.busy": "2025-09-09T07:48:51.642889Z",
     "iopub.status.idle": "2025-09-09T07:53:08.349974Z",
     "shell.execute_reply": "2025-09-09T07:53:08.349289Z"
    },
    "papermill": {
     "duration": 256.784589,
     "end_time": "2025-09-09T07:53:08.351019",
     "exception": false,
     "start_time": "2025-09-09T07:48:51.566430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = meta[meta[\"split\"]==\"train\"].copy()\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "train_df[\"clahe_path\"] = save_clahe_in_batches(train_df, \"/kaggle/working/clahe/train\", batch_size=200)\n",
    "train_df[\"path\"] = train_df[\"clahe_path\"]\n",
    "train_df = train_df.drop(columns=[\"clahe_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f66ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:08.510821Z",
     "iopub.status.busy": "2025-09-09T07:53:08.510095Z",
     "iopub.status.idle": "2025-09-09T07:53:08.553464Z",
     "shell.execute_reply": "2025-09-09T07:53:08.552805Z"
    },
    "papermill": {
     "duration": 0.12712,
     "end_time": "2025-09-09T07:53:08.554535",
     "exception": false,
     "start_time": "2025-09-09T07:53:08.427415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_merged = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "meta_merged.to_csv(\"/kaggle/working/riceleaf_meta_merged.csv\", index=False)\n",
    "print(meta_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf4794",
   "metadata": {
    "papermill": {
     "duration": 0.079631,
     "end_time": "2025-09-09T07:53:08.711113",
     "exception": false,
     "start_time": "2025-09-09T07:53:08.631482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Chuẩn hoá ảnh (Resize + Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a194dd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:08.867228Z",
     "iopub.status.busy": "2025-09-09T07:53:08.866946Z",
     "iopub.status.idle": "2025-09-09T07:53:08.872881Z",
     "shell.execute_reply": "2025-09-09T07:53:08.872303Z"
    },
    "papermill": {
     "duration": 0.083615,
     "end_time": "2025-09-09T07:53:08.873987",
     "exception": false,
     "start_time": "2025-09-09T07:53:08.790372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3), \n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  \n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),  \n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1981d",
   "metadata": {
    "papermill": {
     "duration": 0.075365,
     "end_time": "2025-09-09T07:53:09.025526",
     "exception": false,
     "start_time": "2025-09-09T07:53:08.950161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25d8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:09.177834Z",
     "iopub.status.busy": "2025-09-09T07:53:09.177562Z",
     "iopub.status.idle": "2025-09-09T07:53:09.182548Z",
     "shell.execute_reply": "2025-09-09T07:53:09.181924Z"
    },
    "papermill": {
     "duration": 0.083008,
     "end_time": "2025-09-09T07:53:09.183702",
     "exception": false,
     "start_time": "2025-09-09T07:53:09.100694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RiceDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "        label = int(row[\"label_id\"])   \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5a93f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:09.340894Z",
     "iopub.status.busy": "2025-09-09T07:53:09.340109Z",
     "iopub.status.idle": "2025-09-09T07:53:09.414416Z",
     "shell.execute_reply": "2025-09-09T07:53:09.413811Z"
    },
    "papermill": {
     "duration": 0.155174,
     "end_time": "2025-09-09T07:53:09.415584",
     "exception": false,
     "start_time": "2025-09-09T07:53:09.260410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "train_set = RiceDataset(train_df, transform=train_transform)\n",
    "val_set   = RiceDataset(val_df, transform=val_test_transform)\n",
    "test_set  = RiceDataset(test_df, transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061613e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:09.573927Z",
     "iopub.status.busy": "2025-09-09T07:53:09.573095Z",
     "iopub.status.idle": "2025-09-09T07:53:10.726733Z",
     "shell.execute_reply": "2025-09-09T07:53:10.725839Z"
    },
    "papermill": {
     "duration": 1.235904,
     "end_time": "2025-09-09T07:53:10.728033",
     "exception": false,
     "start_time": "2025-09-09T07:53:09.492129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader  = DataLoader(test_set, \n",
    "                          batch_size=32, \n",
    "                          shuffle=False, num_workers=2, \n",
    "                          pin_memory=use_cuda)\n",
    "imgs, labels = next(iter(test_loader))\n",
    "print(\"Batch shape:\", imgs.shape)\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Min label:\", labels.min().item(), \"Max label:\", labels.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca72d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:10.882773Z",
     "iopub.status.busy": "2025-09-09T07:53:10.882466Z",
     "iopub.status.idle": "2025-09-09T07:53:10.886858Z",
     "shell.execute_reply": "2025-09-09T07:53:10.886303Z"
    },
    "papermill": {
     "duration": 0.083065,
     "end_time": "2025-09-09T07:53:10.887981",
     "exception": false,
     "start_time": "2025-09-09T07:53:10.804916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=64, \n",
    "    shuffle=True,\n",
    "    num_workers=4,            \n",
    "    pin_memory=use_cuda,      \n",
    "    persistent_workers=True,  \n",
    "    prefetch_factor=2,       \n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4, \n",
    "    pin_memory=use_cuda,\n",
    "    persistent_workers=True, prefetch_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49bd494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:11.043561Z",
     "iopub.status.busy": "2025-09-09T07:53:11.043288Z",
     "iopub.status.idle": "2025-09-09T07:53:13.654896Z",
     "shell.execute_reply": "2025-09-09T07:53:13.652120Z"
    },
    "papermill": {
     "duration": 2.692427,
     "end_time": "2025-09-09T07:53:13.657422",
     "exception": false,
     "start_time": "2025-09-09T07:53:10.964995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_loader))\n",
    "print(\"Batch shape:\", imgs.shape)\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Min label:\", labels.min().item(), \"Max label:\", labels.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9b9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:14.121941Z",
     "iopub.status.busy": "2025-09-09T07:53:14.121459Z",
     "iopub.status.idle": "2025-09-09T07:53:19.345119Z",
     "shell.execute_reply": "2025-09-09T07:53:19.344298Z"
    },
    "papermill": {
     "duration": 5.457328,
     "end_time": "2025-09-09T07:53:19.359833",
     "exception": false,
     "start_time": "2025-09-09T07:53:13.902505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(images[i].permute(1,2,0).numpy())\n",
    "    plt.title(labels[i].item())\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf80620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:19.728878Z",
     "iopub.status.busy": "2025-09-09T07:53:19.727709Z",
     "iopub.status.idle": "2025-09-09T07:53:19.755429Z",
     "shell.execute_reply": "2025-09-09T07:53:19.753649Z"
    },
    "papermill": {
     "duration": 0.166123,
     "end_time": "2025-09-09T07:53:19.757263",
     "exception": false,
     "start_time": "2025-09-09T07:53:19.591140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_counts = meta.groupby(\"label_name\")[\"path\"].count().sort_values(ascending=False)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e11da",
   "metadata": {
    "papermill": {
     "duration": 0.14035,
     "end_time": "2025-09-09T07:53:20.073600",
     "exception": false,
     "start_time": "2025-09-09T07:53:19.933250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca3dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:20.456740Z",
     "iopub.status.busy": "2025-09-09T07:53:20.456417Z",
     "iopub.status.idle": "2025-09-09T07:53:20.471642Z",
     "shell.execute_reply": "2025-09-09T07:53:20.468883Z"
    },
    "papermill": {
     "duration": 0.236566,
     "end_time": "2025-09-09T07:53:20.476644",
     "exception": false,
     "start_time": "2025-09-09T07:53:20.240078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = meta[\"label_id\"].nunique()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97f946",
   "metadata": {
    "papermill": {
     "duration": 0.139466,
     "end_time": "2025-09-09T07:53:20.760666",
     "exception": false,
     "start_time": "2025-09-09T07:53:20.621200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### (1) CNN đơn giản (3 lớp Conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617323f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:21.076288Z",
     "iopub.status.busy": "2025-09-09T07:53:21.074546Z",
     "iopub.status.idle": "2025-09-09T07:53:21.084263Z",
     "shell.execute_reply": "2025-09-09T07:53:21.083596Z"
    },
    "papermill": {
     "duration": 0.15408,
     "end_time": "2025-09-09T07:53:21.085871",
     "exception": false,
     "start_time": "2025-09-09T07:53:20.931791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))   # Global Avg Pool\n",
    "        # self.fc = nn.Linear(128, num_classes)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),               \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345c814",
   "metadata": {
    "papermill": {
     "duration": 0.129259,
     "end_time": "2025-09-09T07:53:21.349754",
     "exception": false,
     "start_time": "2025-09-09T07:53:21.220495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### (2) ResNet18 (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80bbf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:21.629709Z",
     "iopub.status.busy": "2025-09-09T07:53:21.627493Z",
     "iopub.status.idle": "2025-09-09T07:53:21.635396Z",
     "shell.execute_reply": "2025-09-09T07:53:21.634737Z"
    },
    "papermill": {
     "duration": 0.155071,
     "end_time": "2025-09-09T07:53:21.637117",
     "exception": false,
     "start_time": "2025-09-09T07:53:21.482046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "def build_resnet18(num_classes):\n",
    "    weights = ResNet18_Weights.DEFAULT  # thay cho pretrained=True\n",
    "    model = resnet18(weights=weights)\n",
    "    # model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596f179",
   "metadata": {
    "papermill": {
     "duration": 0.132318,
     "end_time": "2025-09-09T07:53:21.899281",
     "exception": false,
     "start_time": "2025-09-09T07:53:21.766963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### (3) ResNet50 (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f9924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:22.132052Z",
     "iopub.status.busy": "2025-09-09T07:53:22.131442Z",
     "iopub.status.idle": "2025-09-09T07:53:22.135955Z",
     "shell.execute_reply": "2025-09-09T07:53:22.135180Z"
    },
    "papermill": {
     "duration": 0.119244,
     "end_time": "2025-09-09T07:53:22.137199",
     "exception": false,
     "start_time": "2025-09-09T07:53:22.017955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "def build_resnet50(num_classes):\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights)\n",
    "    # model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd94d1",
   "metadata": {
    "papermill": {
     "duration": 0.081737,
     "end_time": "2025-09-09T07:53:22.302003",
     "exception": false,
     "start_time": "2025-09-09T07:53:22.220266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  (4) EfficientNet-B0 (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0e737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:22.469776Z",
     "iopub.status.busy": "2025-09-09T07:53:22.469489Z",
     "iopub.status.idle": "2025-09-09T07:53:22.474295Z",
     "shell.execute_reply": "2025-09-09T07:53:22.473718Z"
    },
    "papermill": {
     "duration": 0.089106,
     "end_time": "2025-09-09T07:53:22.475413",
     "exception": false,
     "start_time": "2025-09-09T07:53:22.386307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "def build_efficientnet(num_classes):\n",
    "    weights = EfficientNet_B0_Weights.DEFAULT\n",
    "    model = efficientnet_b0(weights=weights)\n",
    "    # model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    in_feat = model.classifier[1].in_features \n",
    "    model.classifier[1] = nn.Sequential(\n",
    "        nn.Dropout(0.2),  \n",
    "        nn.Linear(in_feat, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff270cf",
   "metadata": {
    "papermill": {
     "duration": 0.081542,
     "end_time": "2025-09-09T07:53:22.638031",
     "exception": false,
     "start_time": "2025-09-09T07:53:22.556489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### (5) MobileNetV2 (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353234d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:22.801398Z",
     "iopub.status.busy": "2025-09-09T07:53:22.800582Z",
     "iopub.status.idle": "2025-09-09T07:53:22.806933Z",
     "shell.execute_reply": "2025-09-09T07:53:22.806515Z"
    },
    "papermill": {
     "duration": 0.088616,
     "end_time": "2025-09-09T07:53:22.808050",
     "exception": false,
     "start_time": "2025-09-09T07:53:22.719434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "def build_mobilenet(num_classes):\n",
    "    weights = MobileNet_V2_Weights.DEFAULT\n",
    "    model = mobilenet_v2(weights=weights)\n",
    "    # model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    in_feat = model.classifier[1].in_features \n",
    "    model.classifier[1] = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(in_feat, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b34a98",
   "metadata": {
    "papermill": {
     "duration": 0.080871,
     "end_time": "2025-09-09T07:53:22.968973",
     "exception": false,
     "start_time": "2025-09-09T07:53:22.888102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### (6) Custom RiceLeafCNN - Specialized Architecture for Rice Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbdd40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:23.140369Z",
     "iopub.status.busy": "2025-09-09T07:53:23.139944Z",
     "iopub.status.idle": "2025-09-09T07:53:23.152269Z",
     "shell.execute_reply": "2025-09-09T07:53:23.151503Z"
    },
    "papermill": {
     "duration": 0.103652,
     "end_time": "2025-09-09T07:53:23.153497",
     "exception": false,
     "start_time": "2025-09-09T07:53:23.049845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RiceLeafCNN(nn.Module):\n",
    "    \"\"\"Custom architecture specialized for rice leaf disease with focus on efficiency\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(RiceLeafCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction path with depth-wise separable convolutions\n",
    "        self.features = nn.Sequential(\n",
    "            # Standard first conv\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Depthwise separable blocks for efficiency\n",
    "            self._depthwise_block(32, 64, stride=1),\n",
    "            self._depthwise_block(64, 128, stride=2),\n",
    "            self._depthwise_block(128, 128, stride=1),\n",
    "            self._depthwise_block(128, 256, stride=2),\n",
    "            self._depthwise_block(256, 256, stride=1),\n",
    "            self._depthwise_block(256, 512, stride=2),\n",
    "            \n",
    "            # Extra blocks with skip connections for disease texture patterns\n",
    "            self._residual_block(512, 512),\n",
    "            self._residual_block(512, 512),\n",
    "        )\n",
    "        \n",
    "        # Disease-specific pattern enhancement with dilated convolutions\n",
    "        self.pattern_enhancer = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=2, dilation=2, groups=512, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 1, bias=False),  # Pointwise\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _depthwise_block(self, in_channels, out_channels, stride=1):\n",
    "        return nn.Sequential(\n",
    "            # Depthwise\n",
    "            nn.Conv2d(in_channels, in_channels, 3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Pointwise\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def _residual_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1, groups=out_channels, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pattern_enhancer(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a35f6",
   "metadata": {
    "papermill": {
     "duration": 0.080455,
     "end_time": "2025-09-09T07:53:23.314350",
     "exception": false,
     "start_time": "2025-09-09T07:53:23.233895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| Mô hình             | Lõi kiến trúc                                                               | Đặc trưng chính                    | Điểm mạnh                                          | Hạn chế                                                 | Khi nên dùng                                                  |\n",
    "| ------------------- | --------------------------------------------------------------------------- | ---------------------------------- | -------------------------------------------------- | ------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| **SimpleCNN**       | 3× (Conv+ReLU+MaxPool) → GAP → FC                                           | Cực đơn giản, dễ debug             | Nhanh, ít tham số, baseline tốt                    | Biểu đạt hạn chế trên mẫu phức tạp                      | Kiểm thử pipeline, dataset rất nhỏ                            |\n",
    "| **RiceLeafCNN**     | Depthwise-separable + (khối “residual” tùy chỉnh) + dilated depthwise + GAP | Tối ưu họa tiết lá, nhẹ            | Hiệu quả FLOPs/tham số tốt; nhấn mạnh pattern bệnh | “Residual” trong code chưa có skip; cần tinh chỉnh thêm | Bài toán lá/bệnh; cần mô hình gọn nhưng giàu đặc trưng cục bộ |\n",
    "| **ResNet-18**       | Residual basic blocks (2×3×3)                                               | Skip connection giúp train ổn định | Triển khai dễ, ổn định, nhanh hơn ResNet-50        | Chính xác kém hơn mạng sâu hơn                          | Baseline chắc, inference nhanh                                |\n",
    "| **ResNet-50**       | Residual **bottleneck** (1×1–3×3–1×1)                                       | Sâu hơn, mạnh hơn R18              | Chính xác tốt, phổ biến                            | Nặng hơn MobileNet/EffNet-B0                            | Khi cần thêm accuracy nhưng vẫn muốn kiến trúc “chuẩn”        |\n",
    "| **EfficientNet-B0** | **MBConv + SE** + compound scaling                                          | Rất hiệu quả params/FLOPs          | Accuracy cao với chi phí thấp                      | Cấu trúc phức tạp hơn; nhạy preprocessing               | Muốn tối ưu **accuracy/compute**                              |\n",
    "| **MobileNetV2**     | **Inverted residual + linear bottleneck**                                   | Cực nhẹ, depthwise separable       | Rất nhanh/nhẹ (edge)                               | Accuracy < EffNet-B0/ResNet-50                          | Thiết bị giới hạn, realtime                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3109d3",
   "metadata": {
    "papermill": {
     "duration": 0.084695,
     "end_time": "2025-09-09T07:53:23.484504",
     "exception": false,
     "start_time": "2025-09-09T07:53:23.399809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb15140",
   "metadata": {
    "papermill": {
     "duration": 0.08637,
     "end_time": "2025-09-09T07:53:23.654921",
     "exception": false,
     "start_time": "2025-09-09T07:53:23.568551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kiểm tra máy tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc488c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:23.826840Z",
     "iopub.status.busy": "2025-09-09T07:53:23.826087Z",
     "iopub.status.idle": "2025-09-09T07:53:23.833450Z",
     "shell.execute_reply": "2025-09-09T07:53:23.832917Z"
    },
    "papermill": {
     "duration": 0.095454,
     "end_time": "2025-09-09T07:53:23.834590",
     "exception": false,
     "start_time": "2025-09-09T07:53:23.739136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chọn thiết bị: xác định dùng CPU hay GPU (CUDA).\n",
    "# Tạo AMP context: bật autocast nếu có CUDA, ngược lại dùng nullcontext().\n",
    "# Tạo GradScaler: chọn API mới/cũ và bật tắt theo tình trạng CUDA.\n",
    "\n",
    "def setup_amp():\n",
    "    try:\n",
    "        from torch.amp import GradScaler, autocast\n",
    "        NEW_AMP = True\n",
    "    except Exception:\n",
    "        from torch.cuda.amp import GradScaler, autocast\n",
    "        NEW_AMP = False\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if not use_cuda:\n",
    "        amp_ctx = nullcontext()\n",
    "    else:\n",
    "        amp_ctx = autocast(device_type=\"cuda\", enabled=True) if NEW_AMP else autocast(enabled=True)\n",
    "    if NEW_AMP:\n",
    "        scaler = GradScaler(device=\"cuda\" if use_cuda else \"cpu\", enabled=use_cuda)\n",
    "    else:\n",
    "        scaler = GradScaler(enabled=use_cuda)\n",
    "    return device, amp_ctx, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e216c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:24.001077Z",
     "iopub.status.busy": "2025-09-09T07:53:24.000794Z",
     "iopub.status.idle": "2025-09-09T07:53:24.006336Z",
     "shell.execute_reply": "2025-09-09T07:53:24.005658Z"
    },
    "papermill": {
     "duration": 0.091833,
     "end_time": "2025-09-09T07:53:24.007422",
     "exception": false,
     "start_time": "2025-09-09T07:53:23.915589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, mode=\"min\", min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.best = None\n",
    "        self.counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "    def step(self, current):\n",
    "        if self.best is None:\n",
    "            self.best = current\n",
    "            return False\n",
    "\n",
    "        improvement = (current < self.best - self.min_delta) if self.mode == \"min\" else (current > self.best + self.min_delta)\n",
    "\n",
    "        if improvement:\n",
    "            self.best = current\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        return self.should_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52cbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:24.168733Z",
     "iopub.status.busy": "2025-09-09T07:53:24.168462Z",
     "iopub.status.idle": "2025-09-09T07:53:24.173106Z",
     "shell.execute_reply": "2025-09-09T07:53:24.172577Z"
    },
    "papermill": {
     "duration": 0.086892,
     "end_time": "2025-09-09T07:53:24.174268",
     "exception": false,
     "start_time": "2025-09-09T07:53:24.087376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = bool(torch.cuda.is_available())\n",
    "def prepare_model(model, lr, monitor):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = \"min\" if monitor==\"val_loss\" else \"max\", factor=0.5, patience=2)\n",
    "    return model, scheduler, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa446b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:24.342749Z",
     "iopub.status.busy": "2025-09-09T07:53:24.342364Z",
     "iopub.status.idle": "2025-09-09T07:53:24.353932Z",
     "shell.execute_reply": "2025-09-09T07:53:24.353402Z"
    },
    "papermill": {
     "duration": 0.099598,
     "end_time": "2025-09-09T07:53:24.355002",
     "exception": false,
     "start_time": "2025-09-09T07:53:24.255404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=30, lr=1e-4, device=None, ckpt_path=\"/kaggle/working/best.pth\", es_patience=5, monitor=\"val_loss\"):\n",
    "    dev, amp_ctx, scaler = setup_amp()\n",
    "    if device is None:   \n",
    "        device = dev\n",
    "\n",
    "    model, scheduler, optimizer, criterion = prepare_model(model, lr, monitor)\n",
    "    es = EarlyStopping(patience=es_patience, mode=(\"min\" if monitor==\"val_loss\" else \"max\"), min_delta=0.0)\n",
    "\n",
    "    best_metric = float(\"inf\") if monitor==\"val_loss\" else -float(\"inf\")\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # TRAIN \n",
    "        model.train()\n",
    "        running_loss, running_correct, running_total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Train E{epoch}/{epochs}\")\n",
    "\n",
    "        for imgs, labels in pbar:\n",
    "            imgs   = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.long().to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with amp_ctx:   \n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += float(loss.item()) * imgs.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            running_total += labels.size(0)\n",
    "            pbar.set_postfix(loss=float(loss.item()))\n",
    "\n",
    "        train_loss = running_loss / max(1, running_total)\n",
    "        train_acc  = running_correct / max(1, running_total)\n",
    "        \n",
    "        # VALID \n",
    "        model.eval()\n",
    "        val_loss_sum, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(val_loader, desc=f\"Valid E{epoch}/{epochs}\"):\n",
    "                imgs   = imgs.to(device, non_blocking=True)\n",
    "                labels = labels.long().to(device, non_blocking=True)\n",
    "                with amp_ctx:  \n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                val_loss_sum += float(loss.item()) * imgs.size(0)\n",
    "                val_correct  += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total    += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss_sum / max(1, val_total)\n",
    "        val_acc  = val_correct / max(1, val_total)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        print(f\"Epoch {epoch}/{epochs} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
    "\n",
    "        monitored_value = val_loss if monitor == \"val_loss\" else val_acc\n",
    "        scheduler.step(monitored_value)\n",
    "\n",
    "        is_better = (monitored_value < best_metric) if monitor==\"val_loss\" else (monitored_value > best_metric)\n",
    "        if is_better:\n",
    "            best_metric = monitored_value\n",
    "            torch.save(model.state_dict(), ckpt_path)\n",
    "            print(f\"Saved BEST to {ckpt_path} (best {monitor}: {best_metric:.4f})\")\n",
    "        if es.step(monitored_value):\n",
    "            print(f\"Early stopping at epoch {epoch} (no improvement on {monitor})\")\n",
    "            break\n",
    "\n",
    "    print(f\"Best {monitor}: {best_metric:.4f}\")\n",
    "    return history, ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a866444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:24.525175Z",
     "iopub.status.busy": "2025-09-09T07:53:24.524627Z",
     "iopub.status.idle": "2025-09-09T07:53:24.533171Z",
     "shell.execute_reply": "2025-09-09T07:53:24.532458Z"
    },
    "papermill": {
     "duration": 0.096888,
     "end_time": "2025-09-09T07:53:24.534440",
     "exception": false,
     "start_time": "2025-09-09T07:53:24.437552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_on_loader(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for imgs, labels in loader:\n",
    "        imgs   = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.long().to(device, non_blocking=True)\n",
    "        logits = model(imgs)\n",
    "        preds  = logits.argmax(1)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "    y_pred  = np.concatenate(all_preds)\n",
    "    y_true  = np.concatenate(all_labels)\n",
    "    acc     = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    return {\"test_acc\": acc, \"precision\": p, \"recall\": r, \"f1\": f1, \"confusion_matrix\": confusion_matrix(y_true, y_pred)}\n",
    "\n",
    "def count_params_m(model):\n",
    "    return sum(p.numel() for p in model.parameters()) / 1e6\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_latency_ms(model, device, input_size=(1,3,224,224), warmup=10, runs=30):\n",
    "    model.eval()\n",
    "    x = torch.randn(*input_size, device=device)\n",
    "    # warm-up\n",
    "    for _ in range(warmup):\n",
    "        _ = model(x)\n",
    "    # measure\n",
    "    torch.cuda.synchronize() if device.type == \"cuda\" else None\n",
    "    t0 = time.time()\n",
    "    for _ in range(runs):\n",
    "        _ = model(x)\n",
    "    torch.cuda.synchronize() if device.type == \"cuda\" else None\n",
    "    dt = (time.time() - t0) / runs\n",
    "    return dt * 1000.0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39758e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:24.702916Z",
     "iopub.status.busy": "2025-09-09T07:53:24.702178Z",
     "iopub.status.idle": "2025-09-09T07:53:24.712369Z",
     "shell.execute_reply": "2025-09-09T07:53:24.711776Z"
    },
    "papermill": {
     "duration": 0.096133,
     "end_time": "2025-09-09T07:53:24.713650",
     "exception": false,
     "start_time": "2025-09-09T07:53:24.617517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title=\"Training Curve\", show=True, save_path=None, monitor=\"val_loss\"):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Tìm best point theo monitor\n",
    "    if monitor == \"val_loss\":\n",
    "        best_epoch = int(np.argmin(history[\"val_loss\"])) + 1\n",
    "        best_value = min(history[\"val_loss\"])\n",
    "        label_text = f\"Best Val Loss={best_value:.4f} (Epoch {best_epoch})\"\n",
    "    else:  # val_acc\n",
    "        best_epoch = int(np.argmax(history[\"val_acc\"])) + 1\n",
    "        best_value = max(history[\"val_acc\"])\n",
    "        label_text = f\"Best Val Acc={best_value:.4f} (Epoch {best_epoch})\"\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.scatter(best_epoch, history[\"val_acc\"][best_epoch-1], color=\"red\", marker=\"o\", s=80, label=\"Best Point\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.scatter(best_epoch, history[\"val_loss\"][best_epoch-1], color=\"red\", marker=\"o\", s=80, label=\"Best Point\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title} - Loss\\n{label_text}\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb4e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:24.885655Z",
     "iopub.status.busy": "2025-09-09T07:53:24.885376Z",
     "iopub.status.idle": "2025-09-09T07:53:24.894344Z",
     "shell.execute_reply": "2025-09-09T07:53:24.893628Z"
    },
    "papermill": {
     "duration": 0.098182,
     "end_time": "2025-09-09T07:53:24.895559",
     "exception": false,
     "start_time": "2025-09-09T07:53:24.797377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def comprehensive_evaluation(models_dict, dataset_combinations, device, epochs=10):\n",
    "    results = []\n",
    "    all_histories = {}\n",
    "    \n",
    "    for sources in dataset_combinations:\n",
    "        source_name = \"+\".join(sources) if sources else \"all_sources\"\n",
    "        print(f\"\\n===== EVALUATING ON {source_name} =====\")\n",
    "        \n",
    "        # Create datasets for this combination\n",
    "        train_df_filtered, val_df_filtered, test_df_filtered = create_filtered_datasets(meta, sources=sources)\n",
    "        \n",
    "        if len(train_df_filtered) == 0:\n",
    "            print(f\"Skipping {source_name} - no data found\")\n",
    "            continue\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_set = RiceDataset(train_df_filtered, transform=train_transform)\n",
    "        val_set = RiceDataset(val_df_filtered, transform=val_test_transform)\n",
    "        test_set = RiceDataset(test_df_filtered, transform=val_test_transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "        test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "        \n",
    "        for model_name, model_constructor in models_dict.items():\n",
    "            print(f\"\\nTraining {model_name} on {source_name}\")\n",
    "            \n",
    "            # Initialize model\n",
    "            model = model_constructor().to(device)\n",
    "            \n",
    "            # Train model\n",
    "            ckpt_path = f\"/kaggle/working/{model_name}_{source_name}_best.pth\"\n",
    "            history, _ = train_model(\n",
    "                model, train_loader, val_loader,\n",
    "                epochs=epochs, lr=1e-4, device=device,\n",
    "                ckpt_path=ckpt_path, \n",
    "                es_patience=5, monitor=\"val_loss\"\n",
    "            )\n",
    "            \n",
    "            all_histories[f\"{model_name}_{source_name}\"] = history\n",
    "            plot_history(history, title=f\"{model_name} on {source_name}\", save_path=f\"/kaggle/working/modeltraining/{model_name}_{source_name}_curve.png\", monitor=\"val_acc\")\n",
    "            # Load best weights and evaluate\n",
    "            model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "            test_metrics = evaluate_on_loader(model, test_loader, device)\n",
    "            \n",
    "            # Model metrics\n",
    "            params_m = count_params_m(model)\n",
    "            latency_ms = measure_latency_ms(model, device)\n",
    "            fps = 1000 / latency_ms\n",
    "            \n",
    "            # Save results\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Dataset\": source_name,\n",
    "                \"Test Acc\": test_metrics[\"test_acc\"],\n",
    "                \"Precision\": test_metrics[\"precision\"],\n",
    "                \"Recall\": test_metrics[\"recall\"],\n",
    "                \"F1\": test_metrics[\"f1\"],\n",
    "                \"Params (M)\": params_m,\n",
    "                \"Latency (ms)\": latency_ms,\n",
    "                \"FPS\": fps,\n",
    "                \"Checkpoint\": ckpt_path\n",
    "            })\n",
    "            \n",
    "            # Clean up\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    return pd.DataFrame(results), all_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f68e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T07:53:25.066760Z",
     "iopub.status.busy": "2025-09-09T07:53:25.066468Z",
     "iopub.status.idle": "2025-09-09T13:32:42.286128Z",
     "shell.execute_reply": "2025-09-09T13:32:42.285312Z"
    },
    "papermill": {
     "duration": 20358.614117,
     "end_time": "2025-09-09T13:32:43.590974",
     "exception": false,
     "start_time": "2025-09-09T07:53:24.976857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_combinations = [\n",
    "    [\"dataset_1\"],  \n",
    "    [\"dataset_1\", \"dataset_4\"],\n",
    "    None,  \n",
    "]\n",
    "\n",
    "models_list = {\n",
    "    \"SimpleCNN\":       lambda: SimpleCNN(num_classes),\n",
    "    \"RiceLeafCNN\":     lambda: RiceLeafCNN(num_classes), \n",
    "    \"ResNet18\":        lambda: build_resnet18(num_classes),\n",
    "    \"ResNet50\":        lambda: build_resnet50(num_classes),\n",
    "    \"EfficientNetB0\":  lambda: build_efficientnet(num_classes),\n",
    "    \"MobileNetV2\":     lambda: build_mobilenet(num_classes),\n",
    "}\n",
    "\n",
    "results_df, histories = comprehensive_evaluation(models_list, source_combinations, device, epochs=20)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPREHENSIVE RESULTS\") \n",
    "print(\"=\"*50)\n",
    "print(results_df.to_string(index=False))\n",
    "results_df.to_csv(\"/kaggle/working/comprehensive_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ecdd7",
   "metadata": {
    "papermill": {
     "duration": 1.285245,
     "end_time": "2025-09-09T13:32:46.052368",
     "exception": false,
     "start_time": "2025-09-09T13:32:44.767123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## So sánh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b3415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:32:48.494303Z",
     "iopub.status.busy": "2025-09-09T13:32:48.493674Z",
     "iopub.status.idle": "2025-09-09T13:32:50.512975Z",
     "shell.execute_reply": "2025-09-09T13:32:50.512232Z"
    },
    "papermill": {
     "duration": 3.301292,
     "end_time": "2025-09-09T13:32:50.516132",
     "exception": false,
     "start_time": "2025-09-09T13:32:47.214840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SO SÁNH TEST ACCURACY GIỮA CÁC MODEL THEO TỪNG BỘ DATASET\n",
    "def plot_model_dataset_accuracy_comparison(results_df):\n",
    "    if len(results_df) == 0:\n",
    "        print(\"Không có dữ liệu để hiển thị\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('So sánh Test Accuracy: Models vs Datasets', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Grouped Bar Chart\n",
    "    ax1 = axes[0, 0]\n",
    "    pivot_acc = results_df.pivot(index='Model', columns='Dataset', values='Test Acc')\n",
    "    \n",
    "    # Plot grouped bars\n",
    "    pivot_acc.plot(kind='bar', ax=ax1, width=0.8, colormap='tab10')\n",
    "    ax1.set_title('Test Accuracy by Model and Dataset', fontsize=14)\n",
    "    ax1.set_ylabel('Test Accuracy', fontsize=12)\n",
    "    ax1.set_xlabel('Model', fontsize=12)\n",
    "    ax1.set_ylim(0, 1.0)\n",
    "    ax1.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for container in ax1.containers:\n",
    "        ax1.bar_label(container, fmt='%.3f', fontsize=9, rotation=90)\n",
    "    \n",
    "    # 2. Heatmap\n",
    "    ax2 = axes[0, 1]\n",
    "    sns.heatmap(pivot_acc, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                ax=ax2, cbar_kws={'label': 'Test Accuracy'})\n",
    "    ax2.set_title('Accuracy Heatmap', fontsize=14)\n",
    "    ax2.set_xlabel('Dataset', fontsize=12)\n",
    "    ax2.set_ylabel('Model', fontsize=12)\n",
    "    \n",
    "    # 3. Line Plot - Xu hướng accuracy qua các dataset\n",
    "    ax3 = axes[1, 0]\n",
    "    for model in results_df['Model'].unique():\n",
    "        model_data = results_df[results_df['Model'] == model]\n",
    "        ax3.plot(model_data['Dataset'], model_data['Test Acc'], \n",
    "                marker='o', linewidth=2, markersize=8, label=model)\n",
    "    \n",
    "    ax3.set_title('Accuracy Trends Across Datasets', fontsize=14)\n",
    "    ax3.set_ylabel('Test Accuracy', fontsize=12)\n",
    "    ax3.set_xlabel('Dataset', fontsize=12)\n",
    "    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Stacked Bar Chart - Contribution comparison\n",
    "    ax4 = axes[1, 1]\n",
    "    pivot_acc_T = pivot_acc.T  # Transpose for stacked bars\n",
    "    pivot_acc_T.plot(kind='bar', stacked=True, ax=ax4, colormap='Set3')\n",
    "    ax4.set_title('Stacked Accuracy by Dataset', fontsize=14)\n",
    "    ax4.set_ylabel('Cumulative Test Accuracy', fontsize=12)\n",
    "    ax4.set_xlabel('Dataset', fontsize=12)\n",
    "    ax4.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"/kaggle/working/model_dataset_accuracy_comparison.png\", \n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"THỐNG KÊ CHI TIẾT ACCURACY THEO MODEL VÀ DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Best performer for each dataset\n",
    "    print(\"\\n MODEL TỐT NHẤT CHO TỪNG DATASET:\")\n",
    "    for dataset in results_df['Dataset'].unique():\n",
    "        dataset_data = results_df[results_df['Dataset'] == dataset]\n",
    "        best_model = dataset_data.loc[dataset_data['Test Acc'].idxmax()]\n",
    "        print(f\"   {dataset}: {best_model['Model']} ({best_model['Test Acc']:.4f})\")\n",
    "    \n",
    "    # Average performance by model\n",
    "    print(\"\\n ACCURACY TRUNG BÌNH CỦA TỪNG MODEL:\")\n",
    "    for model in results_df['Model'].unique():\n",
    "        model_data = results_df[results_df['Model'] == model]\n",
    "        avg_acc = model_data['Test Acc'].mean()\n",
    "        std_acc = model_data['Test Acc'].std()\n",
    "        print(f\"   {model}: {avg_acc:.4f} ± {std_acc:.4f}\")\n",
    "    \n",
    "    # Dataset difficulty ranking\n",
    "    print(\"\\n XẾP HẠNG ĐỘ KHÓ CỦA CÁC DATASET (theo accuracy trung bình):\")\n",
    "    dataset_avg = results_df.groupby('Dataset')['Test Acc'].mean().sort_values(ascending=False)\n",
    "    for i, (dataset, avg_acc) in enumerate(dataset_avg.items(), 1):\n",
    "        difficulty = \"Dễ\" if avg_acc > 0.9 else \"Trung bình\" if avg_acc > 0.8 else \"Khó\"\n",
    "        print(f\"   {i}. {dataset}: {avg_acc:.4f} ({difficulty})\")\n",
    "\n",
    "# Run the comparison\n",
    "if 'results_df' in locals() and len(results_df) > 0:\n",
    "    plot_model_dataset_accuracy_comparison(results_df)\n",
    "elif 'df_results' in locals() and len(df_results) > 0:\n",
    "    # If using the old variable name\n",
    "    plot_model_dataset_accuracy_comparison(df_results)\n",
    "else:\n",
    "    # Create sample data for demonstration\n",
    "    print(\"Không tìm thấy results_df. Tạo dữ liệu mẫu để demo...\")\n",
    "    sample_data = {\n",
    "        'Model': ['SimpleCNN', 'RiceLeafCNN', 'ResNet18', 'MobileNetV2'] * 3,\n",
    "        'Dataset': ['all_sources'] * 4 + ['dataset_1'] * 4 + ['dataset_1+dataset_2'] * 4,\n",
    "        'Test Acc': [0.85, 0.89, 0.92, 0.87, 0.83, 0.88, 0.91, 0.86, 0.86, 0.90, 0.93, 0.88]\n",
    "    }\n",
    "    sample_df = pd.DataFrame(sample_data)\n",
    "    plot_model_dataset_accuracy_comparison(sample_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8863856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:32:52.963977Z",
     "iopub.status.busy": "2025-09-09T13:32:52.963699Z",
     "iopub.status.idle": "2025-09-09T13:32:54.866992Z",
     "shell.execute_reply": "2025-09-09T13:32:54.866282Z"
    },
    "papermill": {
     "duration": 3.189655,
     "end_time": "2025-09-09T13:32:54.869475",
     "exception": false,
     "start_time": "2025-09-09T13:32:51.679820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_comparison_by_dataset(results_df):\n",
    "    \"\"\"Plot performance comparison of models across different datasets\"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    plt.subplot(2, 2, 1)\n",
    "    pivot_acc = results_df.pivot(index='Model', columns='Dataset', values='Test Acc')\n",
    "    pivot_acc.plot(kind='bar', ax=plt.gca())\n",
    "    plt.title('Accuracy by Model and Dataset')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Speed (FPS) comparison  \n",
    "    plt.subplot(2, 2, 2)\n",
    "    pivot_fps = results_df.pivot(index='Model', columns='Dataset', values='FPS')\n",
    "    pivot_fps.plot(kind='bar', ax=plt.gca())\n",
    "    plt.title('Speed (FPS) by Model and Dataset')\n",
    "    plt.ylabel('FPS')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for dataset in results_df['Dataset'].unique():\n",
    "        df_subset = results_df[results_df['Dataset'] == dataset]\n",
    "        plt.scatter(df_subset['Params (M)'], df_subset['Test Acc'], \n",
    "                   label=dataset, s=100, alpha=0.7)\n",
    "        for _, row in df_subset.iterrows():\n",
    "            plt.annotate(row['Model'], \n",
    "                        (row['Params (M)'], row['Test Acc']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.xlabel('Model Size (M parameters)')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.title('Model Size vs Accuracy')\n",
    "    plt.legend(title='Dataset')\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for dataset in results_df['Dataset'].unique():\n",
    "        df_subset = results_df[results_df['Dataset'] == dataset]\n",
    "        plt.scatter(df_subset['FPS'], df_subset['Test Acc'], \n",
    "                   label=dataset, s=100, alpha=0.7)\n",
    "        for _, row in df_subset.iterrows():\n",
    "            plt.annotate(row['Model'], \n",
    "                        (row['FPS'], row['Test Acc']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.xlabel('Speed (FPS)')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.title('Speed vs Accuracy')\n",
    "    plt.legend(title='Dataset')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/kaggle/working/model_dataset_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    plot_model_comparison_by_dataset(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b6e8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:32:57.393295Z",
     "iopub.status.busy": "2025-09-09T13:32:57.392786Z",
     "iopub.status.idle": "2025-09-09T13:32:59.882970Z",
     "shell.execute_reply": "2025-09-09T13:32:59.882195Z"
    },
    "papermill": {
     "duration": 3.682199,
     "end_time": "2025-09-09T13:32:59.890574",
     "exception": false,
     "start_time": "2025-09-09T13:32:56.208375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_training_stability(model_histories):\n",
    "    \"\"\"Analyze training curves for stability and convergence\"\"\"\n",
    "    if not model_histories:\n",
    "        print(\"No training histories available\")\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Loss stability \n",
    "    plt.subplot(2, 2, 1)\n",
    "    for model_name, history in model_histories.items():\n",
    "        if 'train_loss' in history:\n",
    "            plt.plot(history['train_loss'], label=f\"{model_name}\")\n",
    "    plt.title('Training Loss Convergence')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Validation loss stability\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for model_name, history in model_histories.items():\n",
    "        if 'val_loss' in history:\n",
    "            plt.plot(history['val_loss'], label=f\"{model_name}\")\n",
    "    plt.title('Validation Loss Convergence')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Accuracy progress\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for model_name, history in model_histories.items():\n",
    "        if 'train_acc' in history:\n",
    "            plt.plot(history['train_acc'], label=f\"{model_name}\")\n",
    "    plt.title('Training Accuracy Progress')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Validation accuracy progress\n",
    "    plt.subplot(2, 2, 4)\n",
    "    for model_name, history in model_histories.items():\n",
    "        if 'val_acc' in history:\n",
    "            plt.plot(history['val_acc'], label=f\"{model_name}\")\n",
    "    plt.title('Validation Accuracy Progress')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/kaggle/working/training_stability_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    print(\"\\nTraining Stability Analysis:\")\n",
    "    print(\"=\"*50)\n",
    "    for model_name, history in model_histories.items():\n",
    "        if 'train_loss' in history and 'val_loss' in history:\n",
    "            train_loss = history['train_loss']\n",
    "            val_loss = history['val_loss']\n",
    "            \n",
    "            if len(train_loss) > 0 and len(val_loss) > 0:\n",
    "                # Calculate generalization gap\n",
    "                min_len = min(len(train_loss), len(val_loss))\n",
    "                gen_gaps = [val_loss[i] - train_loss[i] for i in range(min_len)]\n",
    "                \n",
    "                print(f\"\\n{model_name}:\")\n",
    "                print(f\"  Final train/val loss gap: {gen_gaps[-1]:.4f}\")\n",
    "                print(f\"  Max train/val loss gap: {max(gen_gaps):.4f}\")\n",
    "                print(f\"  Epochs until min val loss: {val_loss.index(min(val_loss))+1}\")\n",
    "                \n",
    "                # Flag potential issues\n",
    "                if gen_gaps[-1] > 0.1:\n",
    "                    print(\"  Potential overfitting detected\")\n",
    "                if min(val_loss) > 0.5:\n",
    "                    print(\"  High validation loss - model may be underfitting\")\n",
    "\n",
    "if 'histories' in locals() and histories:\n",
    "    analyze_training_stability(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd39a40",
   "metadata": {
    "papermill": {
     "duration": 1.170577,
     "end_time": "2025-09-09T13:33:02.418053",
     "exception": false,
     "start_time": "2025-09-09T13:33:01.247476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Đánh giá model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb007acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:33:04.866803Z",
     "iopub.status.busy": "2025-09-09T13:33:04.866501Z",
     "iopub.status.idle": "2025-09-09T13:33:04.875441Z",
     "shell.execute_reply": "2025-09-09T13:33:04.874753Z"
    },
    "papermill": {
     "duration": 1.169114,
     "end_time": "2025-09-09T13:33:04.876511",
     "exception": false,
     "start_time": "2025-09-09T13:33:03.707397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/working/comprehensive_results.csv\")\n",
    "\n",
    "best_row = df.sort_values(\"Test Acc\", ascending=False).iloc[0]\n",
    "best_ckpt = best_row[\"Checkpoint\"]\n",
    "best_model_name = best_row[\"Model\"]\n",
    "best_acc = best_row[\"Test Acc\"]\n",
    "print(f\"Best model: {best_model_name} ({best_ckpt}), acc={best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de460ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:33:07.366850Z",
     "iopub.status.busy": "2025-09-09T13:33:07.366525Z",
     "iopub.status.idle": "2025-09-09T13:33:07.372506Z",
     "shell.execute_reply": "2025-09-09T13:33:07.371931Z"
    },
    "papermill": {
     "duration": 1.182733,
     "end_time": "2025-09-09T13:33:07.373656",
     "exception": false,
     "start_time": "2025-09-09T13:33:06.190923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    acc = np.mean(np.array(all_labels) == np.array(all_preds))\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb1c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:33:09.828825Z",
     "iopub.status.busy": "2025-09-09T13:33:09.828538Z",
     "iopub.status.idle": "2025-09-09T13:33:32.339516Z",
     "shell.execute_reply": "2025-09-09T13:33:32.338825Z"
    },
    "papermill": {
     "duration": 23.681514,
     "end_time": "2025-09-09T13:33:32.340618",
     "exception": false,
     "start_time": "2025-09-09T13:33:08.659104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = train_df[\"label_name\"].unique().tolist()\n",
    "\n",
    "def select_best_row(results_df: pd.DataFrame, key=\"F1\", dataset: str | None = None):\n",
    "    df = results_df if dataset is None else results_df[results_df[\"Dataset\"] == dataset]\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(f\"Không tìm thấy run nào cho dataset={dataset}\")\n",
    "    return df.loc[df[key].idxmax()]   # Series\n",
    "\n",
    "def load_model_from_row(best_row, models_dict, device):\n",
    "    model_name = best_row[\"Model\"]\n",
    "    ckpt_path  = best_row[\"Checkpoint\"]\n",
    "    if model_name not in models_dict:\n",
    "        raise KeyError(f\"'{model_name}' không có trong models_dict\")\n",
    "    model = models_dict[model_name]().to(device)\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    # hỗ trợ cả state_dict thuần và checkpoint dict\n",
    "    if isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "        model.load_state_dict(state[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model, ckpt_path\n",
    "\n",
    "def auto_load_best_model(results_csv, models_dict, device, key=\"F1\", dataset=None):\n",
    "    results_df = pd.read_csv(results_csv)\n",
    "    best_row = select_best_row(results_df, key=key, dataset=dataset)\n",
    "    print(f\"Best by {key}: {best_row['Model']} @ {best_row['Dataset']} ({best_row[key]:.4f})\")\n",
    "    model, ckpt = load_model_from_row(best_row, models_dict, device)\n",
    "    return model, best_row\n",
    "\n",
    "# ===== DÙNG =====\n",
    "results_csv = \"/kaggle/working/comprehensive_results.csv\"\n",
    "model_best, info = auto_load_best_model(results_csv, models_list, device, key=\"F1\", dataset=None)\n",
    "\n",
    "# Nếu bạn đã có sẵn test_loader + class_names:\n",
    "evaluate_model(model_best, test_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2ac26",
   "metadata": {
    "papermill": {
     "duration": 1.300226,
     "end_time": "2025-09-09T13:33:34.932568",
     "exception": false,
     "start_time": "2025-09-09T13:33:33.632342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92b88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:33:37.382273Z",
     "iopub.status.busy": "2025-09-09T13:33:37.381956Z",
     "iopub.status.idle": "2025-09-09T13:33:37.389743Z",
     "shell.execute_reply": "2025-09-09T13:33:37.389214Z"
    },
    "papermill": {
     "duration": 1.295737,
     "end_time": "2025-09-09T13:33:37.390793",
     "exception": false,
     "start_time": "2025-09-09T13:33:36.095056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_arch_from_path(ckpt_path: str) -> str:\n",
    "    \"\"\"Đoán tên kiến trúc từ tên file checkpoint.\"\"\"\n",
    "    base = os.path.basename(ckpt_path).lower()\n",
    "    mapping = {\n",
    "        \"resnet18\": \"ResNet18\",\n",
    "        \"resnet50\": \"ResNet50\",\n",
    "        \"mobilenetv2\": \"MobileNetV2\",\n",
    "        \"efficientnetb0\": \"EfficientNetB0\",\n",
    "        \"riceleafcnn\": \"RiceLeafCNN\",\n",
    "        \"simplecnn\": \"SimpleCNN\",\n",
    "    }\n",
    "    for k, v in mapping.items():\n",
    "        if k in base:\n",
    "            return v\n",
    "    raise ValueError(f\"Không suy luận được kiến trúc từ tên file: {base}\")\n",
    "\n",
    "def load_saved_model_by_ckpt(ckpt_path, models_dict, device, strict_head=\"auto\"):\n",
    "    \"\"\"\n",
    "    Khởi tạo đúng kiến trúc theo ckpt_path rồi load state_dict.\n",
    "    - models_dict: {\"ResNet18\": lambda: build_resnet18(num_classes), ...}\n",
    "    - strict_head=\"auto\": thử strict=True; nếu chỉ lỗi ở head thì fallback strict=False.\n",
    "    \"\"\"\n",
    "    arch = infer_arch_from_path(ckpt_path)\n",
    "    if arch not in models_dict:\n",
    "        raise KeyError(f\"'{arch}' không có trong models_dict\")\n",
    "\n",
    "    model = models_dict[arch]().to(device)\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    if isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "        state = state[\"model_state_dict\"]\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(state, strict=True)\n",
    "    except RuntimeError as e:\n",
    "        if strict_head == \"auto\":\n",
    "            print(f\"strict=True lỗi ({e.__class__.__name__}): thử strict=False (có thể sai head).\")\n",
    "            model.load_state_dict(state, strict=False)\n",
    "        else:\n",
    "            raise\n",
    "    model.eval()\n",
    "    return model, arch\n",
    "\n",
    "def ensure_save_dir_from_path(path: str) -> str:\n",
    "    \"\"\"Trả về thư mục hợp lệ để lưu file theo một 'path' (file hoặc folder).\"\"\"\n",
    "    if os.path.isdir(path):\n",
    "        save_dir = path\n",
    "    else:\n",
    "        save_dir = os.path.dirname(path) or \".\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    return save_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c75db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:33:39.886985Z",
     "iopub.status.busy": "2025-09-09T13:33:39.886699Z",
     "iopub.status.idle": "2025-09-09T13:33:39.906290Z",
     "shell.execute_reply": "2025-09-09T13:33:39.905717Z"
    },
    "papermill": {
     "duration": 1.210759,
     "end_time": "2025-09-09T13:33:39.907494",
     "exception": false,
     "start_time": "2025-09-09T13:33:38.696735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def demo_prediction_with_saved_model(checkpoint_path=\"../output\", dataset_path=\"data\", num_samples=6):\n",
    "    print(\"DEMO PREDICTION VỚI MODEL ĐÃ SAVE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    all_images = []\n",
    "    class_names = None\n",
    "    if not isinstance(dataset_path, pd.DataFrame):\n",
    "        raise TypeError(\"`dataset_path` phải là str/path hoặc pandas.DataFrame\")\n",
    "    df_in = dataset_path.copy()\n",
    "    if 'path' not in df_in.columns:\n",
    "        raise ValueError(\"DataFrame phải có cột 'path'.\")\n",
    "    label_col = None\n",
    "    if 'label_name' in df_in.columns:\n",
    "        label_col = 'label_name'\n",
    "    else:\n",
    "        for c in ['label', 'class', 'target', 'y', 'category']:\n",
    "            if c in df_in.columns:\n",
    "                label_col = c; break\n",
    "    has_label_id = 'label_id' in df_in.columns\n",
    "    if label_col is None and not has_label_id:\n",
    "        raise ValueError(\"Thiếu nhãn: cần 'label_name' hoặc 1 trong ['label','class','target','y','category'] hoặc 'label_id'.\")\n",
    "\n",
    "    if has_label_id and 'label_name' in df_in.columns:\n",
    "        id_name = df_in[['label_id','label_name']].drop_duplicates().sort_values('label_id')\n",
    "        class_names = id_name['label_name'].astype(str).tolist()\n",
    "        id_to_idx = {int(i): idx for idx, i in enumerate(id_name['label_id'].tolist())}\n",
    "        for _, row in df_in.iterrows():\n",
    "            img_path = str(row['path'])\n",
    "            if os.path.isfile(img_path) and img_path.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                lid = int(row['label_id'])\n",
    "                if lid in id_to_idx:\n",
    "                    all_images.append({\n",
    "                        'path': img_path,\n",
    "                        'true_label': str(row['label_name']),\n",
    "                        'true_label_idx': id_to_idx[lid],\n",
    "                    })\n",
    "    elif has_label_id and label_col is None:\n",
    "        uniq_ids = sorted(set(int(x) for x in df_in['label_id'].tolist()))\n",
    "        class_names = [str(i) for i in uniq_ids]\n",
    "        id_to_idx = {i: idx for idx, i in enumerate(uniq_ids)}\n",
    "        for _, row in df_in.iterrows():\n",
    "            img_path = str(row['path'])\n",
    "            if os.path.isfile(img_path) and img_path.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                lid = int(row['label_id'])\n",
    "                if lid in id_to_idx:\n",
    "                    all_images.append({\n",
    "                        'path': img_path,\n",
    "                        'true_label': str(lid),\n",
    "                        'true_label_idx': id_to_idx[lid],\n",
    "                    })\n",
    "    else:\n",
    "        labels_series = df_in[label_col].astype(str)\n",
    "        class_names = sorted(labels_series.unique().tolist())\n",
    "        class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "        for _, row in df_in.iterrows():\n",
    "            img_path = str(row['path'])\n",
    "            if os.path.isfile(img_path) and img_path.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                name = str(row[label_col])\n",
    "                all_images.append({\n",
    "                    'path': img_path,\n",
    "                    'true_label': name,\n",
    "                    'true_label_idx': class_to_idx[name],\n",
    "                })\n",
    "\n",
    "    if len(all_images) == 0:\n",
    "        raise RuntimeError(\"❌ Không tìm thấy ảnh nào để test!\")\n",
    "    print(f\"Tìm thấy {len(all_images)} ảnh. Số lớp: {len(class_names)} -> {class_names}\")\n",
    "    models_dict = {\n",
    "        \"SimpleCNN\":      lambda: SimpleCNN(len(class_names)),\n",
    "        \"RiceLeafCNN\":    lambda: RiceLeafCNN(len(class_names)),\n",
    "        \"ResNet18\":       lambda: build_resnet18(len(class_names)),\n",
    "        \"ResNet50\":       lambda: build_resnet50(len(class_names)),\n",
    "        \"EfficientNetB0\": lambda: build_efficientnet(len(class_names)),\n",
    "        \"MobileNetV2\":    lambda: build_mobilenet(len(class_names)),\n",
    "    }\n",
    "    model, model_name = load_saved_model_by_ckpt(\n",
    "        ckpt_path=checkpoint_path,\n",
    "        models_dict=models_dict,\n",
    "        device=device,\n",
    "        strict_head=\"auto\",\n",
    "    )\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    random_images = random.sample(all_images, min(num_samples, len(all_images)))\n",
    "    rows = 2 if len(random_images) > 3 else 1\n",
    "    cols = min(3, len(random_images))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    if hasattr(axes, \"ravel\"):\n",
    "        axes = axes.ravel()\n",
    "    else:\n",
    "        axes = [axes]\n",
    "\n",
    "    total_time = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for idx, img_info in enumerate(random_images):\n",
    "        img_path = img_info['path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "        end_time = time.time()\n",
    "\n",
    "        inference_time = end_time - start_time\n",
    "        total_time += inference_time\n",
    "\n",
    "        predicted_idx = predicted.item()\n",
    "        predicted_class = class_names[predicted_idx]\n",
    "        confidence_score = float(confidence.item())\n",
    "        true_class = img_info['true_label']\n",
    "        is_correct = (str(predicted_class) == str(true_class))\n",
    "        if is_correct:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(\n",
    "            f\"True: {true_class}\\nPred: {predicted_class}\\n\"\n",
    "            f\"Conf: {confidence_score:.3f}\\n\"\n",
    "            f\"Time: {inference_time*1000:.1f}ms\",\n",
    "            fontsize=10\n",
    "        )\n",
    "        ax.axis('off')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('green' if is_correct else 'red')\n",
    "            spine.set_linewidth(3)\n",
    "\n",
    "        status = \"đúng\" if is_correct else \"sai\"\n",
    "        print(f\"{os.path.basename(img_path)} | True: {true_class} | Pred: {predicted_class} \"\n",
    "              f\"| {confidence_score:.4f} | {inference_time*1000:.2f}ms | {status}\")\n",
    "\n",
    "    # Ẩn subplot thừa\n",
    "    for j in range(len(random_images), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    plt.suptitle(f'Random Prediction Demo - {model_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    # Lưu ảnh DEMO vào đúng thư mục \n",
    "    save_dir = ensure_save_dir_from_path(checkpoint_path)\n",
    "    out_img = os.path.join(save_dir, \"demo_predictions.png\")\n",
    "    plt.savefig(out_img, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    #  Summary \n",
    "    accuracy = correct_predictions / len(random_images)\n",
    "    avg_time = total_time / len(random_images)\n",
    "    fps = len(random_images) / total_time if total_time > 0 else float('inf')\n",
    "\n",
    "    print(\"DEMO SUMMARY:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {correct_predictions}/{len(random_images)} ({accuracy*100:.1f}%)\")\n",
    "    print(f\"Avg Time: {avg_time*1000:.2f}ms/image\")\n",
    "    print(f\"Speed: {fps:.1f} FPS\")\n",
    "    print(f\"Saved preview: {out_img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19316599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T13:33:42.400213Z",
     "iopub.status.busy": "2025-09-09T13:33:42.399905Z",
     "iopub.status.idle": "2025-09-09T13:33:58.574189Z",
     "shell.execute_reply": "2025-09-09T13:33:58.573489Z"
    },
    "papermill": {
     "duration": 17.381267,
     "end_time": "2025-09-09T13:33:58.607380",
     "exception": false,
     "start_time": "2025-09-09T13:33:41.226113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_prediction_with_saved_model(\n",
    "    checkpoint_path=best_ckpt,   \n",
    "    dataset_path=df_test,\n",
    "    num_samples=6\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 193945,
     "sourceId": 796736,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 522658,
     "sourceId": 959791,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1723926,
     "sourceId": 2819304,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2252401,
     "sourceId": 3770935,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4245440,
     "sourceId": 7316033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5461696,
     "sourceId": 9057601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8158738,
     "sourceId": 12895000,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8190451,
     "sourceId": 12942672,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8215465,
     "sourceId": 12979682,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 443445,
     "modelInstanceId": 425959,
     "sourceId": 562948,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20868.882219,
   "end_time": "2025-09-09T13:34:02.901041",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-09T07:46:14.018822",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
