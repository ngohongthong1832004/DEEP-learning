{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72189e-8fee-47dc-8f1d-0a5a5c82ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image_type(img_path, edge_threshold=0.15):\n",
    "    \"\"\"\n",
    "    Detect if image is single leaf or rice plant cluster\n",
    "    \n",
    "    Strategy:\n",
    "    - Single leaf: Usually centered, edges are clear background\n",
    "    - Cluster/plant: Complex, multiple objects, edges have content\n",
    "    \n",
    "    Returns: 'single_leaf' or 'cluster'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return 'unknown'\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        h, w = gray.shape\n",
    "        \n",
    "        # Check edge density (if edges have little content → single leaf)\n",
    "        edge_width = int(w * 0.1)  # 10% from each edge\n",
    "        edge_height = int(h * 0.1)\n",
    "        \n",
    "        # Extract edge regions\n",
    "        top_edge = gray[:edge_height, :]\n",
    "        bottom_edge = gray[h-edge_height:, :]\n",
    "        left_edge = gray[:, :edge_width]\n",
    "        right_edge = gray[:, w-edge_width:]\n",
    "        \n",
    "        # Calculate edge density using standard deviation\n",
    "        # Low std → uniform background → single leaf\n",
    "        # High std → complex content → cluster\n",
    "        edge_std = np.mean([\n",
    "            np.std(top_edge),\n",
    "            np.std(bottom_edge),\n",
    "            np.std(left_edge),\n",
    "            np.std(right_edge)\n",
    "        ])\n",
    "        \n",
    "        center_std = np.std(gray[edge_height:h-edge_height, edge_width:w-edge_width])\n",
    "        \n",
    "        # If edge is much simpler than center → single leaf\n",
    "        if center_std > 0:\n",
    "            edge_ratio = edge_std / center_std\n",
    "            if edge_ratio < edge_threshold:\n",
    "                return 'single_leaf'\n",
    "        \n",
    "        return 'cluster'\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error detecting type for {img_path}: {e}\")\n",
    "        return 'unknown'\n",
    "\n",
    "def create_pseudo_labels_for_cluster(img_path, label_id):\n",
    "    \"\"\"\n",
    "    For cluster images, create pseudo bounding boxes using image processing\n",
    "    \n",
    "    Strategy:\n",
    "    1. Use color-based segmentation to find green regions (leaves)\n",
    "    2. Find contours and create bounding boxes\n",
    "    3. Filter small/noisy detections\n",
    "    \n",
    "    Returns: List of (class_id, x_center, y_center, width, height) normalized\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return []\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img_rgb.shape[:2]\n",
    "        \n",
    "        # Convert to HSV for better green detection\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Define range for green color (leaves)\n",
    "        lower_green = np.array([25, 30, 30])\n",
    "        upper_green = np.array([90, 255, 255])\n",
    "        \n",
    "        mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        \n",
    "        # Morphological operations to clean up\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        bboxes = []\n",
    "        min_area = (w * h) * 0.01  # At least 1% of image\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area < min_area:\n",
    "                continue\n",
    "            \n",
    "            x, y, box_w, box_h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Skip very thin boxes (noise)\n",
    "            aspect_ratio = box_w / box_h if box_h > 0 else 0\n",
    "            if aspect_ratio < 0.1 or aspect_ratio > 10:\n",
    "                continue\n",
    "            \n",
    "            # Normalize to YOLO format\n",
    "            x_center = (x + box_w / 2) / w\n",
    "            y_center = (y + box_h / 2) / h\n",
    "            norm_w = box_w / w\n",
    "            norm_h = box_h / h\n",
    "            \n",
    "            bboxes.append((label_id, x_center, y_center, norm_w, norm_h))\n",
    "        \n",
    "        # If no boxes found, fall back to full image\n",
    "        if len(bboxes) == 0:\n",
    "            bboxes = [(label_id, 0.5, 0.5, 1.0, 1.0)]\n",
    "        \n",
    "        return bboxes\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error creating pseudo labels for {img_path}: {e}\")\n",
    "        return [(label_id, 0.5, 0.5, 1.0, 1.0)]  # Fallback\n",
    "\n",
    "def prepare_field_dataset(df, output_dir, val_size=0.15, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Prepare dataset with SMART LABELING:\n",
    "    - Single leaf images: Use full-image bbox (valid assumption)\n",
    "    - Cluster images: Use pseudo-labels from image processing\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n\" + \"=\"*60)\n",
    "    logging.info(\"SMART DATASET PREPARATION\")\n",
    "    logging.info(\"=\"*60)\n",
    "    logging.info(\"Strategy:\")\n",
    "    logging.info(\"  • Single leaf images → Full-image bbox\")\n",
    "    logging.info(\"  • Cluster images → Pseudo-labels from segmentation\")\n",
    "    \n",
    "    trainval_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, random_state=42, stratify=df['label_id']\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        trainval_df, test_size=val_size/(1-test_size), random_state=42,\n",
    "        stratify=trainval_df['label_id']\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"\\nTrain: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    logging.info(f\"Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "    logging.info(f\"Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    field_data = {'train': [], 'val': [], 'test': []}\n",
    "    type_stats = {'single_leaf': 0, 'cluster': 0, 'unknown': 0}\n",
    "    \n",
    "    for split, split_df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
    "        split_dir = os.path.join(output_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        logging.info(f\"\\nProcessing {split}...\")\n",
    "        \n",
    "        for idx, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f\"Preparing {split}\"):\n",
    "            src = row['image_path']\n",
    "            dst = os.path.join(split_dir, f\"{split}_{idx:06d}.jpg\")\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(src, dst)\n",
    "                \n",
    "                # Detect image type\n",
    "                img_type = detect_image_type(src)\n",
    "                type_stats[img_type] = type_stats.get(img_type, 0) + 1\n",
    "                \n",
    "                label_file = os.path.join(split_dir, f\"{split}_{idx:06d}.txt\")\n",
    "                \n",
    "                if img_type == 'single_leaf':\n",
    "                    # Single leaf: Use full-image bbox (valid for centered single leaf)\n",
    "                    with open(label_file, 'w') as f:\n",
    "                        f.write(f\"{row['label_id']} 0.5 0.5 1.0 1.0\\n\")\n",
    "                else:\n",
    "                    # Cluster or unknown: Use pseudo-labels\n",
    "                    bboxes = create_pseudo_labels_for_cluster(src, row['label_id'])\n",
    "                    with open(label_file, 'w') as f:\n",
    "                        for bbox in bboxes:\n",
    "                            class_id, x_c, y_c, w, h = bbox\n",
    "                            f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "                \n",
    "                field_data[split].append({\n",
    "                    'image_path': dst,\n",
    "                    'label_path': label_file,\n",
    "                    'label_name': row['label_name'],\n",
    "                    'label_id': row['label_id'],\n",
    "                    'image_type': img_type\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Error: {e}\")\n",
    "    \n",
    "    logging.info(f\"\\n{'='*60}\")\n",
    "    logging.info(\"Image Type Statistics:\")\n",
    "    logging.info(f\"  Single Leaf: {type_stats.get('single_leaf', 0)} \"\n",
    "                f\"({type_stats.get('single_leaf', 0)/len(df)*100:.1f}%)\")\n",
    "    logging.info(f\"  Cluster:     {type_stats.get('cluster', 0)} \"\n",
    "                f\"({type_stats.get('cluster', 0)/len(df)*100:.1f}%)\")\n",
    "    logging.info(f\"  Unknown:     {type_stats.get('unknown', 0)} \"\n",
    "                f\"({type_stats.get('unknown', 0)/len(df)*100:.1f}%)\")\n",
    "    logging.info(f\"{'='*60}\")\n",
    "    \n",
    "    # Save statistics\n",
    "    stats_df = pd.DataFrame([type_stats])\n",
    "    stats_df.to_csv(os.path.join(output_dir, 'image_type_stats.csv'), index=False)\n",
    "    \n",
    "    return field_data\n",
    "\n",
    "def create_yolo_yaml(data_root, output_path):\n",
    "    import yaml\n",
    "    yaml_data = {\n",
    "        'path': str(Path(data_root).absolute()),\n",
    "        'train': 'train', 'val': 'val', 'test': 'test',\n",
    "        'nc': len(LABELS),\n",
    "        'names': [LABELS[i]['name'] for i in sorted(LABELS.keys())]\n",
    "    }\n",
    "    yaml_path = os.path.join(output_path, \"data.yaml\")\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "    logging.info(f\"Created data.yaml: {yaml_path}\")\n",
    "    return yaml_path\n",
    "\n",
    "field_data = prepare_field_dataset(\n",
    "    collected_df, OUTPUT_DIRS[\"field_images\"], \n",
    "    val_size=CONFIG['val_size'], test_size=CONFIG['test_size']\n",
    ")\n",
    "yaml_path = create_yolo_yaml(OUTPUT_DIRS[\"field_images\"], OUTPUT_DIRS[\"field_images\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37705bd4-7ed3-44fb-b275-fcf3ff619352",
   "metadata": {},
   "source": [
    " ## PHASE 3: YOLO Training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
