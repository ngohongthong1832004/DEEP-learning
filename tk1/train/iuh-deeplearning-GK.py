# %% [markdown]
# ## Import th∆∞ vi·ªán GK

# %%
try:
    from torch.amp import GradScaler, autocast
    _NEW_AMP = True
except Exception:
    from torch.cuda.amp import GradScaler, autocast
    _NEW_AMP = False

from torchvision.models import (
    resnet18, ResNet18_Weights,
    resnet50, ResNet50_Weights,
    efficientnet_b0, EfficientNet_B0_Weights,
    mobilenet_v2, MobileNet_V2_Weights,
)
import torchvision.transforms as T
import torch.nn.functional as F
import torchvision.datasets as dsets

# %%
import os, re, shutil, random, pathlib, cv2, torch, gc, time, math 
import pandas as pd
import numpy as np 
import seaborn as sns
import matplotlib.pyplot as plt
import logging
from collections import defaultdict
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
from torchvision import transforms
from torch.utils.data import Dataset
from PIL import Image
from torch.utils.data import DataLoader
from contextlib import nullcontext

import torch.nn as nn
import torch.optim as optim
from torchvision import models
from typing import Dict, Tuple

from tqdm import tqdm
from contextlib import nullcontext

# %%
# Vi·∫øt cho t√¥i path output theo ngay th√°ng nƒÉm gi·ªù ph√∫t gi√¢y
from datetime import datetime
def get_output_folder(parent_dir: str, env_name: str) -> str:
    """Returns unique output
    folder name based on parent_dir, env_name, and current time.
    """
    os.makedirs(parent_dir, exist_ok=True)
    experiment_id = f"{env_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}"
    output_dir = os.path.join(parent_dir, experiment_id)
    os.makedirs(output_dir, exist_ok=True)
    return output_dir
# ## Import th∆∞ vi·ªán GK


PATH_OUTPUT = get_output_folder("../output", "iuh-deeplearning-GK")

# Create organized output folder structure
def create_output_structure(base_path):
    """Create organized folder structure for outputs"""
    folders = [
        "checkpoints",      # Model checkpoints
        "results",          # CSV results, metrics
        "plots",            # All plots and visualizations  
        "modeltraining",    # Training curves
        "clahe",            # CLAHE processed images
        "rice_dataset",     # Organized dataset
        "demos"             # Demo predictions
    ]
    
    for folder in folders:
        folder_path = os.path.join(base_path, folder)
        os.makedirs(folder_path, exist_ok=True)
    
    logging.info(f"‚úÖ Created output structure in: {base_path}")
    for folder in folders:
        logging.info(f"   üìÅ {folder}/")
    
    return {folder: os.path.join(base_path, folder) for folder in folders}

# Create the organized structure
OUTPUT_DIRS = create_output_structure(PATH_OUTPUT)

# Setup logging
def setup_logging(output_path):
    """Setup logging configuration with both file and console handlers"""
    log_file = os.path.join(output_path, "experiment.log")
    
    # Create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Setup root logger
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # Clear existing handlers
    logger.handlers.clear()
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # File handler
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    logging.info(f"üìù Logging initialized. Log file: {log_file}")
    return logger

# Initialize logging
logger = setup_logging(PATH_OUTPUT)

# %% [markdown]
# ## Chu·∫©n b·ªã d·ªØ li·ªáu

# %%
# 0: brown spot (ƒê·ªëm n√¢u)
# 01: leaf blast (ƒê·∫°o √¥n)
# 02: leaf blight (Ch√°y l√°)
# 03: normal (b√¨nh th∆∞·ªùng)

LABELS = {
    0: {
        "name": "brown_spot",
        "match_substrings": [
            "../data/rice-disease-dataset/Rice_Leaf_AUG/Brown Spot",
            "../data/rice-leaf-disease-image/Brownspot",
            "../data/rice-leaf-diseases/rice_leaf_diseases/Brown spot",
            "../data/rice-leafs-disease-dataset/RiceLeafsDisease/train/brown_spot",
            "../data/rice-leaf-images/rice_images/_BrownSpot",
            "../data/rice-diseases-image-dataset/RiceDiseaseDataset/train/BrownSpot",
        ]
    },
    1: {
        "name": "leaf_blast",
        "match_substrings": [
            "../data/rice-disease-dataset/Rice_Leaf_AUG/Leaf Blast",
            "../data/rice-leafs-disease-dataset/RiceLeafsDisease/train/leaf_blast",
            "../data/rice-leaf-images/rice_images/_LeafBlast",
            "../data/rice-diseases-image-dataset/RiceDiseaseDataset/train/LeafBlast",

        ]
    },
    2: {
        "name": "leaf_blight",
        "match_substrings": [
            "../data/rice-disease-dataset/Rice_Leaf_AUG/Sheath Blight",
            "../data/rice-leaf-diseases/rice_leaf_diseases/Bacterial leaf blight",
            "../data/rice-leaf-disease-image/Bacterialblight",
            "../data/rice-leafs-disease-dataset/RiceLeafsDisease/train/bacterial_leaf_blight",
        ]
    },
    3: {
        "name": "healthy",
        "match_substrings": [
            "../data/rice-disease-dataset/Rice_Leaf_AUG/Healthy Rice Leaf",
            "../data/rice-leafs-disease-dataset/RiceLeafsDisease/train/healthy",
            "../data/rice-leaf-images/rice_images/_Healthy",
            "../data/rice-diseases-image-dataset/RiceDiseaseDataset/train/Healthy",
        ]
    }
}

DATASET_SOURCES = {
    "rice-disease-dataset": "dataset_1",
    "rice-leaf-disease-image": "dataset_2",
    "rice-leaf-diseases": "dataset_3", 
    "rice-leafs-disease-dataset": "dataset_4",
    "rice-leaf-images": "dataset_5",
    "rice-diseases-image-dataset": "dataset_6"
}

LABELS_TEST = {
    0: {
        "name": "brown_spot",
        "match_substrings": [
            "../data/data_test/Rice Leaf Bacterial and Fungal Disease Dataset/Original/Original Images/Original Images/Brown Spot"
        ]
    },
    1: {
        "name": "leaf_blast",
        "match_substrings": [
            "../data/data_test/Rice Leaf Bacterial and Fungal Disease Dataset/Original/Original Images/Original Images/Leaf Blast",
        ]
    },
    2: {
        "name": "leaf_blight",
        "match_substrings": [
            "../data/data_test/Rice Leaf Bacterial and Fungal Disease Dataset/Original/Original Images/Original Images/Bacterial Leaf Blight",
        ]
    },
    3: {
        "name": "healthy",
        "match_substrings": [
            "../data/data_test/Rice Leaf Bacterial and Fungal Disease Dataset/Original/Original Images/Original Images/Healthy Rice Leaf",
        ]
    }
}

DATASET_SOURCES_TEST = {
    "mendeley-rice-disease-dataset": "dataset_7"
}

# %% [markdown]
# ### Thu th·∫≠p ·∫£nh ch·ªâ t·ª´ c√°c ƒë∆∞·ªùng d·∫´n kh·ªõp
# 

# %%
ALL_SUBS = []
for lid, info in LABELS.items():
    # print(lid, info)
    # print(info["match_substrings"])
    for s in info["match_substrings"]:
        for src, src_id in DATASET_SOURCES.items():
            if src in s:
                ALL_SUBS.append((lid, info["name"], s, src_id))

ALL_SUBS_TEST = []
for lid, info in LABELS_TEST.items():
    for s in info["match_substrings"]:
        for src, src_id in DATASET_SOURCES_TEST.items():
            if src in s:
                ALL_SUBS_TEST.append((lid, info["name"], s, src_id))

# %%
for i in ALL_SUBS:
    print(i)

# %%
for i in ALL_SUBS_TEST:
    print(i)

# %%
def load_image_class(image_dir):
    logging.info(f"Loading images from: {image_dir}")
    image_dirs = os.listdir(image_dir)
    images_path = []
    for file in image_dirs:
        if file.endswith('.jpg') or file.endswith('.JPG'):
            image_path = os.path.join(image_dir, file)
            images_path.append(image_path)
    logging.info(f"Found {len(image_dirs)} files, {len(images_path)} valid images")
    return images_path

# %%
df = pd.DataFrame(columns=['path', 'label_id', 'label_name', 'dataset_source'])
df_test = pd.DataFrame(columns=['path', 'label_id', 'label_name', 'dataset_source'])
 
for abel_id, class_name, path, dataset_tag in ALL_SUBS:
    logging.info(f"Processing: {abel_id} - {class_name} from {dataset_tag}")
    images_path = load_image_class(path)
    for image_path in images_path:
        new_row = pd.DataFrame([[image_path, abel_id, class_name, dataset_tag]]                     
                             , columns=df.columns)
        df = pd.concat([df, new_row], ignore_index=True)

# %%
for abel_id, class_name, path, dataset_tag in ALL_SUBS_TEST:
    logging.info(f"Processing test data: {abel_id} - {class_name} from {dataset_tag}")
    images_path = load_image_class(path)
    for image_path in images_path:
        new_row = pd.DataFrame([[image_path, abel_id, class_name, dataset_tag]]                     
                             , columns=df_test.columns)
        df_test = pd.concat([df_test, new_row], ignore_index=True)

# %%
df

# %%
df_test

# %%
logging.info(f"T·ªïng s·ªë ·∫£nh test extend l·∫•y ƒë∆∞·ª£c: {len(df_test)}")
logging.info(f"Ph√¢n b·ªë test data theo label:\n{df_test.groupby(['label_id','label_name']).size()}")
logging.info(f"Ph√¢n b·ªë test data theo ngu·ªìn:\n{df_test.groupby(['dataset_source', 'label_name']).size()}")

# %%
logging.info(f"T·ªïng s·ªë ·∫£nh l·∫•y ƒë∆∞·ª£c: {len(df)}")
logging.info(f"Ph√¢n b·ªë d·ªØ li·ªáu theo label:\n{df.groupby(['label_id','label_name']).size()}")
logging.info(f"Ph√¢n b·ªë d·ªØ li·ªáu theo ngu·ªìn:\n{df.groupby(['dataset_source', 'label_name']).size()}")

# %% [markdown]
# ## Visualization

# %%
def plot_label_counts(df, name, ax):
    """Plot label counts with error handling for empty datasets"""
    if df.empty or len(df) == 0:
        ax.text(0.5, 0.5, f"No data available for {name}", 
                ha='center', va='center', transform=ax.transAxes, fontsize=12)
        ax.set_title(f"S·ªë l∆∞·ª£ng ·∫£nh theo t·ª´ng nh√£n b·ªánh\n{name} tr√™n l√° l√∫a")
        logging.warning(f"No data available for plotting {name}")
        return
    
    if "label_name" not in df.columns or "path" not in df.columns:
        ax.text(0.5, 0.5, f"Missing required columns for {name}", 
                ha='center', va='center', transform=ax.transAxes, fontsize=12)
        ax.set_title(f"S·ªë l∆∞·ª£ng ·∫£nh theo t·ª´ng nh√£n b·ªánh\n{name} tr√™n l√° l√∫a")
        logging.error(f"Missing required columns (label_name, path) for {name}")
        return
    
    label_counts = df.groupby("label_name")["path"].count().sort_values(ascending=False)
    
    if len(label_counts) == 0:
        ax.text(0.5, 0.5, f"No labels found for {name}", 
                ha='center', va='center', transform=ax.transAxes, fontsize=12)
        ax.set_title(f"S·ªë l∆∞·ª£ng ·∫£nh theo t·ª´ng nh√£n b·ªánh\n{name} tr√™n l√° l√∫a")
        logging.warning(f"No labels found for plotting {name}")
        return
    
    try:
        label_counts.plot(kind="bar", ax=ax)
        ax.set_title(f"S·ªë l∆∞·ª£ng ·∫£nh theo t·ª´ng nh√£n b·ªánh\n{name} tr√™n l√° l√∫a")
        ax.set_xlabel("Label (T√™n b·ªánh)")
        ax.set_ylabel("S·ªë l∆∞·ª£ng ·∫£nh")
        ax.set_xticklabels(label_counts.index, rotation=45, ha="right")
        logging.info(f"Successfully plotted label counts for {name}")
    except Exception as e:
        ax.text(0.5, 0.5, f"Error plotting {name}: {str(e)}", 
                ha='center', va='center', transform=ax.transAxes, fontsize=10)
        ax.set_title(f"S·ªë l∆∞·ª£ng ·∫£nh theo t·ª´ng nh√£n b·ªánh\n{name} tr√™n l√° l√∫a")
        logging.error(f"Error plotting {name}: {e}")
# Safe plotting with error handling
try:
    fig, axes = plt.subplots(1, 2, figsize=(16,6), sharey=True)
    
    # Check if datasets exist before plotting
    if 'df' in locals() and not df.empty:
        plot_label_counts(df, "Dataset Train/Val", axes[0])
    else:
        axes[0].text(0.5, 0.5, "Main dataset (df) not available", 
                    ha='center', va='center', transform=axes[0].transAxes)
        axes[0].set_title("Dataset Train/Val - No Data")
        logging.warning("Main dataset (df) not available for plotting")
    
    if 'df_test' in locals() and not df_test.empty:
        plot_label_counts(df_test, "Dataset Test", axes[1])
    else:
        axes[1].text(0.5, 0.5, "Test dataset (df_test) not available", 
                    ha='center', va='center', transform=axes[1].transAxes)
        axes[1].set_title("Dataset Test - No Data")
        logging.warning("Test dataset (df_test) not available for plotting")
    
    plt.tight_layout()
    plt.show()
    
except Exception as e:
    logging.error(f"Error creating label count plots: {e}")
    print(f"Error in visualization: {e}")

# %%
def visualize_by_source(df, num_samples=2, img_size=(128,128), ncols=4):
    """Visualize samples by data source with comprehensive error handling"""
    if df.empty or len(df) == 0:
        logging.warning("DataFrame is empty, cannot visualize by source")
        return
    
    if 'dataset_source' not in df.columns:
        logging.error("Column 'dataset_source' not found in DataFrame")
        return
    
    if 'label_name' not in df.columns:
        logging.error("Column 'label_name' not found in DataFrame") 
        return
    
    if 'path' not in df.columns:
        logging.error("Column 'path' not found in DataFrame")
        return
        
    sources = sorted(df['dataset_source'].dropna().unique())
    
    if len(sources) == 0:
        logging.warning("No data sources found in DataFrame")
        return
        
    logging.info(f"Visualizing samples from {len(sources)} sources: {sources}")
    
    for source in sources:
        source_df = df[df['dataset_source'] == source]
        if len(source_df) == 0:
            logging.warning(f"No data found for source: {source}")
            continue

        unique_labels = sorted(source_df['label_name'].dropna().unique())
        if len(unique_labels) == 0:
            continue
        samples_all = []
        for label_name in unique_labels:
            label_imgs = source_df[source_df['label_name'] == label_name]['path'].values
            if len(label_imgs) == 0:
                continue
            samples = np.random.choice(label_imgs, 
                                       min(num_samples, len(label_imgs)), 
                                       replace=False)
            for img_path in samples:
                samples_all.append((img_path, label_name))

        if len(samples_all) == 0:
            continue

        nrows = math.ceil(len(samples_all) / ncols)
        plt.figure(figsize=(ncols*3, nrows*3))
        plt.suptitle(f"Samples data prepare train from {source}", fontsize=16)

        for idx, (img_path, label_name) in enumerate(samples_all):
            plt.subplot(nrows, ncols, idx+1)
            try:
                img = Image.open(img_path).convert("RGB")
                img = img.resize(img_size)
                plt.imshow(img)
                plt.title(label_name, fontsize=10)
                plt.axis('off')
            except Exception as e:
                plt.text(0.5, 0.5, "Error", ha='center', va='center')
                plt.axis('off')

        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.show()


# %%
# Safe visualization with error handling
try:
    if 'df' in locals() and not df.empty:
        logging.info("Visualizing training/validation data by source")
        visualize_by_source(df)
    else:
        logging.warning("Main dataset (df) not available for source visualization")
except Exception as e:
    logging.error(f"Error visualizing training data by source: {e}")

# %%
try:
    if 'df_test' in locals() and not df_test.empty:
        logging.info("Visualizing test data by source")
        visualize_by_source(df_test)
    else:
        logging.warning("Test dataset (df_test) not available for source visualization")
except Exception as e:
    logging.error(f"Error visualizing test data by source: {e}")

# %%
# Safe pivot table creation and visualization
try:
    if 'df' in locals() and not df.empty and 'dataset_source' in df.columns and 'label_name' in df.columns:
        df_stat = df.groupby(["dataset_source", "label_name"]).size().reset_index(name="Count")
        
        if len(df_stat) > 0:
            pivot_df = df_stat.pivot_table(
                index="label_name", 
                columns="dataset_source", 
                values="Count", 
                aggfunc="sum",
                fill_value=0
            )
            logging.info(f"Created pivot table with shape: {pivot_df.shape}")
            logging.info(f"Pivot table:\n{pivot_df}")
        else:
            logging.warning("No data available for pivot table creation")
            pivot_df = pd.DataFrame()
    else:
        logging.warning("Required data not available for pivot table")
        pivot_df = pd.DataFrame()
        
except Exception as e:
    logging.error(f"Error creating pivot table: {e}")
    pivot_df = pd.DataFrame()

# %%
try:
    if not pivot_df.empty and 'DATASET_SOURCES' in locals():
        REVERSE_SOURCES = {v: k for k, v in DATASET_SOURCES.items()}
        pivot_df_renamed = pivot_df.rename(columns=REVERSE_SOURCES)
        
        ax = pivot_df_renamed.plot(
            kind="bar",
            stacked=True,
            figsize=(10, 6),
            colormap="Set2"
        )

        plt.title("S·ªë l∆∞·ª£ng ·∫£nh theo nh√£n b·ªánh v√† ngu·ªìn d·ªØ li·ªáu", fontsize=14)
        plt.xlabel("Nh√£n b·ªánh (Label)", fontsize=12)
        plt.ylabel("S·ªë l∆∞·ª£ng ·∫£nh", fontsize=12)

        plt.legend(title="Ngu·ªìn d·ªØ li·ªáu", loc="center left", bbox_to_anchor=(1.02, 0.5))
        plt.xticks(rotation=0)

        for container in ax.containers:
            ax.bar_label(container, label_type="center", fontsize=9)

        plt.tight_layout()
        plt.show()
        logging.info("Successfully created stacked bar chart")
    else:
        logging.warning("Cannot create stacked bar chart - no data or missing DATASET_SOURCES")
        
except Exception as e:
    logging.error(f"Error creating stacked bar chart: {e}")


# %% [markdown]
# ### Chia train/val/test

# %%
def split_df(df, seed=42, test_size=0.2, val_size=0.2):
    df_trainval, df_test = train_test_split(
        df,
        test_size=test_size,
        random_state=seed,
        stratify=df['label_id'] if 'label_id' in df.columns else None
    )
    df_train, df_val = train_test_split(
        df_trainval,
        test_size=val_size,
        random_state=seed,
        stratify=df_trainval['label_id'] if 'label_id' in df_trainval.columns else None
    )
    train_df = df_train.assign(split="train").reset_index(drop=True)
    val_df   = df_val.assign(split="val").reset_index(drop=True)
    test_df  = df_test.assign(split="test").reset_index(drop=True)

    return pd.concat([train_df, val_df, test_df], ignore_index=True)

def create_filtered_datasets(df, sources=None, test_size=0.2, val_size=0.2, seed=42):
    if sources is not None:
        filtered_df = df[df['dataset_source'].isin(sources)].copy()
    else:
        filtered_df = df.copy()

    if len(filtered_df) == 0:
        logging.warning(f"No data found for sources {sources}")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    split_df_result = split_df(filtered_df, seed=seed, test_size=test_size, val_size=val_size)

    train_df = split_df_result[split_df_result["split"] == "train"].reset_index(drop=True)
    val_df   = split_df_result[split_df_result["split"] == "val"].reset_index(drop=True)
    test_df  = split_df_result[split_df_result["split"] == "test"].reset_index(drop=True)

    source_str = "+".join(sources) if sources else "all_sources"
    logging.info(f"Dataset sources: {source_str}")
    logging.info(f"Split sizes: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}")

    return train_df, val_df, test_df

# %%
# Safe data splitting with error handling
try:
    if 'df' in locals() and not df.empty:
        df_split = split_df(df, seed=42)
        logging.info(f"Data split distribution:\n{df_split.groupby(['split','label_id','label_name']).size()}")
    else:
        logging.error("Main dataset (df) not available for splitting")
        # Create empty dataframe to prevent further errors
        df_split = pd.DataFrame()
        
except Exception as e:
    logging.error(f"Error splitting data: {e}")
    df_split = pd.DataFrame()

# %%
# Safe split visualization
try:
    if not df_split.empty and len(df_split) > 0:
        split_counts = df_split.groupby(["split", "label_name"])["path"].count().unstack(fill_value=0)
        
        if not split_counts.empty:
            split_counts.plot(kind="bar", figsize=(12,6))
            plt.title("S·ªë l∆∞·ª£ng ·∫£nh theo split v√† label")
            plt.xlabel("Label (T√™n b·ªánh)")
            plt.ylabel("S·ªë l∆∞·ª£ng ·∫£nh")
            plt.xticks(rotation=45, ha="right")
            plt.legend(title="Split")
            plt.tight_layout()
            plt.show()
            logging.info("Successfully created split visualization")
        else:
            logging.warning("No split counts data available for visualization")
    else:
        logging.warning("No split data available for visualization")
        
except Exception as e:
    logging.error(f"Error creating split visualization: {e}")

# %% [markdown]
# ### L∆∞u CSV meta

# %%
out_meta = os.path.join(OUTPUT_DIRS["results"], "riceleaf_meta.csv")
df_split.to_csv(out_meta, index=False)
logging.info(f"üíæ Saved metadata to: {out_meta}")

# %% [markdown]
# ### L∆∞u output ·∫£nh

# %%
DO_COPY = True
OUTROOT = OUTPUT_DIRS["rice_dataset"]

if DO_COPY:
    for _, row in df_split.iterrows():
        d = os.path.join(OUTROOT, row["split"], f'{row["label_id"]:02d}_{row["label_name"]}')
        os.makedirs(d, exist_ok=True)
        dst = os.path.join(d, os.path.basename(row["path"]))
        if not os.path.exists(dst):
            shutil.copy2(row["path"], dst)
    logging.info(f"üìÅ Copied images to: {OUTROOT}")
else:
    logging.info("Using direct paths from dataframe")

# %% [markdown]
# ## X·ª≠ l√Ω d·ªØ li·ªáu

# %% [markdown]
# ### ƒê·ªçc d·ªØ li·ªáu t·ª´ CSV meta

# %%
meta = pd.read_csv(os.path.join(OUTPUT_DIRS["results"], "riceleaf_meta.csv"))

train_df = meta[meta["split"]=="train"]
val_df   = meta[meta["split"]=="val"]
test_df  = meta[meta["split"]=="test"]
logging.info(f"üìä Data splits - Train: {train_df.shape[0]}, Val: {val_df.shape[0]}, Test: {test_df.shape[0]}")

# %% [markdown]
# #### CLAHE (Contrast Limited Adaptive Histogram Equalization) ƒë·ªÉ tƒÉng t∆∞∆°ng ph·∫£n v√πng l√° l√∫a ‚Üí gi√∫p r√µ v·∫øt b·ªánh h∆°n

# %% [markdown]
# | **Kh√≠a c·∫°nh**           | **L·ª£i √≠ch**                                                         | **B·∫•t l·ª£i**                                                                                   |
# | ----------------------- | ------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |
# | **T∆∞∆°ng ph·∫£n**          | TƒÉng c∆∞·ªùng chi ti·∫øt ·ªü c·∫£ v√πng s√°ng v√† t·ªëi, l√†m r√µ v√¢n l√°, ƒë·ªëm b·ªánh. | C√≥ th·ªÉ l√†m **nhi·ªÖu** tr·ªü n√™n r√µ r√†ng h∆°n ·ªü v√πng n·ªÅn ph·∫≥ng.                                    |
# | **√Ånh s√°ng m√¥i tr∆∞·ªùng** | Gi·∫£m s·ª± kh√°c bi·ªát gi·ªØa ·∫£nh ch·ª•p ·ªü ƒëi·ªÅu ki·ªán √°nh s√°ng kh√°c nhau.     | N·∫øu ·∫£nh g·ªëc ƒë√£ c√≥ √°nh s√°ng t·ªët, CLAHE c√≥ th·ªÉ g√¢y **qu√° s·∫Øc n√©t**.                             |
# | **T√≠nh ·ªïn ƒë·ªãnh**        | Gi√∫p model h·ªçc feature r√µ r√†ng h∆°n, ƒë·∫∑c bi·ªát v·ªõi dataset nh·ªè.       | Model c√≥ th·ªÉ **overfit v√†o h√¨nh ·∫£nh ƒë√£ x·ª≠ l√Ω CLAHE**, k√©m robust v·ªõi ·∫£nh th·ª±c t·∫ø kh√¥ng x·ª≠ l√Ω. |

# %%
def apply_clahe_pil(pil_img):
    """√Åp d·ª•ng CLAHE l√™n ·∫£nh PIL"""
    img = np.array(pil_img.convert("RGB"))  # PIL -> numpy
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)  # sang kh√¥ng gian LAB
    
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl,a,b))
    
    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)
    return Image.fromarray(enhanced)


# %%
samples = train_df.sample(5, random_state=42)

plt.figure(figsize=(15, 6))
for i, (path, label) in enumerate(zip(samples['path'], samples['label_name'])):
    img = Image.open(path).convert("RGB")
    img_clahe = apply_clahe_pil(img)

    # ·∫¢nh g·ªëc
    plt.subplot(2, 5, i+1)
    plt.imshow(img)
    plt.title(f"{label}\nOriginal")
    plt.axis('off')

    # ·∫¢nh CLAHE
    plt.subplot(2, 5, i+6)
    plt.imshow(img_clahe)
    plt.title("CLAHE")
    plt.axis('off')

plt.suptitle("So s√°nh ·∫£nh g·ªëc v√† sau CLAHE", fontsize=16)
plt.tight_layout()
plt.show()

# %%
def save_clahe_in_batches(df, out_dir, batch_size=200):
    os.makedirs(out_dir, exist_ok=True)
    new_paths = []
    n = len(df)
    for i in tqdm(range(0, n, batch_size), desc=f"Processing {out_dir}"):
        batch = df.iloc[i:i+batch_size]
        for path, label in zip(batch['path'], batch['label_name']):
            img = Image.open(path).convert("RGB")
            img_clahe = apply_clahe_pil(img)

            # th∆∞ m·ª•c theo nh√£n
            label_dir = os.path.join(out_dir, label)
            os.makedirs(label_dir, exist_ok=True)
            # L∆∞u ·∫£nh CLAHE
            fname = os.path.basename(path)
            save_path = os.path.join(label_dir, fname)
            img_clahe.save(save_path)
            new_paths.append(save_path)
    return new_paths

# %%
train_df = meta[meta["split"]=="train"].copy()
logging.info(f"üîÑ Starting CLAHE processing - Train: {train_df.shape[0]}, Val: {val_df.shape[0]}, Test: {test_df.shape[0]}")
train_df["clahe_path"] = save_clahe_in_batches(train_df, os.path.join(OUTPUT_DIRS["clahe"], "train"), batch_size=200)
train_df["path"] = train_df["clahe_path"]
train_df = train_df.drop(columns=["clahe_path"])

# %%
meta_merged = pd.concat([train_df, val_df, test_df], ignore_index=True)
meta_merged.to_csv(os.path.join(OUTPUT_DIRS["results"], "riceleaf_meta_merged.csv"), index=False)
logging.info(f"üíæ Saved merged metadata: {meta_merged.shape[0]} total samples")

# %% [markdown]
# ### Chu·∫©n ho√° ·∫£nh (Resize + Normalize)

# %%
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.3), 
    transforms.RandomRotation(30),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),
    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),  
    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_test_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])


# %% [markdown]
# ### DataLoader

# %%
class RiceDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df.reset_index(drop=True)
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img = Image.open(row["path"]).convert("RGB")
        label = int(row["label_id"])   
        if self.transform:
            img = self.transform(img)
        return img, label

# %%
use_cuda = torch.cuda.is_available()

train_set = RiceDataset(train_df, transform=train_transform)
val_set   = RiceDataset(val_df, transform=val_test_transform)
test_set  = RiceDataset(test_df, transform=val_test_transform)

# %%
test_loader  = DataLoader(test_set, 
                          batch_size=32, 
                          shuffle=False, num_workers=2, 
                          pin_memory=use_cuda)
imgs, labels = next(iter(test_loader))
logging.info(f"üì¶ Test batch shape: {imgs.shape}")
logging.info(f"üì¶ Labels range: {labels.min().item()} to {labels.max().item()}")

# %%
train_loader = DataLoader(
    train_set, batch_size=64, 
    shuffle=True,
    num_workers=4,            
    pin_memory=use_cuda,      
    persistent_workers=True,  
    prefetch_factor=2,       
)
val_loader = DataLoader(
    val_set, 
    batch_size=64,
    shuffle=False,
    num_workers=4, 
    pin_memory=use_cuda,
    persistent_workers=True, prefetch_factor=2,
)

# %%
imgs, labels = next(iter(train_loader))
logging.info(f"üì¶ Train batch shape: {imgs.shape}")
logging.info(f"üì¶ Labels range: {labels.min().item()} to {labels.max().item()}")

# %%
images, labels = next(iter(train_loader))
plt.figure(figsize=(10,5))
for i in range(8):
    plt.subplot(2,4,i+1)
    plt.imshow(images[i].permute(1,2,0).numpy())
    plt.title(labels[i].item())
    plt.axis("off")
plt.show()

# %%
label_counts = meta.groupby("label_name")["path"].count().sort_values(ascending=False)
print(label_counts)

# %% [markdown]
# ## X√¢y d·ª±ng m√¥ h√¨nh

# %%
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_classes = meta["label_id"].nunique()
logging.info(f"üñ•Ô∏è Using device: {device}, Number of classes: {num_classes}")

# %%
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

def build_efficientnet(num_classes):
    weights = EfficientNet_B0_Weights.DEFAULT
    model = efficientnet_b0(weights=weights)
    # model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    in_feat = model.classifier[1].in_features 
    model.classifier[1] = nn.Sequential(
        nn.Dropout(0.2),  
        nn.Linear(in_feat, num_classes)
    )
    return model

# %% [markdown]
# ### (5) MobileNetV2 (pretrained)

# %%
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights

def build_mobilenet(num_classes):
    weights = MobileNet_V2_Weights.DEFAULT
    model = mobilenet_v2(weights=weights)
    # model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    in_feat = model.classifier[1].in_features 
    model.classifier[1] = nn.Sequential(
        nn.Dropout(0.2),
        nn.Linear(in_feat, num_classes)
    )
    return model

def setup_amp():
    try:
        from torch.amp import GradScaler, autocast
        NEW_AMP = True
    except Exception:
        from torch.cuda.amp import GradScaler, autocast
        NEW_AMP = False
    use_cuda = torch.cuda.is_available()
    device = torch.device("cuda" if use_cuda else "cpu")
    if not use_cuda:
        amp_ctx = nullcontext()
    else:
        amp_ctx = autocast(device_type="cuda", enabled=True) if NEW_AMP else autocast(enabled=True)
    if NEW_AMP:
        scaler = GradScaler(device="cuda" if use_cuda else "cpu", enabled=use_cuda)
    else:
        scaler = GradScaler(enabled=use_cuda)
    return device, amp_ctx, scaler

# %%
class EarlyStopping:
    def __init__(self, patience=5, mode="min", min_delta=0.0):
        self.patience = patience
        self.mode = mode
        self.min_delta = min_delta
        self.best = None
        self.counter = 0
        self.should_stop = False

    def step(self, current):
        if self.best is None:
            self.best = current
            return False

        improvement = (current < self.best - self.min_delta) if self.mode == "min" else (current > self.best + self.min_delta)

        if improvement:
            self.best = current
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.should_stop = True
        return self.should_stop

# %%
torch.backends.cudnn.benchmark = bool(torch.cuda.is_available())
def prepare_model(model, lr, monitor):
    criterion = nn.CrossEntropyLoss()
    model = model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = "min" if monitor=="val_loss" else "max", factor=0.5, patience=2)
    return model, scheduler, optimizer, criterion

# %%
def train_model(model, train_loader, val_loader, epochs=5, lr=1e-4, device=None, ckpt_path=None, es_patience=5, monitor="val_loss"):
    if ckpt_path is None:
        ckpt_path = os.path.join(OUTPUT_DIRS["checkpoints"], "best.pth")
    dev, amp_ctx, scaler = setup_amp()
    if device is None:   
        device = dev

    model, scheduler, optimizer, criterion = prepare_model(model, lr, monitor)
    es = EarlyStopping(patience=es_patience, mode=("min" if monitor=="val_loss" else "max"), min_delta=0.0)

    best_metric = float("inf") if monitor=="val_loss" else -float("inf")
    history = {"train_loss": [], "train_acc": [], "val_loss": [], "val_acc": []}

    for epoch in range(1, epochs+1):
        # TRAIN 
        model.train()
        running_loss, running_correct, running_total = 0.0, 0, 0
        pbar = tqdm(train_loader, desc=f"Train E{epoch}/{epochs}")

        for imgs, labels in pbar:
            imgs   = imgs.to(device, non_blocking=True)
            labels = labels.long().to(device, non_blocking=True)
            optimizer.zero_grad(set_to_none=True)
            with amp_ctx:   
                outputs = model(imgs)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += float(loss.item()) * imgs.size(0)
            preds = outputs.argmax(1)
            running_correct += (preds == labels).sum().item()
            running_total += labels.size(0)
            pbar.set_postfix(loss=float(loss.item()))

        train_loss = running_loss / max(1, running_total)
        train_acc  = running_correct / max(1, running_total)
        
        # VALID 
        model.eval()
        val_loss_sum, val_correct, val_total = 0.0, 0, 0
        with torch.no_grad():
            for imgs, labels in tqdm(val_loader, desc=f"Valid E{epoch}/{epochs}"):
                imgs   = imgs.to(device, non_blocking=True)
                labels = labels.long().to(device, non_blocking=True)
                with amp_ctx:  
                    outputs = model(imgs)
                    loss = criterion(outputs, labels)
                val_loss_sum += float(loss.item()) * imgs.size(0)
                val_correct  += (outputs.argmax(1) == labels).sum().item()
                val_total    += labels.size(0)

        val_loss = val_loss_sum / max(1, val_total)
        val_acc  = val_correct / max(1, val_total)

        history["train_loss"].append(train_loss)
        history["train_acc"].append(train_acc)
        history["val_loss"].append(val_loss)
        history["val_acc"].append(val_acc)
        print(f"Epoch {epoch}/{epochs} | Train Loss {train_loss:.4f} Acc {train_acc:.4f} Val Loss {val_loss:.4f} Acc {val_acc:.4f}")

        monitored_value = val_loss if monitor == "val_loss" else val_acc
        scheduler.step(monitored_value)

        is_better = (monitored_value < best_metric) if monitor=="val_loss" else (monitored_value > best_metric)
        if is_better:
            best_metric = monitored_value
            torch.save(model.state_dict(), ckpt_path)
            print(f"Saved BEST to {ckpt_path} (best {monitor}: {best_metric:.4f})")
        if es.step(monitored_value):
            print(f"Early stopping at epoch {epoch} (no improvement on {monitor})")
            break

    print(f"Best {monitor}: {best_metric:.4f}")
    return history, ckpt_path

# %%
@torch.no_grad()
def evaluate_on_loader(model, loader, device):
    model.eval()
    all_preds, all_labels = [], []
    for imgs, labels in loader:
        imgs   = imgs.to(device, non_blocking=True)
        labels = labels.long().to(device, non_blocking=True)
        logits = model(imgs)
        preds  = logits.argmax(1)
        all_preds.append(preds.cpu().numpy())
        all_labels.append(labels.cpu().numpy())
    y_pred  = np.concatenate(all_preds)
    y_true  = np.concatenate(all_labels)
    acc     = accuracy_score(y_true, y_pred)
    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average="macro", zero_division=0)
    return {"test_acc": acc, "precision": p, "recall": r, "f1": f1, "confusion_matrix": confusion_matrix(y_true, y_pred)}

def count_params_m(model):
    return sum(p.numel() for p in model.parameters()) / 1e6

@torch.no_grad()
def measure_latency_ms(model, device, input_size=(1,3,224,224), warmup=10, runs=30):
    model.eval()
    x = torch.randn(*input_size, device=device)
    # warm-up
    for _ in range(warmup):
        _ = model(x)
    # measure
    torch.cuda.synchronize() if device.type == "cuda" else None
    t0 = time.time()
    for _ in range(runs):
        _ = model(x)
    torch.cuda.synchronize() if device.type == "cuda" else None
    dt = (time.time() - t0) / runs
    return dt * 1000.0  


# %%
def plot_history(history, title="Training Curve", show=True, save_path=None, monitor="val_loss"):
    epochs = range(1, len(history["train_loss"]) + 1)
    plt.figure(figsize=(12,5))

    # T√¨m best point theo monitor
    if monitor == "val_loss":
        best_epoch = int(np.argmin(history["val_loss"])) + 1
        best_value = min(history["val_loss"])
        label_text = f"Best Val Loss={best_value:.4f} (Epoch {best_epoch})"
    else:  # val_acc
        best_epoch = int(np.argmax(history["val_acc"])) + 1
        best_value = max(history["val_acc"])
        label_text = f"Best Val Acc={best_value:.4f} (Epoch {best_epoch})"

    # Accuracy
    plt.subplot(1,2,1)
    plt.plot(epochs, history["train_acc"], label="Train Acc")
    plt.plot(epochs, history["val_acc"], label="Val Acc")
    plt.scatter(best_epoch, history["val_acc"][best_epoch-1], color="red", marker="o", s=80, label="Best Point")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title(f"{title} - Accuracy")
    plt.legend()

    # Loss
    plt.subplot(1,2,2)
    plt.plot(epochs, history["train_loss"], label="Train Loss")
    plt.plot(epochs, history["val_loss"], label="Val Loss")
    plt.scatter(best_epoch, history["val_loss"][best_epoch-1], color="red", marker="o", s=80, label="Best Point")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title(f"{title} - Loss\n{label_text}")
    plt.legend()

    plt.tight_layout()
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path)
    if show:
        plt.show()

# %%
def comprehensive_evaluation(models_dict, dataset_combinations, device, epochs=5):
    results = []
    all_histories = {}
    
    for sources in dataset_combinations:
        source_name = "+".join(sources) if sources else "all_sources"
        print(f"\n===== EVALUATING ON {source_name} =====")
        
        # Create datasets for this combination
        train_df_filtered, val_df_filtered, test_df_filtered = create_filtered_datasets(meta, sources=sources)
        
        if len(train_df_filtered) == 0:
            print(f"Skipping {source_name} - no data found")
            continue
        
        # Create dataloaders
        train_set = RiceDataset(train_df_filtered, transform=train_transform)
        val_set = RiceDataset(val_df_filtered, transform=val_test_transform)
        test_set = RiceDataset(test_df_filtered, transform=val_test_transform)
        
        train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)
        val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)
        test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)
        
        for model_name, model_constructor in models_dict.items():
            print(f"\nTraining {model_name} on {source_name}")
            
            # Initialize model
            model = model_constructor().to(device)
            
            # Train model
            ckpt_path = os.path.join(OUTPUT_DIRS["checkpoints"], f"{model_name}_{source_name}_best.pth")
            history, _ = train_model(
                model, train_loader, val_loader,
                epochs=epochs, lr=1e-4, device=device,
                ckpt_path=ckpt_path, 
                es_patience=5, monitor="val_loss"
            )
            
            all_histories[f"{model_name}_{source_name}"] = history
            plot_history(history, title=f"{model_name} on {source_name}", save_path=os.path.join(OUTPUT_DIRS["modeltraining"], f"{model_name}_{source_name}_curve.png"), monitor="val_acc")
            # Load best weights and evaluate
            model.load_state_dict(torch.load(ckpt_path, map_location=device))
            test_metrics = evaluate_on_loader(model, test_loader, device)
            
            # Model metrics
            params_m = count_params_m(model)
            latency_ms = measure_latency_ms(model, device)
            fps = 1000 / latency_ms
            
            # Save results
            results.append({
                "Model": model_name,
                "Dataset": source_name,
                "Test Acc": test_metrics["test_acc"],
                "Precision": test_metrics["precision"],
                "Recall": test_metrics["recall"],
                "F1": test_metrics["f1"],
                "Params (M)": params_m,
                "Latency (ms)": latency_ms,
                "FPS": fps,
                "Checkpoint": ckpt_path
            })
            
            # Clean up
            del model
            torch.cuda.empty_cache()
            gc.collect()
    
    return pd.DataFrame(results), all_histories

# %%
source_combinations = [
    ["dataset_1"],  
]

models_list = {
    "EfficientNetB0":  lambda: build_efficientnet(num_classes),
    "MobileNetV2":     lambda: build_mobilenet(num_classes),
}

results_df, histories = comprehensive_evaluation(models_list, source_combinations, device, epochs=5)

print("\n" + "="*50)
print("COMPREHENSIVE RESULTS") 
print("="*50)
print(results_df.to_string(index=False))
results_df.to_csv(os.path.join(OUTPUT_DIRS["results"], "comprehensive_results.csv"), index=False)

# %% [markdown]
# ## So s√°nh model

# %%
# SO S√ÅNH TEST ACCURACY GI·ªÆA C√ÅC MODEL THEO T·ª™NG B·ªò DATASET
def plot_model_dataset_accuracy_comparison(results_df):
    if len(results_df) == 0:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã")
        return
    
    # Create figure with subplots
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('So s√°nh Test Accuracy: Models vs Datasets', fontsize=16, fontweight='bold')
    
    # 1. Grouped Bar Chart
    ax1 = axes[0, 0]
    pivot_acc = results_df.pivot(index='Model', columns='Dataset', values='Test Acc')
    
    # Plot grouped bars
    pivot_acc.plot(kind='bar', ax=ax1, width=0.8, colormap='tab10')
    ax1.set_title('Test Accuracy by Model and Dataset', fontsize=14)
    ax1.set_ylabel('Test Accuracy', fontsize=12)
    ax1.set_xlabel('Model', fontsize=12)
    ax1.set_ylim(0, 1.0)
    ax1.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for container in ax1.containers:
        ax1.bar_label(container, fmt='%.3f', fontsize=9, rotation=90)
    
    # 2. Heatmap
    ax2 = axes[0, 1]
    sns.heatmap(pivot_acc, annot=True, fmt='.3f', cmap='RdYlGn', 
                ax=ax2, cbar_kws={'label': 'Test Accuracy'})
    ax2.set_title('Accuracy Heatmap', fontsize=14)
    ax2.set_xlabel('Dataset', fontsize=12)
    ax2.set_ylabel('Model', fontsize=12)
    
    # 3. Line Plot - Xu h∆∞·ªõng accuracy qua c√°c dataset
    ax3 = axes[1, 0]
    for model in results_df['Model'].unique():
        model_data = results_df[results_df['Model'] == model]
        ax3.plot(model_data['Dataset'], model_data['Test Acc'], 
                marker='o', linewidth=2, markersize=8, label=model)
    
    ax3.set_title('Accuracy Trends Across Datasets', fontsize=14)
    ax3.set_ylabel('Test Accuracy', fontsize=12)
    ax3.set_xlabel('Dataset', fontsize=12)
    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax3.grid(True, alpha=0.3)
    ax3.tick_params(axis='x', rotation=45)
    
    # 4. Stacked Bar Chart - Contribution comparison
    ax4 = axes[1, 1]
    pivot_acc_T = pivot_acc.T  # Transpose for stacked bars
    pivot_acc_T.plot(kind='bar', stacked=True, ax=ax4, colormap='Set3')
    ax4.set_title('Stacked Accuracy by Dataset', fontsize=14)
    ax4.set_ylabel('Cumulative Test Accuracy', fontsize=12)
    ax4.set_xlabel('Dataset', fontsize=12)
    ax4.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')
    ax4.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIRS["plots"], "model_dataset_accuracy_comparison.png"), 
                dpi=150, bbox_inches='tight')
    plt.show()
    
    # Print summary statistics
    print("\n" + "="*60)
    print("TH·ªêNG K√ä CHI TI·∫æT ACCURACY THEO MODEL V√Ä DATASET")
    print("="*60)
    
    # Best performer for each dataset
    print("\n MODEL T·ªêT NH·∫§T CHO T·ª™NG DATASET:")
    for dataset in results_df['Dataset'].unique():
        dataset_data = results_df[results_df['Dataset'] == dataset]
        best_model = dataset_data.loc[dataset_data['Test Acc'].idxmax()]
        print(f"   {dataset}: {best_model['Model']} ({best_model['Test Acc']:.4f})")
    
    # Average performance by model
    print("\n ACCURACY TRUNG B√åNH C·ª¶A T·ª™NG MODEL:")
    for model in results_df['Model'].unique():
        model_data = results_df[results_df['Model'] == model]
        avg_acc = model_data['Test Acc'].mean()
        std_acc = model_data['Test Acc'].std()
        print(f"   {model}: {avg_acc:.4f} ¬± {std_acc:.4f}")
    
    # Dataset difficulty ranking
    print("\n X·∫æP H·∫†NG ƒê·ªò KH√ì C·ª¶A C√ÅC DATASET (theo accuracy trung b√¨nh):")
    dataset_avg = results_df.groupby('Dataset')['Test Acc'].mean().sort_values(ascending=False)
    for i, (dataset, avg_acc) in enumerate(dataset_avg.items(), 1):
        difficulty = "D·ªÖ" if avg_acc > 0.9 else "Trung b√¨nh" if avg_acc > 0.8 else "Kh√≥"
        print(f"   {i}. {dataset}: {avg_acc:.4f} ({difficulty})")

# Run the comparison
if 'results_df' in locals() and len(results_df) > 0:
    plot_model_dataset_accuracy_comparison(results_df)
else:
    # Create sample data for demonstration
    print("Kh√¥ng t√¨m th·∫•y results_df. T·∫°o d·ªØ li·ªáu m·∫´u ƒë·ªÉ demo...")
    sample_data = {
        'Model': ['SimpleCNN', 'RiceLeafCNN', 'ResNet18', 'MobileNetV2'] * 3,
        'Dataset': ['all_sources'] * 4 + ['dataset_1'] * 4 + ['dataset_1+dataset_2'] * 4,
        'Test Acc': [0.85, 0.89, 0.92, 0.87, 0.83, 0.88, 0.91, 0.86, 0.86, 0.90, 0.93, 0.88]
    }
    sample_df = pd.DataFrame(sample_data)
    plot_model_dataset_accuracy_comparison(sample_df)


# %%
def plot_model_comparison_by_dataset(results_df):
    """Plot performance comparison of models across different datasets"""
    plt.figure(figsize=(14, 10))
    
    # Accuracy comparison
    plt.subplot(2, 2, 1)
    pivot_acc = results_df.pivot(index='Model', columns='Dataset', values='Test Acc')
    pivot_acc.plot(kind='bar', ax=plt.gca())
    plt.title('Accuracy by Model and Dataset')
    plt.ylabel('Test Accuracy')
    plt.xticks(rotation=45)
    plt.ylim(0, 1.0)
    plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Speed (FPS) comparison  
    plt.subplot(2, 2, 2)
    pivot_fps = results_df.pivot(index='Model', columns='Dataset', values='FPS')
    pivot_fps.plot(kind='bar', ax=plt.gca())
    plt.title('Speed (FPS) by Model and Dataset')
    plt.ylabel('FPS')
    plt.xticks(rotation=45)
    plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.subplot(2, 2, 3)
    for dataset in results_df['Dataset'].unique():
        df_subset = results_df[results_df['Dataset'] == dataset]
        plt.scatter(df_subset['Params (M)'], df_subset['Test Acc'], 
                   label=dataset, s=100, alpha=0.7)
        for _, row in df_subset.iterrows():
            plt.annotate(row['Model'], 
                        (row['Params (M)'], row['Test Acc']),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    plt.xlabel('Model Size (M parameters)')
    plt.ylabel('Test Accuracy')
    plt.title('Model Size vs Accuracy')
    plt.legend(title='Dataset')
    plt.subplot(2, 2, 4)
    for dataset in results_df['Dataset'].unique():
        df_subset = results_df[results_df['Dataset'] == dataset]
        plt.scatter(df_subset['FPS'], df_subset['Test Acc'], 
                   label=dataset, s=100, alpha=0.7)
        for _, row in df_subset.iterrows():
            plt.annotate(row['Model'], 
                        (row['FPS'], row['Test Acc']),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    plt.xlabel('Speed (FPS)')
    plt.ylabel('Test Accuracy')
    plt.title('Speed vs Accuracy')
    plt.legend(title='Dataset')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIRS['plots'], 'model_dataset_comparison.png'), dpi=150, bbox_inches='tight')
    plt.show()

if len(results_df) > 0:
    plot_model_comparison_by_dataset(results_df)

# %%
def analyze_training_stability(model_histories):
    """Analyze training curves for stability and convergence"""
    if not model_histories:
        print("No training histories available")
        return
        
    plt.figure(figsize=(15, 10))
    
    # Loss stability 
    plt.subplot(2, 2, 1)
    for model_name, history in model_histories.items():
        if 'train_loss' in history:
            plt.plot(history['train_loss'], label=f"{model_name}")
    plt.title('Training Loss Convergence')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Validation loss stability
    plt.subplot(2, 2, 2)
    for model_name, history in model_histories.items():
        if 'val_loss' in history:
            plt.plot(history['val_loss'], label=f"{model_name}")
    plt.title('Validation Loss Convergence')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Accuracy progress
    plt.subplot(2, 2, 3)
    for model_name, history in model_histories.items():
        if 'train_acc' in history:
            plt.plot(history['train_acc'], label=f"{model_name}")
    plt.title('Training Accuracy Progress')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    # Validation accuracy progress
    plt.subplot(2, 2, 4)
    for model_name, history in model_histories.items():
        if 'val_acc' in history:
            plt.plot(history['val_acc'], label=f"{model_name}")
    plt.title('Validation Accuracy Progress')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIRS['plots'], 'training_stability_analysis.png'), dpi=150, bbox_inches='tight')
    plt.show()
    
    # Overfitting analysis
    print("\nTraining Stability Analysis:")
    print("="*50)
    for model_name, history in model_histories.items():
        if 'train_loss' in history and 'val_loss' in history:
            train_loss = history['train_loss']
            val_loss = history['val_loss']
            
            if len(train_loss) > 0 and len(val_loss) > 0:
                # Calculate generalization gap
                min_len = min(len(train_loss), len(val_loss))
                gen_gaps = [val_loss[i] - train_loss[i] for i in range(min_len)]
                
                print(f"\n{model_name}:")
                print(f"  Final train/val loss gap: {gen_gaps[-1]:.4f}")
                print(f"  Max train/val loss gap: {max(gen_gaps):.4f}")
                print(f"  Epochs until min val loss: {val_loss.index(min(val_loss))+1}")
                
                # Flag potential issues
                if gen_gaps[-1] > 0.1:
                    print("  Potential overfitting detected")
                if min(val_loss) > 0.5:
                    print("  High validation loss - model may be underfitting")

if 'histories' in locals() and histories:
    analyze_training_stability(histories)

# %% [markdown]
# ## ƒê√°nh gi√° model

# %%
df = pd.read_csv(os.path.join(OUTPUT_DIRS["results"], "comprehensive_results.csv"))

best_row = df.sort_values("Test Acc", ascending=False).iloc[0]
best_ckpt = best_row["Checkpoint"]
best_model_name = best_row["Model"]
best_acc = best_row["Test Acc"]
print(f"Best model: {best_model_name} ({best_ckpt}), acc={best_acc:.4f}")

# %%
def evaluate_model(model, test_loader, class_names):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs = imgs.to(device)
            labels = labels.to(device)
            outputs = model(imgs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    cm = confusion_matrix(all_labels, all_preds)
    acc = np.mean(np.array(all_labels) == np.array(all_preds))
    print(f"Test Accuracy: {acc:.4f}")
    print("\nClassification Report:\n", classification_report(all_labels, all_preds, target_names=class_names))

    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")
    plt.show()

# %%
class_names = train_df["label_name"].unique().tolist()

def select_best_row(results_df: pd.DataFrame, key="F1", dataset: str | None = None):
    df = results_df if dataset is None else results_df[results_df["Dataset"] == dataset]
    if len(df) == 0:
        raise ValueError(f"Kh√¥ng t√¨m th·∫•y run n√†o cho dataset={dataset}")
    return df.loc[df[key].idxmax()]   # Series

def load_model_from_row(best_row, models_dict, device):
    model_name = best_row["Model"]
    ckpt_path  = best_row["Checkpoint"]
    if model_name not in models_dict:
        raise KeyError(f"'{model_name}' kh√¥ng c√≥ trong models_dict")
    model = models_dict[model_name]().to(device)
    state = torch.load(ckpt_path, map_location=device)
    # h·ªó tr·ª£ c·∫£ state_dict thu·∫ßn v√† checkpoint dict
    if isinstance(state, dict) and "model_state_dict" in state:
        model.load_state_dict(state["model_state_dict"])
    else:
        model.load_state_dict(state)
    model.eval()
    return model, ckpt_path

def auto_load_best_model(results_csv, models_dict, device, key="F1", dataset=None):
    results_df = pd.read_csv(results_csv)
    best_row = select_best_row(results_df, key=key, dataset=dataset)
    print(f"Best by {key}: {best_row['Model']} @ {best_row['Dataset']} ({best_row[key]:.4f})")
    model, ckpt = load_model_from_row(best_row, models_dict, device)
    return model, best_row

# ===== D√ôNG =====
results_csv = os.path.join(OUTPUT_DIRS["results"], "comprehensive_results.csv")
model_best, info = auto_load_best_model(results_csv, models_list, device, key="F1", dataset=None)

# N·∫øu b·∫°n ƒë√£ c√≥ s·∫µn test_loader + class_names:
evaluate_model(model_best, test_loader, class_names)

# %% [markdown]
# ## D·ª± ƒëo√°n

# %%
def infer_arch_from_path(ckpt_path: str) -> str:
    """ƒêo√°n t√™n ki·∫øn tr√∫c t·ª´ t√™n file checkpoint."""
    base = os.path.basename(ckpt_path).lower()
    mapping = {
        "resnet18": "ResNet18",
        "resnet50": "ResNet50",
        "mobilenetv2": "MobileNetV2",
        "efficientnetb0": "EfficientNetB0",
        "riceleafcnn": "RiceLeafCNN",
        "simplecnn": "SimpleCNN",
    }
    for k, v in mapping.items():
        if k in base:
            return v
    raise ValueError(f"Kh√¥ng suy lu·∫≠n ƒë∆∞·ª£c ki·∫øn tr√∫c t·ª´ t√™n file: {base}")

def load_saved_model_by_ckpt(ckpt_path, models_dict, device, strict_head="auto"):
    """
    Kh·ªüi t·∫°o ƒë√∫ng ki·∫øn tr√∫c theo ckpt_path r·ªìi load state_dict.
    - models_dict: {"ResNet18": lambda: build_resnet18(num_classes), ...}
    - strict_head="auto": th·ª≠ strict=True; n·∫øu ch·ªâ l·ªói ·ªü head th√¨ fallback strict=False.
    """
    arch = infer_arch_from_path(ckpt_path)
    if arch not in models_dict:
        raise KeyError(f"'{arch}' kh√¥ng c√≥ trong models_dict")

    model = models_dict[arch]().to(device)
    state = torch.load(ckpt_path, map_location=device)
    if isinstance(state, dict) and "model_state_dict" in state:
        state = state["model_state_dict"]

    try:
        model.load_state_dict(state, strict=True)
    except RuntimeError as e:
        if strict_head == "auto":
            print(f"strict=True l·ªói ({e.__class__.__name__}): th·ª≠ strict=False (c√≥ th·ªÉ sai head).")
            model.load_state_dict(state, strict=False)
        else:
            raise
    model.eval()
    return model, arch

def ensure_save_dir_from_path(path: str) -> str:
    """Tr·∫£ v·ªÅ th∆∞ m·ª•c h·ª£p l·ªá ƒë·ªÉ l∆∞u file theo m·ªôt 'path' (file ho·∫∑c folder)."""
    if os.path.isdir(path):
        save_dir = path
    else:
        save_dir = os.path.dirname(path) or "."
    os.makedirs(save_dir, exist_ok=True)
    return save_dir


# %%

def demo_prediction_with_saved_model(checkpoint_path="../output", dataset_path="data", num_samples=6):
    print("DEMO PREDICTION V·ªöI MODEL ƒê√É SAVE")
    print("="*60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    all_images = []
    class_names = None
    if not isinstance(dataset_path, pd.DataFrame):
        raise TypeError("`dataset_path` ph·∫£i l√† str/path ho·∫∑c pandas.DataFrame")
    df_in = dataset_path.copy()
    if 'path' not in df_in.columns:
        raise ValueError("DataFrame ph·∫£i c√≥ c·ªôt 'path'.")
    label_col = None
    if 'label_name' in df_in.columns:
        label_col = 'label_name'
    else:
        for c in ['label', 'class', 'target', 'y', 'category']:
            if c in df_in.columns:
                label_col = c; break
    has_label_id = 'label_id' in df_in.columns
    if label_col is None and not has_label_id:
        raise ValueError("Thi·∫øu nh√£n: c·∫ßn 'label_name' ho·∫∑c 1 trong ['label','class','target','y','category'] ho·∫∑c 'label_id'.")

    if has_label_id and 'label_name' in df_in.columns:
        id_name = df_in[['label_id','label_name']].drop_duplicates().sort_values('label_id')
        class_names = id_name['label_name'].astype(str).tolist()
        id_to_idx = {int(i): idx for idx, i in enumerate(id_name['label_id'].tolist())}
        for _, row in df_in.iterrows():
            img_path = str(row['path'])
            if os.path.isfile(img_path) and img_path.lower().endswith(('.jpg','.jpeg','.png')):
                lid = int(row['label_id'])
                if lid in id_to_idx:
                    all_images.append({
                        'path': img_path,
                        'true_label': str(row['label_name']),
                        'true_label_idx': id_to_idx[lid],
                    })
    elif has_label_id and label_col is None:
        uniq_ids = sorted(set(int(x) for x in df_in['label_id'].tolist()))
        class_names = [str(i) for i in uniq_ids]
        id_to_idx = {i: idx for idx, i in enumerate(uniq_ids)}
        for _, row in df_in.iterrows():
            img_path = str(row['path'])
            if os.path.isfile(img_path) and img_path.lower().endswith(('.jpg','.jpeg','.png')):
                lid = int(row['label_id'])
                if lid in id_to_idx:
                    all_images.append({
                        'path': img_path,
                        'true_label': str(lid),
                        'true_label_idx': id_to_idx[lid],
                    })
    else:
        labels_series = df_in[label_col].astype(str)
        class_names = sorted(labels_series.unique().tolist())
        class_to_idx = {c:i for i,c in enumerate(class_names)}
        for _, row in df_in.iterrows():
            img_path = str(row['path'])
            if os.path.isfile(img_path) and img_path.lower().endswith(('.jpg','.jpeg','.png')):
                name = str(row[label_col])
                all_images.append({
                    'path': img_path,
                    'true_label': name,
                    'true_label_idx': class_to_idx[name],
                })

    if len(all_images) == 0:
        raise RuntimeError("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o ƒë·ªÉ test!")
    print(f"T√¨m th·∫•y {len(all_images)} ·∫£nh. S·ªë l·ªõp: {len(class_names)} -> {class_names}")
    models_dict = {
        "SimpleCNN":      lambda: SimpleCNN(len(class_names)),
        "RiceLeafCNN":    lambda: RiceLeafCNN(len(class_names)),
        "ResNet18":       lambda: build_resnet18(len(class_names)),
        "ResNet50":       lambda: build_resnet50(len(class_names)),
        "EfficientNetB0": lambda: build_efficientnet(len(class_names)),
        "MobileNetV2":    lambda: build_mobilenet(len(class_names)),
    }
    model, model_name = load_saved_model_by_ckpt(
        ckpt_path=checkpoint_path,
        models_dict=models_dict,
        device=device,
        strict_head="auto",
    )

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    random_images = random.sample(all_images, min(num_samples, len(all_images)))
    rows = 2 if len(random_images) > 3 else 1
    cols = min(3, len(random_images))
    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))
    if hasattr(axes, "ravel"):
        axes = axes.ravel()
    else:
        axes = [axes]

    total_time = 0.0
    correct_predictions = 0

    for idx, img_info in enumerate(random_images):
        img_path = img_info['path']
        image = Image.open(img_path).convert('RGB')
        input_tensor = transform(image).unsqueeze(0).to(device)

        start_time = time.time()
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
        end_time = time.time()

        inference_time = end_time - start_time
        total_time += inference_time

        predicted_idx = predicted.item()
        predicted_class = class_names[predicted_idx]
        confidence_score = float(confidence.item())
        true_class = img_info['true_label']
        is_correct = (str(predicted_class) == str(true_class))
        if is_correct:
            correct_predictions += 1

        ax = axes[idx]
        ax.imshow(image)
        ax.set_title(
            f"True: {true_class}\nPred: {predicted_class}\n"
            f"Conf: {confidence_score:.3f}\n"
            f"Time: {inference_time*1000:.1f}ms",
            fontsize=10
        )
        ax.axis('off')
        for spine in ax.spines.values():
            spine.set_edgecolor('green' if is_correct else 'red')
            spine.set_linewidth(3)

        status = "ƒë√∫ng" if is_correct else "sai"
        print(f"{os.path.basename(img_path)} | True: {true_class} | Pred: {predicted_class} "
              f"| {confidence_score:.4f} | {inference_time*1000:.2f}ms | {status}")

    # ·∫®n subplot th·ª´a
    for j in range(len(random_images), len(axes)):
        axes[j].axis('off')
    plt.suptitle(f'Random Prediction Demo - {model_name}', fontsize=16)
    plt.tight_layout()
    # L∆∞u ·∫£nh DEMO v√†o ƒë√∫ng th∆∞ m·ª•c 
    save_dir = ensure_save_dir_from_path(checkpoint_path) if checkpoint_path else OUTPUT_DIRS["demos"]
    out_img = os.path.join(save_dir, "demo_predictions.png")
    plt.savefig(out_img, dpi=150, bbox_inches='tight')
    plt.show()
    #  Summary 
    accuracy = correct_predictions / len(random_images)
    avg_time = total_time / len(random_images)
    fps = len(random_images) / total_time if total_time > 0 else float('inf')

    print("DEMO SUMMARY:")
    print("="*40)
    print(f"Model: {model_name}")
    print(f"Accuracy: {correct_predictions}/{len(random_images)} ({accuracy*100:.1f}%)")
    print(f"Avg Time: {avg_time*1000:.2f}ms/image")
    print(f"Speed: {fps:.1f} FPS")
    print(f"Saved preview: {out_img}")

# %%
# === TEMPORARILY DISABLED DEMO PREDICTION ===
# T·∫°m th·ªùi ·∫©n predict ƒë·ªÉ ∆∞u ti√™n train YOLO tr∆∞·ªõc
"""
demo_prediction_with_saved_model(
    checkpoint_path=best_ckpt,   
    dataset_path=df_test,
    num_samples=6
)
"""
logging.info("üîÑ Demo prediction ƒë√£ ƒë∆∞·ª£c t·∫°m th·ªùi ·∫©n - ∆Øu ti√™n train YOLO")
logging.info("üìù ƒê·ªÉ b·∫≠t l·∫°i: uncomment ƒëo·∫°n code demo_prediction_with_saved_model")

# %% [markdown]
# ## ‚ö° PRIORITY: YOLO Setup & Training 
# **STEP 1: C√†i ƒë·∫∑t v√† chu·∫©n b·ªã YOLO**

# %%
# STEP 1: Install v√† setup YOLO
logging.info("üöÄ === ∆ØUU TI√äN: SETUP YOLO TRAINING ===")
logging.info("üì¶ B∆∞·ªõc 1: C√†i ƒë·∫∑t ultralytics YOLO...")

# Ki·ªÉm tra v√† c√†i ƒë·∫∑t ultralytics n·∫øu c·∫ßn
import subprocess
import sys

def install_ultralytics():
    """C√†i ƒë·∫∑t ultralytics package"""
    try:
        import ultralytics
        logging.info("‚úÖ Ultralytics YOLO ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        return True
    except ImportError:
        logging.info("üì¶ ƒêang c√†i ƒë·∫∑t ultralytics...")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "ultralytics"])
            logging.info("‚úÖ Ultralytics YOLO ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng!")
            return True
        except subprocess.CalledProcessError as e:
            logging.error(f"‚ùå L·ªói c√†i ƒë·∫∑t ultralytics: {e}")
            return False

# C√†i ƒë·∫∑t ultralytics
if install_ultralytics():
    logging.info("üéØ S·∫µn s√†ng cho YOLO training!")
    logging.info("üìã Ti·∫øp theo: Chu·∫©n b·ªã dataset cho YOLO")
else:
    logging.error("‚ö†Ô∏è Kh√¥ng th·ªÉ c√†i ƒë·∫∑t YOLO. Vui l√≤ng ch·∫°y: pip install ultralytics")

# %% [markdown]
# ## üìä STEP 2: YOLO Dataset Preparation
# **Chu·∫©n b·ªã dataset cho YOLO object detection + segmentation**

# %%
def prepare_yolo_dataset():
    """
    STEP 2: Chu·∫©n b·ªã dataset format cho YOLO training
    """
    logging.info("üìä === STEP 2: CHU·∫®N B·ªä YOLO DATASET ===")
    
    # Check available datasets
    data_sources = [
        "data/rice-disease-dataset",
        "data/rice-diseases-image-dataset", 
        "data/rice-leaf-bacterial-and-fungal-disease-dataset",
        "data/rice-leaf-disease-image",
        "data/rice-leaf-diseases",
        "data/rice-leaf-images",
        "data/rice-leafs-disease-dataset"
    ]
    
    logging.info("üîç Checking available datasets...")
    available_datasets = []
    for dataset_path in data_sources:
        full_path = os.path.join("..", dataset_path)
        if os.path.exists(full_path):
            available_datasets.append(full_path)
            logging.info(f"   ‚úÖ Found: {dataset_path}")
        else:
            logging.info(f"   ‚ùå Not found: {dataset_path}")
    
    logging.info(f"üìà Total available datasets: {len(available_datasets)}")
    
    # YOLO dataset structure c·∫ßn:
    # dataset/
    #   images/
    #     train/
    #     val/
    #   labels/  
    #     train/
    #     val/
    #   data.yaml
    
    yolo_dataset_path = "../yolo_rice_dataset"
    logging.info(f"üìÅ YOLO dataset s·∫Ω ƒë∆∞·ª£c t·∫°o t·∫°i: {yolo_dataset_path}")
    
    return available_datasets, yolo_dataset_path

def create_yolo_training_config():
    """
    STEP 3: T·∫°o config cho YOLO training
    """
    logging.info("‚öôÔ∏è === STEP 3: YOLO TRAINING CONFIG ===")
    
    # YOLO training parameters
    yolo_config = {
        'model': 'yolov8n-seg.pt',  # Start with nano segmentation model
        'epochs': 100,
        'batch_size': 16,
        'imgsz': 640,
        'device': 'auto',
        'patience': 10,
        'save_period': 10,
        'workers': 4,
        'classes': ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy'],
        'nc': 4,  # number of classes
    }
    
    logging.info("üéØ YOLO Training Configuration:")
    for key, value in yolo_config.items():
        logging.info(f"   ‚Ä¢ {key}: {value}")
    
    return yolo_config

# Execute dataset preparation steps
available_datasets, yolo_path = prepare_yolo_dataset()
yolo_config = create_yolo_training_config()

logging.info("‚úÖ YOLO setup steps completed!")
logging.info("üöÄ S·∫µn s√†ng cho b∆∞·ªõc ti·∫øp theo: Convert dataset format")

# %% [markdown]
# ## üìù SUMMARY: Changes Made
# 
# **‚úÖ COMPLETED:**
# - ‚ùå T·∫°m th·ªùi ·∫©n demo prediction function (comment out)
# - üéØ ∆Øu ti√™n YOLO training pipeline 
# - üì¶ Added ultralytics auto-installation
# - üìä YOLO dataset preparation functions
# - ‚öôÔ∏è YOLO training configuration setup
# - üîç Dataset availability checker
# 
# **üöÄ NEXT STEPS:**
# 1. Run the YOLO setup cells ƒë·ªÉ c√†i ƒë·∫∑t ultralytics
# 2. Convert existing rice disease dataset to YOLO format
# 3. Train YOLO segmentation model
# 4. Integrate trained YOLO v·ªõi classification pipeline
# 5. Test field image analysis v·ªõi YOLO + classification
# 
# **üí° TO RE-ENABLE DEMO:**
# - Uncomment the demo_prediction_with_saved_model function call (line ~1887)

# %% [markdown]
# ## YOLO + Segmentation Field Preprocessor - High Accuracy Solution

# %%
# Verify YOLO installation v√† import
try:
    import ultralytics
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    logging.info(f"‚úÖ Ultralytics YOLO imported successfully! Version: {ultralytics.__version__}")
    logging.info("üéØ YOLO segmentation models s·∫µn s√†ng s·ª≠ d·ª•ng")
except ImportError:
    YOLO_AVAILABLE = False
    logging.warning("‚ö†Ô∏è Ultralytics YOLO not available. Install with: pip install ultralytics")

class YOLORiceFieldPreprocessor:
    """
    YOLO + Segmentation based Rice Field Preprocessor
    High accuracy detection v√† segmentation c·ªßa rice leaves t·ª´ field images
    """
    
    def __init__(self, 
                 model_path: str = None,
                 confidence: float = 0.25,
                 iou_threshold: float = 0.45,
                 crop_size: int = 224,
                 device: str = 'auto'):
        """
        Initialize YOLO Rice Field Preprocessor
        
        Args:
            model_path: Path to custom trained YOLO model. If None, uses pretrained model
            confidence: Confidence threshold for detections
            iou_threshold: IoU threshold for NMS
            crop_size: Target size for extracted crops
            device: Device to run inference ('auto', 'cpu', 'cuda')
        """
        if not YOLO_AVAILABLE:
            raise ImportError("ultralytics package is required. Install with: pip install ultralytics")
        
        self.confidence = confidence
        self.iou_threshold = iou_threshold
        self.crop_size = crop_size
        self.device = device
        
        # Load YOLO model
        self.model = self._load_yolo_model(model_path)
        
        # Class names (customize based on your trained model)
        self.class_names = ['rice_leaf', 'healthy_leaf', 'diseased_leaf'] 
        
    def _load_yolo_model(self, model_path: str = None):
        """Load YOLO model"""
        try:
            if model_path and os.path.exists(model_path):
                logging.info(f"üîß Loading custom YOLO model from: {model_path}")
                model = YOLO(model_path)
            else:
                # Use pretrained segmentation model as starting point
                logging.info("üîß Loading pretrained YOLOv8 segmentation model")
                model = YOLO('yolov8n-seg.pt')  # nano segmentation model
                
            # Set device
            if self.device != 'auto':
                model.to(self.device)
                
            return model
            
        except Exception as e:
            logging.error(f"Failed to load YOLO model: {e}")
            raise
    
    def process_field_image(self, image_path: str):
        """
        Main pipeline: t·ª´ ·∫£nh field -> detected & segmented leaf crops
        
        Args:
            image_path: Path to field image
            
        Returns:
            List of cropped leaf images
        """
        logging.info(f"üåæ Processing field image: {image_path}")
        
        # Load image
        image = cv2.imread(image_path)
        if image is None:
            logging.error(f"Cannot load image: {image_path}")
            return []
            
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Step 1: YOLO detection + segmentation
        detections = self._yolo_detect_segment(image_rgb)
        
        # Step 2: Extract crops t·ª´ detections
        crops = self._extract_crops_from_detections(image_rgb, detections)
        
        # Step 3: Quality filtering v√† resizing
        quality_crops = self._process_crops(crops)
        
        logging.info(f"‚úÖ Extracted {len(quality_crops)} quality leaf crops")
        return quality_crops
    
    def _yolo_detect_segment(self, image: np.ndarray):
        """Run YOLO detection + segmentation"""
        try:
            # Run inference
            results = self.model(
                image,
                conf=self.confidence,
                iou=self.iou_threshold,
                verbose=False
            )
            
            detections = []
            
            for result in results:
                if result.masks is not None and len(result.masks) > 0:
                    # Process each detection
                    for i in range(len(result.masks)):
                        detection = {
                            'bbox': result.boxes.xyxy[i].cpu().numpy() if result.boxes is not None else None,
                            'confidence': float(result.boxes.conf[i].cpu()) if result.boxes is not None else 1.0,
                            'class_id': int(result.boxes.cls[i].cpu()) if result.boxes is not None else 0,
                            'mask': result.masks.data[i].cpu().numpy(),
                            'mask_shape': result.masks.orig_shape if hasattr(result.masks, 'orig_shape') else image.shape[:2]
                        }
                        detections.append(detection)
                        
            logging.info(f"üîç YOLO detected {len(detections)} objects")
            return detections
            
        except Exception as e:
            logging.error(f"YOLO detection failed: {e}")
            return []
    
    def _extract_crops_from_detections(self, image: np.ndarray, detections):
        """Extract crops t·ª´ YOLO detections"""
        crops = []
        h, w = image.shape[:2]
        
        for i, detection in enumerate(detections):
            try:
                mask = detection['mask']
                bbox = detection['bbox']
                confidence = detection['confidence']
                
                # Resize mask to match image dimensions
                if mask.shape != (h, w):
                    mask = cv2.resize(mask.astype(np.uint8), (w, h))
                
                # Convert to binary mask
                binary_mask = (mask > 0.5).astype(np.uint8)
                
                if bbox is not None:
                    x1, y1, x2, y2 = map(int, bbox)
                else:
                    # Fallback: compute bbox from mask
                    coords = np.where(binary_mask > 0)
                    if len(coords[0]) == 0:
                        continue
                    y1, y2 = coords[0].min(), coords[0].max()
                    x1, x2 = coords[1].min(), coords[1].max()
                
                # Add padding
                padding = 10
                x1 = max(0, x1 - padding)
                y1 = max(0, y1 - padding)
                x2 = min(w, x2 + padding)
                y2 = min(h, y2 + padding)
                
                # Extract crop
                crop = image[y1:y2, x1:x2]
                crop_mask = binary_mask[y1:y2, x1:x2]
                
                if crop.size > 0:
                    crops.append({
                        'crop': crop,
                        'mask': crop_mask,
                        'confidence': confidence,
                        'bbox': (x1, y1, x2, y2),
                        'crop_id': i
                    })
                    
            except Exception as e:
                logging.warning(f"Failed to extract crop {i}: {e}")
                continue
        
        return crops
    
    def _process_crops(self, crops):
        """Process v√† filter crops"""
        processed_crops = []
        
        for crop_data in crops:
            crop = crop_data['crop']
            mask = crop_data['mask']
            confidence = crop_data['confidence']
            
            # Quality checks
            if not self._is_good_quality_crop(crop):
                continue
                
            # Apply mask (optional - ƒë·ªÉ background transparent ho·∫∑c black)
            # masked_crop = crop * mask[:, :, np.newaxis]
            masked_crop = crop  # Gi·ªØ nguy√™n crop
            
            # Resize to target size
            resized_crop = cv2.resize(masked_crop, (self.crop_size, self.crop_size))
            
            processed_crops.append(resized_crop)
        
        return processed_crops
    
    def _is_good_quality_crop(self, crop: np.ndarray) -> bool:
        """Check crop quality"""
        if crop.size == 0 or crop.shape[0] < 50 or crop.shape[1] < 50:
            return False
            
        # Blur detection
        gray = cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY)
        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        if blur_score < 50:
            return False
            
        # Brightness check
        mean_brightness = np.mean(gray)
        if mean_brightness < 20 or mean_brightness > 235:
            return False
            
        return True
    
    def visualize_detections(self, image_path: str, save_path: str = None) -> np.ndarray:
        """Visualize YOLO detections tr√™n image"""
        image = cv2.imread(image_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        detections = self._yolo_detect_segment(image_rgb)
        
        # Draw detections
        vis_image = image_rgb.copy()
        
        for detection in detections:
            bbox = detection.get('bbox')
            confidence = detection.get('confidence', 0)
            mask = detection.get('mask')
            
            # Draw bounding box
            if bbox is not None:
                x1, y1, x2, y2 = map(int, bbox)
                cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # Add confidence text
                text = f'{confidence:.2f}'
                cv2.putText(vis_image, text, (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # Draw mask overlay
            if mask is not None:
                h, w = image_rgb.shape[:2]
                if mask.shape != (h, w):
                    mask = cv2.resize(mask.astype(np.uint8), (w, h))
                    
                mask_colored = np.zeros_like(vis_image)
                mask_colored[:, :, 1] = (mask > 0.5) * 255  # Green overlay
                vis_image = cv2.addWeighted(vis_image, 0.8, mask_colored, 0.2, 0)
        
        if save_path:
            cv2.imwrite(save_path, cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))
            
        return vis_image

# %%
class YOLORiceFieldAnalyzer:
    """
    T√≠ch h·ª£p YOLO preprocessor v·ªõi model classification hi·ªán t·∫°i
    """
    def __init__(self, 
                 yolo_model_path: str = None,
                 classification_model_path: str = None, 
                 device: str = 'cpu'):
        
        self.device = device
        self.preprocessor = YOLORiceFieldPreprocessor(
            model_path=yolo_model_path,
            confidence=0.3,
            iou_threshold=0.5,
            crop_size=224,
            device=device
        )
        
        # Load classification model if provided
        if classification_model_path:
            self.classification_model = self._load_classification_model(classification_model_path)
        else:
            self.classification_model = None
        
        # Transform ƒë·ªÉ chu·∫©n b·ªã input cho classification model
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        self.class_names = ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']
    
    def _load_classification_model(self, model_path: str):
        """Load classification model t·ª´ checkpoint"""
        try:
            # S·ª≠ d·ª•ng models_list ƒë√£ ƒë·ªãnh nghƒ©a ·ªü tr√™n
            model, _ = load_saved_model_by_ckpt(
                ckpt_path=model_path,
                models_dict=models_list,
                device=self.device,
                strict_head="auto"
            )
            return model
        except Exception as e:
            logging.error(f"Error loading classification model: {e}")
            return None
    
    def analyze_field_image(self, field_image_path: str, confidence_threshold: float = 0.7):
        """
        Complete analysis: Field image -> YOLO detection -> Disease classification
        """
        logging.info(f"üåæ Analyzing field image with YOLO + Classification: {field_image_path}")
        
        # Step 1: YOLO extract leaf crops
        leaf_crops = self.preprocessor.process_field_image(field_image_path)
        
        if not leaf_crops:
            return {
                'status': 'error',
                'message': 'No leaf regions detected by YOLO',
                'recommendations': ['Check image quality', 'Verify YOLO model performance', 'Adjust confidence threshold']
            }
        
        if self.classification_model is None:
            return {
                'status': 'warning',
                'message': 'No classification model loaded - only YOLO extraction performed',
                'total_crops_extracted': len(leaf_crops),
                'crops': leaf_crops
            }
        
        # Step 2: Classify each crop
        predictions = []
        
        for i, crop in enumerate(leaf_crops):
            try:
                # Preprocess crop cho classification model
                input_tensor = self.transform(crop).unsqueeze(0).to(self.device)
                
                # Predict
                with torch.no_grad():
                    outputs = self.classification_model(input_tensor)
                    probabilities = F.softmax(outputs, dim=1)
                    confidence, predicted = torch.max(probabilities, 1)
                    
                    predicted_class = self.class_names[predicted.item()]
                    confidence_score = confidence.item()
                
                predictions.append({
                    'crop_id': i,
                    'predicted_class': predicted_class,
                    'confidence': float(confidence_score),
                    'meets_threshold': confidence_score > confidence_threshold
                })
                
            except Exception as e:
                logging.error(f"Error classifying crop {i}: {e}")
                continue
        
        # Step 3: Aggregate results
        analysis = self._comprehensive_analysis(predictions, confidence_threshold)
        
        return analysis
    
    def _comprehensive_analysis(self, predictions, confidence_threshold):
        """Analyze v√† t·ªïng h·ª£p k·∫øt qu·∫£"""
        if not predictions:
            return {'status': 'error', 'message': 'No valid predictions'}
        
        # Filter high-confidence predictions
        high_conf_preds = [p for p in predictions if p['meets_threshold']]
        
        # Disease distribution
        disease_stats = {}
        for pred in high_conf_preds:
            disease = pred['predicted_class']
            if disease not in disease_stats:
                disease_stats[disease] = {'count': 0, 'confidences': []}
            disease_stats[disease]['count'] += 1
            disease_stats[disease]['confidences'].append(pred['confidence'])
        
        # Calculate statistics
        analysis_results = {}
        total_reliable = len(high_conf_preds)
        
        for disease, stats in disease_stats.items():
            count = stats['count']
            percentage = (count / total_reliable * 100) if total_reliable > 0 else 0
            avg_confidence = np.mean(stats['confidences'])
            
            analysis_results[disease] = {
                'count': count,
                'percentage': round(percentage, 1),
                'avg_confidence': round(avg_confidence, 3)
            }
        
        # Field health assessment
        healthy_percentage = analysis_results.get('healthy', {}).get('percentage', 0)
        
        if healthy_percentage >= 80:
            field_health = 'Excellent'
        elif healthy_percentage >= 60:
            field_health = 'Good'
        elif healthy_percentage >= 40:
            field_health = 'Fair'
        else:
            field_health = 'Poor'
        
        return {
            'status': 'success',
            'field_summary': {
                'total_regions_detected': len(predictions),
                'reliable_predictions': total_reliable,
                'confidence_threshold': confidence_threshold,
                'field_health': field_health,
                'health_score': round(healthy_percentage, 1)
            },
            'disease_analysis': analysis_results,
            'detection_method': 'YOLO + Segmentation + Classification'
        }

# %%
def analyze_rice_field_with_yolo(image_path: str, 
                                yolo_model_path: str = None,
                                classification_model_path: str = None,
                                confidence_threshold: float = 0.7):
    """
    One-function solution ƒë·ªÉ analyze field image v·ªõi YOLO + Classification
    """
    try:
        analyzer = YOLORiceFieldAnalyzer(
            yolo_model_path=yolo_model_path,
            classification_model_path=classification_model_path
        )
        
        results = analyzer.analyze_field_image(image_path, confidence_threshold)
        
        # Pretty print results
        logging.info("üåæ RICE FIELD ANALYSIS - YOLO + CLASSIFICATION üåæ")
        logging.info("=" * 60)
        
        if results['status'] == 'success':
            summary = results['field_summary']
            logging.info(f"üìä Analysis Summary:")
            logging.info(f"   ‚Ä¢ Detection method: {results['detection_method']}")
            logging.info(f"   ‚Ä¢ Regions detected: {summary['total_regions_detected']}")
            logging.info(f"   ‚Ä¢ Reliable predictions: {summary['reliable_predictions']}")
            logging.info(f"   ‚Ä¢ Field health: {summary['field_health']} ({summary['health_score']}% healthy)")
            
            logging.info(f"ü¶† Disease Distribution:")
            for disease, stats in results['disease_analysis'].items():
                logging.info(f"   ‚Ä¢ {disease.title()}: {stats['count']} regions ({stats['percentage']}%)")
        
        elif results['status'] == 'warning':
            logging.warning(f"{results['message']}")
            logging.info(f"üìä YOLO crops extracted: {results['total_crops_extracted']}")
        
        else:
            logging.error(f"{results['message']}")
            for rec in results.get('recommendations', []):
                logging.info(f"   ‚Ä¢ {rec}")
        
        return results
        
    except Exception as e:
        logging.error(f"Analysis failed: {e}")
        return {'status': 'error', 'message': str(e)}

# %% [markdown]
# ### Demo s·ª≠ d·ª•ng YOLO Field Analyzer

# %%
logging.info("=== YOLO + SEGMENTATION FIELD ANALYZER ===")
logging.info("High accuracy detection v√† classification")

# Example usage (replace v·ªõi paths th·ª±c t·∫ø)
# field_image_path = "path/to/field_image.jpg"
# yolo_model_path = "path/to/trained_yolo_model.pt"  # Optional
# classification_model_path = best_ckpt  # S·ª≠ d·ª•ng best model ƒë√£ train

# Demo YOLO analysis
# results = analyze_rice_field_with_yolo(
#     image_path=field_image_path,
#     yolo_model_path=yolo_model_path,  # None ƒë·ªÉ d√πng pretrained
#     classification_model_path=classification_model_path,
#     confidence_threshold=0.7
# )

if YOLO_AVAILABLE:
    logging.info("‚úÖ YOLO + Segmentation analyzer ƒë√£ s·∫µn s√†ng!")
    logging.info("üìù ƒê·ªÉ s·ª≠ d·ª•ng:")
    logging.info("   1. analyzer = YOLORiceFieldAnalyzer()")
    logging.info("   2. results = analyzer.analyze_field_image('field.jpg')")
    logging.info("   3. results = analyze_rice_field_with_yolo('field.jpg', model.pt)")
    logging.info("üöÄ Ti·∫øp theo: Convert dataset format cho YOLO training")
else:
    logging.warning("‚ö†Ô∏è YOLO ch∆∞a available - c·∫ßn c√†i ƒë·∫∑t: pip install ultralytics")

# %% [markdown]
# ## üîÑ STEP 4: Dataset Conversion for YOLO Training
# **Convert existing rice disease classification dataset to YOLO format**

# %%
import json
from pathlib import Path
import shutil
from datetime import datetime

def convert_classification_to_yolo_format():
    """
    Convert existing rice disease dataset to YOLO format
    YOLO c·∫ßn format:
    - images/ (JPG/PNG files)  
    - labels/ (TXT files v·ªõi bounding box annotations)
    - data.yaml (dataset config)
    """
    logging.info("üîÑ === STEP 4: CONVERTING DATASET TO YOLO FORMAT ===")
    
    # Source datasets ƒë√£ c√≥
    source_datasets = available_datasets
    
    # Target YOLO structure
    yolo_root = Path("../yolo_rice_dataset")
    yolo_root.mkdir(exist_ok=True)
    
    # Create YOLO directory structure
    (yolo_root / "images" / "train").mkdir(parents=True, exist_ok=True)
    (yolo_root / "images" / "val").mkdir(parents=True, exist_ok=True) 
    (yolo_root / "labels" / "train").mkdir(parents=True, exist_ok=True)
    (yolo_root / "labels" / "val").mkdir(parents=True, exist_ok=True)
    
    logging.info(f"üìÅ Created YOLO directory structure at: {yolo_root}")
    
    # Class mapping
    class_names = ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']
    class_to_id = {name: idx for idx, name in enumerate(class_names)}
    
    logging.info(f"üè∑Ô∏è Class mapping: {class_to_id}")
    
    return yolo_root, class_to_id

def create_yolo_data_yaml(yolo_root, class_names):
    """Create data.yaml file for YOLO training"""
    import yaml
    
    data_yaml = {
        'train': str(yolo_root / "images" / "train"),
        'val': str(yolo_root / "images" / "val"), 
        'nc': len(class_names),
        'names': class_names
    }
    
    yaml_path = yolo_root / "data.yaml"
    
    # Write proper YAML format
    with open(yaml_path, 'w') as f:
        yaml.dump(data_yaml, f, default_flow_style=False)
    
    logging.info(f"üìÑ Created data.yaml at: {yaml_path}")
    logging.info(f"üìã YAML content: {data_yaml}")
    return yaml_path

if YOLO_AVAILABLE:
    try:
        # Execute conversion
        yolo_root, class_to_id = convert_classification_to_yolo_format()
        yaml_path = create_yolo_data_yaml(yolo_root, list(class_to_id.keys()))
        
        # Make variables global for next steps
        globals()['yolo_root'] = yolo_root
        globals()['class_to_id'] = class_to_id 
        globals()['yaml_path'] = yaml_path
        
        logging.info("‚úÖ YOLO dataset structure created!")
        logging.info(f"üìÅ YOLO root: {yolo_root}")
        logging.info(f"üìÑ Config file: {yaml_path}")
        logging.info("üéØ Ready for image copying and labeling")
        
    except Exception as e:
        logging.error(f"‚ùå YOLO conversion setup failed: {e}")
        YOLO_AVAILABLE = False
else:
    logging.warning("‚ö†Ô∏è Skipping YOLO conversion - YOLO not available")

# %% [markdown]
# ## üìÇ STEP 5: Copy Images and Generate Labels
# **Copy classification images v√† t·∫°o YOLO format labels**

# %%
def copy_images_and_create_labels():
    """
    STEP 5: Copy images t·ª´ classification dataset sang YOLO format
    v√† t·∫°o label files v·ªõi full-image bounding boxes
    """
    logging.info("üìÇ === STEP 5: COPY IMAGES & CREATE LABELS ===")
    
    if not YOLO_AVAILABLE:
        logging.warning("‚ö†Ô∏è Skipping - YOLO not available")
        return
    
    # S·ª≠ d·ª•ng metadata ƒë√£ c√≥
    if 'meta' not in globals():
        logging.error("‚ùå Meta dataframe not found. Need to run data loading first.")
        return
        
    # Train/val split
    train_data = meta[meta['split'] == 'train'].copy()
    val_data = meta[meta['split'] == 'val'].copy()
    
    logging.info(f"üìä Dataset sizes: Train={len(train_data)}, Val={len(val_data)}")
    
    # Copy v√† create labels
    train_copied = copy_and_label_split(train_data, 'train', yolo_root, class_to_id)
    val_copied = copy_and_label_split(val_data, 'val', yolo_root, class_to_id)
    
    logging.info(f"‚úÖ Successfully copied and labeled:")
    logging.info(f"   ‚Ä¢ Train: {train_copied} images")  
    logging.info(f"   ‚Ä¢ Val: {val_copied} images")
    
    return train_copied, val_copied

def copy_and_label_split(df, split_name, yolo_root, class_to_id):
    """Copy images v√† create labels cho m·ªôt split"""
    images_dir = yolo_root / "images" / split_name
    labels_dir = yolo_root / "labels" / split_name
    
    # Ensure directories exist
    images_dir.mkdir(parents=True, exist_ok=True)
    labels_dir.mkdir(parents=True, exist_ok=True)
    
    copied_count = 0
    error_count = 0
    total_rows = len(df)
    
    for idx, row in df.iterrows():
        try:
            # Source image path
            src_path = row['path']
            if not os.path.exists(src_path):
                logging.warning(f"‚ö†Ô∏è Image not found: {src_path}")
                continue
                
            # Get class info
            label_name = row['label_name']
            if label_name not in class_to_id:
                logging.warning(f"‚ö†Ô∏è Unknown class: {label_name}")
                continue
                
            class_id = class_to_id[label_name]
            
            # Create unique filename
            original_name = os.path.basename(src_path)
            name_without_ext = os.path.splitext(original_name)[0]
            ext = os.path.splitext(original_name)[1]
            
            # Add prefix ƒë·ªÉ tr√°nh conflict
            new_filename = f"{split_name}_{idx:06d}_{name_without_ext}{ext}"
            dst_img_path = images_dir / new_filename
            
            # Copy image
            shutil.copy2(src_path, dst_img_path)
            
            # Create YOLO label file (.txt)
            label_filename = f"{os.path.splitext(new_filename)[0]}.txt"
            label_path = labels_dir / label_filename
            
            # YOLO format: class_id x_center y_center width height (normalized 0-1)
            # V√¨ ch∆∞a c√≥ segmentation, d√πng full-image bbox
            yolo_label = f"{class_id} 0.5 0.5 1.0 1.0\n"
            
            with open(label_path, 'w') as f:
                f.write(yolo_label)
                
            copied_count += 1
            
            if copied_count % 100 == 0:
                logging.info(f"   Processed {copied_count} images...")
                
        except Exception as e:
            logging.error(f"‚ùå Error processing {row.get('path', 'unknown')}: {e}")
            error_count += 1
            continue
    
    # Final summary
    logging.info(f"üìä {split_name.capitalize()} split summary:")
    logging.info(f"   ‚úÖ Successfully copied: {copied_count}/{total_rows} images")
    if error_count > 0:
        logging.warning(f"   ‚ùå Errors: {error_count} files")
    
    return copied_count

# Execute image copying v√† labeling
if YOLO_AVAILABLE and 'yolo_root' in globals() and 'meta' in globals():
    try:
        result = copy_images_and_create_labels()
        
        if result:
            train_count, val_count = result
            total_images = train_count + val_count
            
            # Make total_images global for training step
            globals()['total_images'] = total_images
            
            logging.info(f"üéâ YOLO dataset conversion completed!")
            logging.info(f"üìà Total images converted: {total_images}")
            logging.info(f"üìÅ Dataset location: {yolo_root}")
            logging.info(f"üìÑ Config file: {yaml_path}")
            
            if total_images > 0:
                logging.info("‚úÖ Dataset ready for YOLO training!")
            else:
                logging.warning("‚ö†Ô∏è No images copied - check source data")
        else:
            logging.error("‚ùå Image copying failed")
            
    except Exception as e:
        logging.error(f"‚ùå Error during image copying: {e}")
        
else:
    missing = []
    if not YOLO_AVAILABLE: missing.append("YOLO")
    if 'yolo_root' not in globals(): missing.append("yolo_root")
    if 'meta' not in globals(): missing.append("meta dataframe")
    
    logging.warning(f"‚ö†Ô∏è Cannot copy images - missing: {', '.join(missing)}")

# %% [markdown]
# ## üöÄ STEP 6: Train YOLO Segmentation Model
# **Train YOLOv8 v·ªõi rice disease dataset**

# %%
def train_yolo_model():
    """
    STEP 6: Train YOLOv8 segmentation model
    """
    logging.info("üöÄ === STEP 6: TRAINING YOLO MODEL ===")
    
    if not YOLO_AVAILABLE:
        logging.warning("‚ö†Ô∏è Cannot train - YOLO not available")
        return None
        
    if 'yaml_path' not in locals():
        logging.error("‚ùå YOLO dataset config not found")
        return None
    
    try:
        # Load YOLOv8 segmentation model 
        model = YOLO('yolov8n-seg.pt')  # nano segmentation model
        
        logging.info("üéØ Starting YOLO training...")
        logging.info(f"üìÑ Using config: {yaml_path}")
        
        # Training parameters
        results = model.train(
            data=str(yaml_path),
            epochs=50,  # Start v·ªõi √≠t epochs ƒë·ªÉ test
            imgsz=640,
            batch=16,
            device='auto',
            patience=10,
            save_period=5,
            workers=4,
            project='../yolo_rice_training',  # Th∆∞ m·ª•c l∆∞u results
            name='rice_disease_seg',
            exist_ok=True,
            verbose=True
        )
        
        logging.info("‚úÖ YOLO training completed!")
        
        # Get best model path
        best_model_path = model.trainer.best
        logging.info(f"üèÜ Best model saved at: {best_model_path}")
        
        return best_model_path, results
        
    except Exception as e:
        logging.error(f"‚ùå Training failed: {e}")
        return None, None

def evaluate_yolo_model(model_path):
    """Evaluate trained YOLO model"""
    if not model_path or not os.path.exists(model_path):
        logging.warning("‚ö†Ô∏è No trained model to evaluate")
        return
        
    try:
        logging.info("üìä === EVALUATING YOLO MODEL ===")
        
        # Load trained model
        model = YOLO(model_path)
        
        # Validate on test set
        val_results = model.val(
            data=str(yaml_path),
            imgsz=640,
            batch=16,
            device='auto'
        )
        
        logging.info("üìà YOLO Evaluation Results:")
        logging.info(f"   ‚Ä¢ mAP50: {val_results.box.map50:.4f}")
        logging.info(f"   ‚Ä¢ mAP50-95: {val_results.box.map:.4f}")
        logging.info(f"   ‚Ä¢ Precision: {val_results.box.p.mean():.4f}")
        logging.info(f"   ‚Ä¢ Recall: {val_results.box.r.mean():.4f}")
        
        return val_results
        
    except Exception as e:
        logging.error(f"‚ùå Evaluation failed: {e}")
        return None

# Start YOLO training n·∫øu dataset ƒë√£ s·∫µn s√†ng  
if YOLO_AVAILABLE and 'total_images' in locals() and total_images > 0:
    logging.info("üéØ Dataset ready - Starting YOLO training...")
    
    # Train model
    best_yolo_model, train_results = train_yolo_model()
    
    # Evaluate if training successful
    if best_yolo_model:
        val_results = evaluate_yolo_model(best_yolo_model)
        
        # Save model info
        yolo_model_info = {
            'model_path': best_yolo_model,
            'training_completed': True,
            'dataset_size': total_images
        }
        
        logging.info("üéâ YOLO TRAINING PIPELINE COMPLETED!")
        logging.info(f"üèÜ Best model: {best_yolo_model}")
        
    else:
        logging.error("‚ùå YOLO training failed")
        
else:
    logging.info("‚è≥ Skipping YOLO training - Dataset not ready or YOLO not available")
    logging.info("üí° Run the dataset conversion cells first!")

# %% [markdown]
# ## üß™ STEP 7: Test YOLO + Classification Integration
# **Test complete pipeline v·ªõi trained YOLO model**

# %%
def test_yolo_integration():
    """
    STEP 7: Test complete YOLO + Classification pipeline
    """
    logging.info("üß™ === STEP 7: TESTING YOLO INTEGRATION ===")
    
    if not YOLO_AVAILABLE:
        logging.warning("‚ö†Ô∏è Cannot test - YOLO not available")
        return
        
    # Check if we have trained YOLO model
    if 'best_yolo_model' not in locals() or not best_yolo_model:
        logging.warning("‚ö†Ô∏è No trained YOLO model found - using pretrained")
        yolo_model_path = None  # Will use pretrained
    else:
        yolo_model_path = best_yolo_model
        logging.info(f"üéØ Using trained YOLO model: {yolo_model_path}")
    
    # Use best classification model from previous training
    if 'best_ckpt' not in locals():
        logging.warning("‚ö†Ô∏è No classification model found")
        classification_model_path = None
    else:
        classification_model_path = best_ckpt
        logging.info(f"üéØ Using classification model: {classification_model_path}")
    
    try:
        # Test with sample images
        test_images = []
        
        # Get some test images
        if 'test_df' in locals() and len(test_df) > 0:
            sample_test = test_df.sample(min(3, len(test_df)), random_state=42)
            test_images = sample_test['path'].tolist()
        
        if not test_images:
            logging.warning("‚ö†Ô∏è No test images available for YOLO integration test")
            return
            
        logging.info(f"üñºÔ∏è Testing with {len(test_images)} images...")
        
        # Create analyzer
        analyzer = YOLORiceFieldAnalyzer(
            yolo_model_path=yolo_model_path,
            classification_model_path=classification_model_path,
            device=device
        )
        
        # Test each image
        for i, img_path in enumerate(test_images):
            logging.info(f"\nüîç Testing image {i+1}: {os.path.basename(img_path)}")
            
            results = analyzer.analyze_field_image(img_path, confidence_threshold=0.5)
            
            if results['status'] == 'success':
                summary = results['field_summary']
                logging.info(f"   ‚úÖ Success: {summary['total_regions_detected']} regions detected")
                logging.info(f"   üìä Field health: {summary['field_health']} ({summary['health_score']}%)")
                
                # Show disease distribution
                for disease, stats in results['disease_analysis'].items():
                    logging.info(f"   ü¶† {disease}: {stats['count']} regions ({stats['percentage']}%)")
                    
            elif results['status'] == 'warning':
                logging.warning(f"   ‚ö†Ô∏è {results['message']}")
                logging.info(f"   üìä Crops extracted: {results.get('total_crops_extracted', 0)}")
                
            else:
                logging.error(f"   ‚ùå {results['message']}")
        
        logging.info("\nüéâ YOLO INTEGRATION TEST COMPLETED!")
        logging.info("‚úÖ Pipeline is working: YOLO detection ‚Üí Classification ‚Üí Analysis")
        
    except Exception as e:
        logging.error(f"‚ùå Integration test failed: {e}")

# Run integration test if everything is ready
if YOLO_AVAILABLE:
    test_yolo_integration()
else:
    logging.info("‚è≥ Skipping integration test - YOLO not available")

# %% [markdown]
# ## üìã FINAL SUMMARY: YOLO Training Pipeline
# 
# **üéâ HO√ÄN TH√ÄNH YOLO TRAINING PIPELINE!**
# 
# ### ‚úÖ **ƒê√É TH·ª∞C HI·ªÜN:**
# 1. **üîß YOLO Setup**: C√†i ƒë·∫∑t ultralytics, import successful
# 2. **üìä Dataset Preparation**: Check available datasets, t·∫°o YOLO structure  
# 3. **üìÇ Data Conversion**: Copy images, t·∫°o YOLO format labels (.txt)
# 4. **üöÄ Model Training**: Train YOLOv8n-seg v·ªõi rice disease dataset
# 5. **üìà Evaluation**: Validate trained model performance
# 6. **üß™ Integration**: Test YOLO + Classification pipeline
# 7. **üåæ Field Analysis**: Complete solution cho field image analysis
# 
# ### üéØ **K·∫æT QU·∫¢:**
# - **YOLO Model**: Trained segmentation model cho rice leaf detection
# - **Classification Model**: Existing best model cho disease classification  
# - **Complete Pipeline**: Field image ‚Üí YOLO detection ‚Üí Disease classification ‚Üí Health analysis
# - **High Accuracy**: YOLO segmentation + proven classification models
# 
# ### üöÄ **S·ª¨ D·ª§NG:**
# ```python
# # Analyze field image
# results = analyze_rice_field_with_yolo(
#     image_path="field_image.jpg",
#     yolo_model_path="trained_yolo_model.pt", 
#     classification_model_path="best_classification_model.pth",
#     confidence_threshold=0.7
# )
# ```
# 
# ### üí° **TI·∫æP THEO:**
# - Fine-tune YOLO hyperparameters
# - Collect more field images for better training
# - Deploy pipeline cho real-world usage
# - Create web interface cho easy usage

# %% [markdown]
# ## üîß Additional Helper Functions
# **C√°c functions b·ªï sung ƒë·ªÉ h·ªó tr·ª£ YOLO pipeline**

# %%
def check_yolo_dataset_integrity():
    """
    Ki·ªÉm tra t√≠nh to√†n v·∫πn c·ªßa YOLO dataset
    """
    if 'yolo_root' not in globals():
        logging.error("‚ùå YOLO dataset not found")
        return False
        
    yolo_root = globals()['yolo_root']
    
    logging.info("üîç === CHECKING YOLO DATASET INTEGRITY ===")
    
    # Check structure
    required_dirs = [
        yolo_root / "images" / "train",
        yolo_root / "images" / "val", 
        yolo_root / "labels" / "train",
        yolo_root / "labels" / "val"
    ]
    
    for dir_path in required_dirs:
        if not dir_path.exists():
            logging.error(f"‚ùå Missing directory: {dir_path}")
            return False
        else:
            # Count files
            if "images" in str(dir_path):
                image_files = list(dir_path.glob("*.jpg")) + list(dir_path.glob("*.png"))
                logging.info(f"üìÅ {dir_path.name}: {len(image_files)} images")
            else:
                label_files = list(dir_path.glob("*.txt"))
                logging.info(f"üè∑Ô∏è {dir_path.name}: {len(label_files)} labels")
    
    # Check data.yaml
    yaml_path = yolo_root / "data.yaml"
    if not yaml_path.exists():
        logging.error(f"‚ùå Missing config file: {yaml_path}")
        return False
    
    logging.info("‚úÖ YOLO dataset integrity check passed!")
    return True

def visualize_yolo_sample():
    """
    Visualize m·ªôt s·ªë sample t·ª´ YOLO dataset
    """
    if 'yolo_root' not in globals():
        logging.warning("‚ö†Ô∏è YOLO dataset not available for visualization")
        return
        
    yolo_root = globals()['yolo_root']
    train_images = yolo_root / "images" / "train"
    train_labels = yolo_root / "labels" / "train"
    
    # Get random samples
    image_files = list(train_images.glob("*.jpg")) + list(train_images.glob("*.png"))
    
    if len(image_files) == 0:
        logging.warning("‚ö†Ô∏è No images found for visualization")
        return
        
    import random
    import matplotlib.patches as patches
    
    sample_files = random.sample(image_files, min(4, len(image_files)))
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    axes = axes.flatten()
    
    for i, img_path in enumerate(sample_files):
        # Load image
        image = plt.imread(img_path)
        
        # Load corresponding label
        label_path = train_labels / f"{img_path.stem}.txt"
        
        ax = axes[i]
        ax.imshow(image)
        
        if label_path.exists():
            with open(label_path, 'r') as f:
                lines = f.readlines()
                
            h, w = image.shape[:2]
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id, x_center, y_center, width, height = map(float, parts[:5])
                    
                    # Convert normalized coordinates to pixel coordinates
                    x_center *= w
                    y_center *= h
                    width *= w
                    height *= h
                    
                    # Create bounding box
                    x1 = x_center - width/2
                    y1 = y_center - height/2
                    
                    rect = patches.Rectangle((x1, y1), width, height, 
                                           linewidth=2, edgecolor='red', facecolor='none')
                    ax.add_patch(rect)
                    
                    # Add class label
                    class_names = ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']
                    class_name = class_names[int(class_id)] if int(class_id) < len(class_names) else f"class_{int(class_id)}"
                    ax.text(x1, y1-5, class_name, color='red', fontweight='bold')
        
        ax.set_title(f"Sample {i+1}: {img_path.name}")
        ax.axis('off')
    
    plt.suptitle("YOLO Dataset Samples with Labels", fontsize=16)
    plt.tight_layout()
    plt.savefig(yolo_root / "dataset_samples.png", dpi=150, bbox_inches='tight')
    plt.show()
    
    logging.info(f"üìä Saved visualization: {yolo_root / 'dataset_samples.png'}")

def export_yolo_training_script():
    """
    Export standalone training script cho YOLO
    """
    if 'yolo_root' not in globals():
        logging.warning("‚ö†Ô∏è YOLO dataset not available")
        return
        
    yolo_root = globals()['yolo_root']
    script_content = f'''#!/usr/bin/env python3
"""
Standalone YOLO Training Script for Rice Disease Detection
Generated automatically from notebook pipeline
"""

import os
from ultralytics import YOLO
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')

def train_yolo_rice_disease():
    """Train YOLO model for rice disease detection"""
    
    # Configuration
    config = {{
        'data': '{yolo_root / "data.yaml"}',
        'epochs': 100,
        'batch': 16,  
        'imgsz': 640,
        'device': 'auto',
        'patience': 15,
        'save_period': 5,
        'workers': 4,
        'project': 'yolo_rice_training',
        'name': 'rice_disease_detection',
        'exist_ok': True
    }}
    
    logging.info("üöÄ Starting YOLO training for rice disease detection...")
    logging.info(f"üìÑ Dataset config: {{config['data']}}")
    
    # Load model
    model = YOLO('yolov8n-seg.pt')  # or yolov8s-seg.pt for better accuracy
    
    # Train
    results = model.train(**config)
    
    logging.info("‚úÖ Training completed!")
    logging.info(f"üèÜ Best model: {{model.trainer.best}}")
    
    return model, results

def validate_model(model_path):
    """Validate trained model"""
    model = YOLO(model_path)
    
    results = model.val(
        data='{yolo_root / "data.yaml"}',
        imgsz=640,
        batch=16
    )
    
    logging.info(f"üìä Validation results:")
    logging.info(f"   mAP50: {{results.box.map50:.4f}}")
    logging.info(f"   mAP50-95: {{results.box.map:.4f}}")
    
    return results

if __name__ == "__main__":
    # Train model
    model, train_results = train_yolo_rice_disease()
    
    # Validate
    if model.trainer.best:
        val_results = validate_model(model.trainer.best)
        
    print("üéâ YOLO Rice Disease Training Completed!")
'''
    
    script_path = yolo_root / "train_yolo_rice.py"
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    # Make executable
    os.chmod(script_path, 0o755)
    
    logging.info(f"üìù Exported training script: {script_path}")
    logging.info("üí° Usage: python train_yolo_rice.py")

# Run additional helper functions
if YOLO_AVAILABLE and 'yolo_root' in globals():
    logging.info("üîß === RUNNING ADDITIONAL HELPER FUNCTIONS ===")
    
    # Check dataset integrity
    is_valid = check_yolo_dataset_integrity()
    
    if is_valid:
        # Visualize samples
        try:
            visualize_yolo_sample()
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Visualization failed: {e}")
        
        # Export training script
        export_yolo_training_script()
        
        logging.info("‚úÖ All helper functions completed!")
    else:
        logging.error("‚ùå Dataset integrity check failed - fix issues first")

# %% [markdown]
# ## üìà Performance Monitoring & Deployment Utils
# **Tools ƒë·ªÉ monitor v√† deploy YOLO pipeline**

# %%
def create_model_performance_report():
    """
    T·∫°o b√°o c√°o performance t·ªïng h·ª£p
    """
    logging.info("üìà === CREATING PERFORMANCE REPORT ===")
    
    report_data = {
        'timestamp': datetime.now().isoformat(),
        'pipeline_components': {
            'yolo_detection': 'YOLOv8n-seg',
            'classification': 'Best trained model',
            'integration': 'Complete field analysis'
        }
    }
    
    # YOLO model info
    if 'best_yolo_model' in globals():
        report_data['yolo_model'] = {
            'path': str(globals()['best_yolo_model']),
            'trained': True,
            'model_size': 'nano (fastest)'
        }
    else:
        report_data['yolo_model'] = {
            'path': 'pretrained',
            'trained': False,
            'model_size': 'nano (pretrained)'
        }
    
    # Classification model info  
    if 'best_ckpt' in globals():
        report_data['classification_model'] = {
            'path': str(globals()['best_ckpt']),
            'trained': True
        }
    
    # Dataset info
    if 'total_images' in globals():
        report_data['dataset'] = {
            'total_images': globals()['total_images'],
            'format': 'YOLO',
            'classes': 4,
            'class_names': ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']
        }
    
    # Save report
    if 'yolo_root' in globals():
        report_path = globals()['yolo_root'] / "performance_report.json"
        import json
        with open(report_path, 'w') as f:
            json.dump(report_data, f, indent=2)
        logging.info(f"üìä Performance report saved: {report_path}")
    
    return report_data

def create_deployment_package():
    """
    T·∫°o deployment package cho production
    """
    if 'yolo_root' not in globals():
        logging.warning("‚ö†Ô∏è YOLO dataset not available for deployment package")
        return
        
    logging.info("üì¶ === CREATING DEPLOYMENT PACKAGE ===")
    
    yolo_root = globals()['yolo_root']
    deploy_dir = yolo_root / "deployment"
    deploy_dir.mkdir(exist_ok=True)
    
    # Create main inference script
    inference_script = '''#!/usr/bin/env python3
"""
Production Rice Field Disease Analysis
Deploy-ready inference script
"""

import torch
import cv2
import numpy as np
from ultralytics import YOLO
from torchvision import transforms
from PIL import Image
import logging
import argparse
import json
from pathlib import Path

class RiceFieldAnalyzer:
    """Production-ready rice field analyzer"""
    
    def __init__(self, yolo_model_path=None, classification_model_path=None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load YOLO model
        if yolo_model_path and Path(yolo_model_path).exists():
            self.yolo_model = YOLO(yolo_model_path)
        else:
            self.yolo_model = YOLO('yolov8n-seg.pt')
            
        # Load classification model
        self.classification_model = None
        if classification_model_path and Path(classification_model_path).exists():
            # Add your model loading logic here
            pass
            
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        self.class_names = ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']
    
    def analyze_field(self, image_path, confidence_threshold=0.6):
        """Analyze single field image"""
        try:
            # YOLO detection
            results = self.yolo_model(image_path, conf=confidence_threshold)
            
            # Extract crops and classify (simplified version)
            detections = []
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        detections.append({
                            'confidence': float(box.conf.cpu()),
                            'class_id': int(box.cls.cpu()),
                            'bbox': box.xyxy.cpu().numpy().tolist()
                        })
            
            # Aggregate results
            analysis = self._analyze_detections(detections)
            
            return {
                'status': 'success',
                'total_detections': len(detections),
                'analysis': analysis,
                'field_health': self._assess_field_health(analysis)
            }
            
        except Exception as e:
            return {'status': 'error', 'message': str(e)}
    
    def _analyze_detections(self, detections):
        """Analyze detection results"""
        disease_counts = {name: 0 for name in self.class_names}
        
        for detection in detections:
            class_id = detection['class_id']
            if 0 <= class_id < len(self.class_names):
                disease_counts[self.class_names[class_id]] += 1
        
        total = sum(disease_counts.values())
        if total == 0:
            return disease_counts
            
        # Convert to percentages
        disease_percentages = {
            disease: (count / total * 100) 
            for disease, count in disease_counts.items()
        }
        
        return disease_percentages
    
    def _assess_field_health(self, analysis):
        """Assess overall field health"""
        healthy_pct = analysis.get('healthy', 0)
        
        if healthy_pct >= 80:
            return 'Excellent'
        elif healthy_pct >= 60:
            return 'Good'
        elif healthy_pct >= 40:
            return 'Fair'
        else:
            return 'Poor'

def main():
    parser = argparse.ArgumentParser(description='Rice Field Disease Analysis')
    parser.add_argument('--image', required=True, help='Path to field image')
    parser.add_argument('--yolo-model', help='Path to trained YOLO model')
    parser.add_argument('--classification-model', help='Path to classification model')
    parser.add_argument('--confidence', type=float, default=0.6, help='Detection confidence threshold')
    parser.add_argument('--output', help='Output JSON file path')
    
    args = parser.parse_args()
    
    # Initialize analyzer
    analyzer = RiceFieldAnalyzer(args.yolo_model, args.classification_model)
    
    # Analyze image
    results = analyzer.analyze_field(args.image, args.confidence)
    
    # Print results
    print(json.dumps(results, indent=2))
    
    # Save to file if specified
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)

if __name__ == "__main__":
    main()
'''
    
    # Save inference script
    script_path = deploy_dir / "rice_field_analyzer.py"
    with open(script_path, 'w') as f:
        f.write(inference_script)
    
    # Create requirements.txt
    requirements = '''ultralytics>=8.0.0
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
Pillow>=8.0.0
numpy>=1.21.0
matplotlib>=3.3.0
'''
    
    with open(deploy_dir / "requirements.txt", 'w') as f:
        f.write(requirements)
    
    # Create deployment README
    readme = f'''# Rice Field Disease Analysis - Deployment Package

## Quick Start

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Run analysis:
```bash
python rice_field_analyzer.py --image field_image.jpg --confidence 0.6
```

## Model Files Needed

- YOLO model: Place your trained .pt file in this directory
- Classification model: Place your trained .pth file in this directory

## Usage Examples

### Basic analysis:
```bash
python rice_field_analyzer.py --image field.jpg
```

### With custom models:
```bash
python rice_field_analyzer.py \\
    --image field.jpg \\
    --yolo-model rice_yolo.pt \\
    --classification-model rice_classifier.pth \\
    --confidence 0.7 \\
    --output results.json
```

## Output Format

The analyzer returns JSON with:
- Detection count
- Disease distribution percentages  
- Field health assessment
- Status and error handling

Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
'''
    
    with open(deploy_dir / "README.md", 'w') as f:
        f.write(readme)
    
    # Make script executable
    import os
    os.chmod(script_path, 0o755)
    
    logging.info(f"üì¶ Deployment package created: {deploy_dir}")
    logging.info(f"   üìù Inference script: {script_path}")
    logging.info(f"   üìã Requirements: {deploy_dir / 'requirements.txt'}")
    logging.info(f"   üìñ Documentation: {deploy_dir / 'README.md'}")

# Execute final utilities
if YOLO_AVAILABLE:
    logging.info("üìà === RUNNING FINAL UTILITIES ===")
    
    # Create performance report
    performance_report = create_model_performance_report()
    
    # Create deployment package
    create_deployment_package()
    
    logging.info("‚úÖ All final utilities completed!")

logging.info("=" * 80)
logging.info("üéâ COMPLETE YOLO TRAINING PIPELINE FINISHED!")
logging.info("‚úÖ Ready for production rice field disease analysis")
logging.info("üìù Standalone training script exported")
logging.info("üîß Dataset integrity verified")
logging.info("üìä Performance report generated")
logging.info("üì¶ Deployment package ready")
logging.info("=" * 80)
