{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88431586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mask saved to: segmentation_results/100178_mask.png\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageEnhance\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import SamModel, SamProcessor\n",
    "import shutil\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===== DEVICE CONFIG =====\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    logging.info(f\"GPU count visible to torch: {torch.cuda.device_count()}\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "    logging.info(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    logging.info(\"Using CPU\")\n",
    "\n",
    "# ===== IMPORT MODEL & AUGMENT =====\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ===== CONFIG =====\n",
    "CKPT_PATH  = \"models/best_unet_mnv2.pth\"  \n",
    "IMG_PATH   = \"/home/bbsw/thong/deep_learning/tk1/data/padtor_doctor/blight/100178.jpg\"\n",
    "IMG_SIZE   = 256\n",
    "PROB_THRESH = 0.5\n",
    "\n",
    "# ===== LOAD MODEL =====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Định nghĩa kiến trúc đúng như lúc train\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\",\n",
    "    encoder_weights=None,  # không dùng pretrained vì đã có checkpoint\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "# 2) Load checkpoint\n",
    "state = torch.load(CKPT_PATH, map_location=device)\n",
    "if isinstance(state, dict) and any(k in state for k in [\"state_dict\", \"model\", \"net\"]):\n",
    "    state = state.get(\"state_dict\", state.get(\"model\", state.get(\"net\", state)))\n",
    "\n",
    "from collections import OrderedDict\n",
    "if next(iter(state.keys())).startswith(\"module.\"):\n",
    "    new_state = OrderedDict((k.replace(\"module.\", \"\"), v) for k, v in state.items())\n",
    "    state = new_state\n",
    "\n",
    "model.load_state_dict(state, strict=True)\n",
    "model.to(device).eval().to(memory_format=torch.channels_last)\n",
    "\n",
    "# ===== TIỀN XỬ LÝ ẢNH =====\n",
    "tf = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ===== ĐỌC ẢNH =====\n",
    "img_bgr = cv2.imread(IMG_PATH, cv2.IMREAD_COLOR)\n",
    "H, W = img_bgr.shape[:2]\n",
    "x = tf(image=cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))[\"image\"].unsqueeze(0)\n",
    "x = x.to(device).to(memory_format=torch.channels_last)\n",
    "\n",
    "# ===== INFERENCE =====\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "    logit = model(x)\n",
    "prob = torch.sigmoid(logit)[0, 0].detach().cpu().numpy()\n",
    "mask_small = (prob > PROB_THRESH).astype(np.uint8)\n",
    "mask = cv2.resize(mask_small, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# ===== LƯU MASK =====\n",
    "output_dir = Path(\"segmentation_results\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = output_dir / f\"{Path(IMG_PATH).stem}_mask.png\"\n",
    "cv2.imwrite(str(out_path), (mask * 255))\n",
    "\n",
    "print(f\"✅ Mask saved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9bf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /home/bbsw/truong/.venv/lib/python3.10/site-packages (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albumentations) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: PyYAML in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albumentations) (2.11.10)\n",
      "Requirement already satisfied: albucore==0.0.24 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (4.1.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Collecting segmentation-models-pytorch\n",
      "  Using cached segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (2.1.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (11.0.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.6.2)\n",
      "Collecting timm>=0.9 (from segmentation-models-pytorch)\n",
      "  Using cached timm-1.0.20-py3-none-any.whl.metadata (61 kB)\n",
      "Requirement already satisfied: torch>=1.8 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\n",
      "Requirement already satisfied: requests in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.1.10)\n",
      "Requirement already satisfied: networkx in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bbsw/truong/.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.8.3)\n",
      "Using cached segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
      "Using cached timm-1.0.20-py3-none-any.whl (2.5 MB)\n",
      "Installing collected packages: timm, segmentation-models-pytorch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [segmentation-models-pytorch]on-models-pytorch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed segmentation-models-pytorch-0.5.0 timm-1.0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations\n",
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965b31ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using: NVIDIA GeForce RTX 4090\n",
      "✅ Model loaded.\n",
      "🧩 Found 4 classes: ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']\n",
      "🔍 brown_spot: 965 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_575864/4048015718.py:75: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.inference_mode(), torch.cuda.amp.autocast(enabled=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ 10/965 done\n",
      "➡️ 20/965 done\n",
      "➡️ 30/965 done\n",
      "➡️ 40/965 done\n",
      "➡️ 50/965 done\n",
      "➡️ 60/965 done\n",
      "➡️ 70/965 done\n",
      "➡️ 80/965 done\n",
      "➡️ 90/965 done\n",
      "➡️ 100/965 done\n",
      "➡️ 110/965 done\n",
      "➡️ 120/965 done\n",
      "➡️ 130/965 done\n",
      "➡️ 140/965 done\n",
      "➡️ 150/965 done\n",
      "➡️ 160/965 done\n",
      "➡️ 170/965 done\n",
      "➡️ 180/965 done\n",
      "➡️ 190/965 done\n",
      "➡️ 200/965 done\n",
      "➡️ 210/965 done\n",
      "➡️ 220/965 done\n",
      "➡️ 230/965 done\n",
      "➡️ 240/965 done\n",
      "➡️ 250/965 done\n",
      "➡️ 260/965 done\n",
      "➡️ 270/965 done\n",
      "➡️ 280/965 done\n",
      "➡️ 290/965 done\n",
      "➡️ 300/965 done\n",
      "➡️ 310/965 done\n",
      "➡️ 320/965 done\n",
      "➡️ 330/965 done\n",
      "➡️ 340/965 done\n",
      "➡️ 350/965 done\n",
      "➡️ 360/965 done\n",
      "➡️ 370/965 done\n",
      "➡️ 380/965 done\n",
      "➡️ 390/965 done\n",
      "➡️ 400/965 done\n",
      "➡️ 410/965 done\n",
      "➡️ 420/965 done\n",
      "➡️ 430/965 done\n",
      "➡️ 440/965 done\n",
      "➡️ 450/965 done\n",
      "➡️ 460/965 done\n",
      "➡️ 470/965 done\n",
      "➡️ 480/965 done\n",
      "➡️ 490/965 done\n",
      "➡️ 500/965 done\n",
      "➡️ 510/965 done\n",
      "➡️ 520/965 done\n",
      "➡️ 530/965 done\n",
      "➡️ 540/965 done\n",
      "➡️ 550/965 done\n",
      "➡️ 560/965 done\n",
      "➡️ 570/965 done\n",
      "➡️ 580/965 done\n",
      "➡️ 590/965 done\n",
      "➡️ 600/965 done\n",
      "➡️ 610/965 done\n",
      "➡️ 620/965 done\n",
      "➡️ 630/965 done\n",
      "➡️ 640/965 done\n",
      "➡️ 650/965 done\n",
      "➡️ 660/965 done\n",
      "➡️ 670/965 done\n",
      "➡️ 680/965 done\n",
      "➡️ 690/965 done\n",
      "➡️ 700/965 done\n",
      "➡️ 710/965 done\n",
      "➡️ 720/965 done\n",
      "➡️ 730/965 done\n",
      "➡️ 740/965 done\n",
      "➡️ 750/965 done\n",
      "➡️ 760/965 done\n",
      "➡️ 770/965 done\n",
      "➡️ 780/965 done\n",
      "➡️ 790/965 done\n",
      "➡️ 800/965 done\n",
      "➡️ 810/965 done\n",
      "➡️ 820/965 done\n",
      "➡️ 830/965 done\n",
      "➡️ 840/965 done\n",
      "➡️ 850/965 done\n",
      "➡️ 860/965 done\n",
      "➡️ 870/965 done\n",
      "➡️ 880/965 done\n",
      "➡️ 890/965 done\n",
      "➡️ 900/965 done\n",
      "➡️ 910/965 done\n",
      "➡️ 920/965 done\n",
      "➡️ 930/965 done\n",
      "➡️ 940/965 done\n",
      "➡️ 950/965 done\n",
      "➡️ 960/965 done\n",
      "🔍 leaf_blast: 1738 images\n",
      "➡️ 10/1738 done\n",
      "➡️ 20/1738 done\n",
      "➡️ 30/1738 done\n",
      "➡️ 40/1738 done\n",
      "➡️ 50/1738 done\n",
      "➡️ 60/1738 done\n",
      "➡️ 70/1738 done\n",
      "➡️ 80/1738 done\n",
      "➡️ 90/1738 done\n",
      "➡️ 100/1738 done\n",
      "➡️ 110/1738 done\n",
      "➡️ 120/1738 done\n",
      "➡️ 130/1738 done\n",
      "➡️ 140/1738 done\n",
      "➡️ 150/1738 done\n",
      "➡️ 160/1738 done\n",
      "➡️ 170/1738 done\n",
      "➡️ 180/1738 done\n",
      "➡️ 190/1738 done\n",
      "➡️ 200/1738 done\n",
      "➡️ 210/1738 done\n",
      "➡️ 220/1738 done\n",
      "➡️ 230/1738 done\n",
      "➡️ 240/1738 done\n",
      "➡️ 250/1738 done\n",
      "➡️ 260/1738 done\n",
      "➡️ 270/1738 done\n",
      "➡️ 280/1738 done\n",
      "➡️ 290/1738 done\n",
      "➡️ 300/1738 done\n",
      "➡️ 310/1738 done\n",
      "➡️ 320/1738 done\n",
      "➡️ 330/1738 done\n",
      "➡️ 340/1738 done\n",
      "➡️ 350/1738 done\n",
      "➡️ 360/1738 done\n",
      "➡️ 370/1738 done\n",
      "➡️ 380/1738 done\n",
      "➡️ 390/1738 done\n",
      "➡️ 400/1738 done\n",
      "➡️ 410/1738 done\n",
      "➡️ 420/1738 done\n",
      "➡️ 430/1738 done\n",
      "➡️ 440/1738 done\n",
      "➡️ 450/1738 done\n",
      "➡️ 460/1738 done\n",
      "➡️ 470/1738 done\n",
      "➡️ 480/1738 done\n",
      "➡️ 490/1738 done\n",
      "➡️ 500/1738 done\n",
      "➡️ 510/1738 done\n",
      "➡️ 520/1738 done\n",
      "➡️ 530/1738 done\n",
      "➡️ 540/1738 done\n",
      "➡️ 550/1738 done\n",
      "➡️ 560/1738 done\n",
      "➡️ 570/1738 done\n",
      "➡️ 580/1738 done\n",
      "➡️ 590/1738 done\n",
      "➡️ 600/1738 done\n",
      "➡️ 610/1738 done\n",
      "➡️ 620/1738 done\n",
      "➡️ 630/1738 done\n",
      "➡️ 640/1738 done\n",
      "➡️ 650/1738 done\n",
      "➡️ 660/1738 done\n",
      "➡️ 670/1738 done\n",
      "➡️ 680/1738 done\n",
      "➡️ 690/1738 done\n",
      "➡️ 700/1738 done\n",
      "➡️ 710/1738 done\n",
      "➡️ 720/1738 done\n",
      "➡️ 730/1738 done\n",
      "➡️ 740/1738 done\n",
      "➡️ 750/1738 done\n",
      "➡️ 760/1738 done\n",
      "➡️ 770/1738 done\n",
      "➡️ 780/1738 done\n",
      "➡️ 790/1738 done\n",
      "➡️ 800/1738 done\n",
      "➡️ 810/1738 done\n",
      "➡️ 820/1738 done\n",
      "➡️ 830/1738 done\n",
      "➡️ 840/1738 done\n",
      "➡️ 850/1738 done\n",
      "➡️ 860/1738 done\n",
      "➡️ 870/1738 done\n",
      "➡️ 880/1738 done\n",
      "➡️ 890/1738 done\n",
      "➡️ 900/1738 done\n",
      "➡️ 910/1738 done\n",
      "➡️ 920/1738 done\n",
      "➡️ 930/1738 done\n",
      "➡️ 940/1738 done\n",
      "➡️ 950/1738 done\n",
      "➡️ 960/1738 done\n",
      "➡️ 970/1738 done\n",
      "➡️ 980/1738 done\n",
      "➡️ 990/1738 done\n",
      "➡️ 1000/1738 done\n",
      "➡️ 1010/1738 done\n",
      "➡️ 1020/1738 done\n",
      "➡️ 1030/1738 done\n",
      "➡️ 1040/1738 done\n",
      "➡️ 1050/1738 done\n",
      "➡️ 1060/1738 done\n",
      "➡️ 1070/1738 done\n",
      "➡️ 1080/1738 done\n",
      "➡️ 1090/1738 done\n",
      "➡️ 1100/1738 done\n",
      "➡️ 1110/1738 done\n",
      "➡️ 1120/1738 done\n",
      "➡️ 1130/1738 done\n",
      "➡️ 1140/1738 done\n",
      "➡️ 1150/1738 done\n",
      "➡️ 1160/1738 done\n",
      "➡️ 1170/1738 done\n",
      "➡️ 1180/1738 done\n",
      "➡️ 1190/1738 done\n",
      "➡️ 1200/1738 done\n",
      "➡️ 1210/1738 done\n",
      "➡️ 1220/1738 done\n",
      "➡️ 1230/1738 done\n",
      "➡️ 1240/1738 done\n",
      "➡️ 1250/1738 done\n",
      "➡️ 1260/1738 done\n",
      "➡️ 1270/1738 done\n",
      "➡️ 1280/1738 done\n",
      "➡️ 1290/1738 done\n",
      "➡️ 1300/1738 done\n",
      "➡️ 1310/1738 done\n",
      "➡️ 1320/1738 done\n",
      "➡️ 1330/1738 done\n",
      "➡️ 1340/1738 done\n",
      "➡️ 1350/1738 done\n",
      "➡️ 1360/1738 done\n",
      "➡️ 1370/1738 done\n",
      "➡️ 1380/1738 done\n",
      "➡️ 1390/1738 done\n",
      "➡️ 1400/1738 done\n",
      "➡️ 1410/1738 done\n",
      "➡️ 1420/1738 done\n",
      "➡️ 1430/1738 done\n",
      "➡️ 1440/1738 done\n",
      "➡️ 1450/1738 done\n",
      "➡️ 1460/1738 done\n",
      "➡️ 1470/1738 done\n",
      "➡️ 1480/1738 done\n",
      "➡️ 1490/1738 done\n",
      "➡️ 1500/1738 done\n",
      "➡️ 1510/1738 done\n",
      "➡️ 1520/1738 done\n",
      "➡️ 1530/1738 done\n",
      "➡️ 1540/1738 done\n",
      "➡️ 1550/1738 done\n",
      "➡️ 1560/1738 done\n",
      "➡️ 1570/1738 done\n",
      "➡️ 1580/1738 done\n",
      "➡️ 1590/1738 done\n",
      "➡️ 1600/1738 done\n",
      "➡️ 1610/1738 done\n",
      "➡️ 1620/1738 done\n",
      "➡️ 1630/1738 done\n",
      "➡️ 1640/1738 done\n",
      "➡️ 1650/1738 done\n",
      "➡️ 1660/1738 done\n",
      "➡️ 1670/1738 done\n",
      "➡️ 1680/1738 done\n",
      "➡️ 1690/1738 done\n",
      "➡️ 1700/1738 done\n",
      "➡️ 1710/1738 done\n",
      "➡️ 1720/1738 done\n",
      "➡️ 1730/1738 done\n",
      "🔍 leaf_blight: 479 images\n",
      "➡️ 10/479 done\n",
      "➡️ 20/479 done\n",
      "➡️ 30/479 done\n",
      "➡️ 40/479 done\n",
      "➡️ 50/479 done\n",
      "➡️ 60/479 done\n",
      "➡️ 70/479 done\n",
      "➡️ 80/479 done\n",
      "➡️ 90/479 done\n",
      "➡️ 100/479 done\n",
      "➡️ 110/479 done\n",
      "➡️ 120/479 done\n",
      "➡️ 130/479 done\n",
      "➡️ 140/479 done\n",
      "➡️ 150/479 done\n",
      "➡️ 160/479 done\n",
      "➡️ 170/479 done\n",
      "➡️ 180/479 done\n",
      "➡️ 190/479 done\n",
      "➡️ 200/479 done\n",
      "➡️ 210/479 done\n",
      "➡️ 220/479 done\n",
      "➡️ 230/479 done\n",
      "➡️ 240/479 done\n",
      "➡️ 250/479 done\n",
      "➡️ 260/479 done\n",
      "➡️ 270/479 done\n",
      "➡️ 280/479 done\n",
      "➡️ 290/479 done\n",
      "➡️ 300/479 done\n",
      "➡️ 310/479 done\n",
      "➡️ 320/479 done\n",
      "➡️ 330/479 done\n",
      "➡️ 340/479 done\n",
      "➡️ 350/479 done\n",
      "➡️ 360/479 done\n",
      "➡️ 370/479 done\n",
      "➡️ 380/479 done\n",
      "➡️ 390/479 done\n",
      "➡️ 400/479 done\n",
      "➡️ 410/479 done\n",
      "➡️ 420/479 done\n",
      "➡️ 430/479 done\n",
      "➡️ 440/479 done\n",
      "➡️ 450/479 done\n",
      "➡️ 460/479 done\n",
      "➡️ 470/479 done\n",
      "🔍 healthy: 1764 images\n",
      "➡️ 10/1764 done\n",
      "➡️ 20/1764 done\n",
      "➡️ 30/1764 done\n",
      "➡️ 40/1764 done\n",
      "➡️ 50/1764 done\n",
      "➡️ 60/1764 done\n",
      "➡️ 70/1764 done\n",
      "➡️ 80/1764 done\n",
      "➡️ 90/1764 done\n",
      "➡️ 100/1764 done\n",
      "➡️ 110/1764 done\n",
      "➡️ 120/1764 done\n",
      "➡️ 130/1764 done\n",
      "➡️ 140/1764 done\n",
      "➡️ 150/1764 done\n",
      "➡️ 160/1764 done\n",
      "➡️ 170/1764 done\n",
      "➡️ 180/1764 done\n",
      "➡️ 190/1764 done\n",
      "➡️ 200/1764 done\n",
      "➡️ 210/1764 done\n",
      "➡️ 220/1764 done\n",
      "➡️ 230/1764 done\n",
      "➡️ 240/1764 done\n",
      "➡️ 250/1764 done\n",
      "➡️ 260/1764 done\n",
      "➡️ 270/1764 done\n",
      "➡️ 280/1764 done\n",
      "➡️ 290/1764 done\n",
      "➡️ 300/1764 done\n",
      "➡️ 310/1764 done\n",
      "➡️ 320/1764 done\n",
      "➡️ 330/1764 done\n",
      "➡️ 340/1764 done\n",
      "➡️ 350/1764 done\n",
      "➡️ 360/1764 done\n",
      "➡️ 370/1764 done\n",
      "➡️ 380/1764 done\n",
      "➡️ 390/1764 done\n",
      "➡️ 400/1764 done\n",
      "➡️ 410/1764 done\n",
      "➡️ 420/1764 done\n",
      "➡️ 430/1764 done\n",
      "➡️ 440/1764 done\n",
      "➡️ 450/1764 done\n",
      "➡️ 460/1764 done\n",
      "➡️ 470/1764 done\n",
      "➡️ 480/1764 done\n",
      "➡️ 490/1764 done\n",
      "➡️ 500/1764 done\n",
      "➡️ 510/1764 done\n",
      "➡️ 520/1764 done\n",
      "➡️ 530/1764 done\n",
      "➡️ 540/1764 done\n",
      "➡️ 550/1764 done\n",
      "➡️ 560/1764 done\n",
      "➡️ 570/1764 done\n",
      "➡️ 580/1764 done\n",
      "➡️ 590/1764 done\n",
      "➡️ 600/1764 done\n",
      "➡️ 610/1764 done\n",
      "➡️ 620/1764 done\n",
      "➡️ 630/1764 done\n",
      "➡️ 640/1764 done\n",
      "➡️ 650/1764 done\n",
      "➡️ 660/1764 done\n",
      "➡️ 670/1764 done\n",
      "➡️ 680/1764 done\n",
      "➡️ 690/1764 done\n",
      "➡️ 700/1764 done\n",
      "➡️ 710/1764 done\n",
      "➡️ 720/1764 done\n",
      "➡️ 730/1764 done\n",
      "➡️ 740/1764 done\n",
      "➡️ 750/1764 done\n",
      "➡️ 760/1764 done\n",
      "➡️ 770/1764 done\n",
      "➡️ 780/1764 done\n",
      "➡️ 790/1764 done\n",
      "➡️ 800/1764 done\n",
      "➡️ 810/1764 done\n",
      "➡️ 820/1764 done\n",
      "➡️ 830/1764 done\n",
      "➡️ 840/1764 done\n",
      "➡️ 850/1764 done\n",
      "➡️ 860/1764 done\n",
      "➡️ 870/1764 done\n",
      "➡️ 880/1764 done\n",
      "➡️ 890/1764 done\n",
      "➡️ 900/1764 done\n",
      "➡️ 910/1764 done\n",
      "➡️ 920/1764 done\n",
      "➡️ 930/1764 done\n",
      "➡️ 940/1764 done\n",
      "➡️ 950/1764 done\n",
      "➡️ 960/1764 done\n",
      "➡️ 970/1764 done\n",
      "➡️ 980/1764 done\n",
      "➡️ 990/1764 done\n",
      "➡️ 1000/1764 done\n",
      "➡️ 1010/1764 done\n",
      "➡️ 1020/1764 done\n",
      "➡️ 1030/1764 done\n",
      "➡️ 1040/1764 done\n",
      "➡️ 1050/1764 done\n",
      "➡️ 1060/1764 done\n",
      "➡️ 1070/1764 done\n",
      "➡️ 1080/1764 done\n",
      "➡️ 1090/1764 done\n",
      "➡️ 1100/1764 done\n",
      "➡️ 1110/1764 done\n",
      "➡️ 1120/1764 done\n",
      "➡️ 1130/1764 done\n",
      "➡️ 1140/1764 done\n",
      "➡️ 1150/1764 done\n",
      "➡️ 1160/1764 done\n",
      "➡️ 1170/1764 done\n",
      "➡️ 1180/1764 done\n",
      "➡️ 1190/1764 done\n",
      "➡️ 1200/1764 done\n",
      "➡️ 1210/1764 done\n",
      "➡️ 1220/1764 done\n",
      "➡️ 1230/1764 done\n",
      "➡️ 1240/1764 done\n",
      "➡️ 1250/1764 done\n",
      "➡️ 1260/1764 done\n",
      "➡️ 1270/1764 done\n",
      "➡️ 1280/1764 done\n",
      "➡️ 1290/1764 done\n",
      "➡️ 1300/1764 done\n",
      "➡️ 1310/1764 done\n",
      "➡️ 1320/1764 done\n",
      "➡️ 1330/1764 done\n",
      "➡️ 1340/1764 done\n",
      "➡️ 1350/1764 done\n",
      "➡️ 1360/1764 done\n",
      "➡️ 1370/1764 done\n",
      "➡️ 1380/1764 done\n",
      "➡️ 1390/1764 done\n",
      "➡️ 1400/1764 done\n",
      "➡️ 1410/1764 done\n",
      "➡️ 1420/1764 done\n",
      "➡️ 1430/1764 done\n",
      "➡️ 1440/1764 done\n",
      "➡️ 1450/1764 done\n",
      "➡️ 1460/1764 done\n",
      "➡️ 1470/1764 done\n",
      "➡️ 1480/1764 done\n",
      "➡️ 1490/1764 done\n",
      "➡️ 1500/1764 done\n",
      "➡️ 1510/1764 done\n",
      "➡️ 1520/1764 done\n",
      "➡️ 1530/1764 done\n",
      "➡️ 1540/1764 done\n",
      "➡️ 1550/1764 done\n",
      "➡️ 1560/1764 done\n",
      "➡️ 1570/1764 done\n",
      "➡️ 1580/1764 done\n",
      "➡️ 1590/1764 done\n",
      "➡️ 1600/1764 done\n",
      "➡️ 1610/1764 done\n",
      "➡️ 1620/1764 done\n",
      "➡️ 1630/1764 done\n",
      "➡️ 1640/1764 done\n",
      "➡️ 1650/1764 done\n",
      "➡️ 1660/1764 done\n",
      "➡️ 1670/1764 done\n",
      "➡️ 1680/1764 done\n",
      "➡️ 1690/1764 done\n",
      "➡️ 1700/1764 done\n",
      "➡️ 1710/1764 done\n",
      "➡️ 1720/1764 done\n",
      "➡️ 1730/1764 done\n",
      "➡️ 1740/1764 done\n",
      "➡️ 1750/1764 done\n",
      "➡️ 1760/1764 done\n",
      "✅ Done! Results at /home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/unet_gpu1_fast\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import segmentation_models_pytorch as smp\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ===== CONFIG =====\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   # ✅ chỉ dùng GPU thứ 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"🚀 Using:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DATA_ROOT   = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice\"\n",
    "CKPT_PATH   = \"/home/bbsw/truong/train/models/best_unet_mnv2.pth\"\n",
    "OUTPUT_ROOT = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/unet_gpu1_fast\"\n",
    "IMG_SIZE    = 256\n",
    "PROB_THRESH = 0.5\n",
    "MAX_WORKERS = 4   # số luồng song song (4 là tối ưu cho 1 GPU 4090)\n",
    "\n",
    "# ===== LOAD MODEL 1 LẦN DUY NHẤT =====\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ")\n",
    "state = torch.load(CKPT_PATH, map_location=device)\n",
    "if \"state_dict\" in state:\n",
    "    state = state[\"state_dict\"]\n",
    "from collections import OrderedDict\n",
    "if next(iter(state.keys())).startswith(\"module.\"):\n",
    "    state = OrderedDict((k.replace(\"module.\",\"\"), v) for k,v in state.items())\n",
    "model.load_state_dict(state, strict=True)\n",
    "model.to(device).eval().to(memory_format=torch.channels_last)\n",
    "print(\"✅ Model loaded.\")\n",
    "\n",
    "# ===== TRANSFORM =====\n",
    "tf = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ===== UTILS =====\n",
    "def create_overlay(original, mask, color=(255,0,0), alpha=0.5):\n",
    "    overlay = original.copy()\n",
    "    cmask = np.zeros_like(original)\n",
    "    cmask[mask>0] = color\n",
    "    return cv2.addWeighted(overlay, 1-alpha, cmask, alpha, 0)\n",
    "\n",
    "def extract_region(original, mask):\n",
    "    if mask.max() == 0: return None\n",
    "    coords = np.column_stack(np.where(mask > 0))\n",
    "    y1, x1 = coords.min(axis=0)\n",
    "    y2, x2 = coords.max(axis=0)\n",
    "    pad = 10\n",
    "    h, w = original.shape[:2]\n",
    "    y1, x1 = max(0, y1-pad), max(0, x1-pad)\n",
    "    y2, x2 = min(h, y2+pad), min(w, x2+pad)\n",
    "    return original[y1:y2, x1:x2]\n",
    "\n",
    "# ===== WORKER =====\n",
    "def process_one(img_path: str, out_dir: Path):\n",
    "    img = cv2.imread(img_path)\n",
    "    H, W = img.shape[:2]\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    x = tf(image=rgb)[\"image\"].unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.inference_mode(), torch.cuda.amp.autocast(enabled=True):\n",
    "        logit = model(x)\n",
    "    prob = torch.sigmoid(logit)[0,0].cpu().numpy()\n",
    "    mask = (cv2.resize((prob > PROB_THRESH).astype(np.uint8), (W,H)) * 255).astype(np.uint8)\n",
    "\n",
    "    stem = Path(img_path).stem\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    mask_path = out_dir / f\"{stem}_mask.png\"\n",
    "    overlay_path = out_dir / f\"{stem}_overlay.png\"\n",
    "    region_path = out_dir / f\"{stem}_region.png\"\n",
    "\n",
    "    cv2.imwrite(str(mask_path), mask)\n",
    "    over = create_overlay(rgb, mask)\n",
    "    cv2.imwrite(str(overlay_path), cv2.cvtColor(over, cv2.COLOR_RGB2BGR))\n",
    "    region = extract_region(rgb, mask)\n",
    "    if region is not None:\n",
    "        cv2.imwrite(str(region_path), cv2.cvtColor(region, cv2.COLOR_RGB2BGR))\n",
    "    return {\"image\": img_path, \"mask\": str(mask_path)}\n",
    "\n",
    "# ===== MAIN =====\n",
    "def main():\n",
    "    Path(OUTPUT_ROOT).mkdir(parents=True, exist_ok=True)\n",
    "    disease_dirs = [p for p in Path(DATA_ROOT).iterdir() if p.is_dir()]\n",
    "    print(f\"🧩 Found {len(disease_dirs)} classes:\", [d.name for d in disease_dirs])\n",
    "\n",
    "    all_results = []\n",
    "    for disease_dir in disease_dirs:\n",
    "        out_dir = Path(OUTPUT_ROOT) / disease_dir.name\n",
    "        imgs = [*disease_dir.glob(\"*.jpg\"), *disease_dir.glob(\"*.png\")]\n",
    "        if not imgs: continue\n",
    "        print(f\"🔍 {disease_dir.name}: {len(imgs)} images\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "            futures = [ex.submit(process_one, str(img), out_dir) for img in imgs]\n",
    "            for i, f in enumerate(as_completed(futures), 1):\n",
    "                try:\n",
    "                    res = f.result()\n",
    "                    all_results.append(res)\n",
    "                    if i % 10 == 0:\n",
    "                        print(f\"➡️ {i}/{len(imgs)} done\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ {e}\")\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    with open(Path(OUTPUT_ROOT)/\"summary.json\", \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"✅ Done! Results at {OUTPUT_ROOT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a125a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using: NVIDIA GeForce RTX 4090\n",
      "📦 Loading YOLOv8 model...\n",
      "✅ Model loaded on cuda\n",
      "🧩 Found 4 classes: ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']\n",
      "🔍 brown_spot: 965 images\n",
      "❌ Error: bn\n",
      "❌ Error: bn\n",
      "❌ Error: bn\n",
      "Ultralytics 8.3.204 🚀 Python-3.10.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 22684MiB)\n",
      "Ultralytics 8.3.204 🚀 Python-3.10.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 22684MiB)\n",
      "Ultralytics 8.3.204 🚀 Python-3.10.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 22684MiB)\n",
      "Ultralytics 8.3.204 🚀 Python-3.10.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 4090, 22684MiB)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "➡️ 10/965 done for brown_spot\n",
      "➡️ 20/965 done for brown_spot\n",
      "➡️ 30/965 done for brown_spot\n",
      "➡️ 40/965 done for brown_spot\n",
      "➡️ 50/965 done for brown_spot\n",
      "➡️ 60/965 done for brown_spot\n",
      "➡️ 70/965 done for brown_spot\n",
      "➡️ 80/965 done for brown_spot\n",
      "➡️ 90/965 done for brown_spot\n",
      "➡️ 100/965 done for brown_spot\n",
      "➡️ 110/965 done for brown_spot\n",
      "➡️ 120/965 done for brown_spot\n",
      "➡️ 130/965 done for brown_spot\n",
      "➡️ 140/965 done for brown_spot\n",
      "➡️ 150/965 done for brown_spot\n",
      "➡️ 160/965 done for brown_spot\n",
      "➡️ 170/965 done for brown_spot\n",
      "➡️ 180/965 done for brown_spot\n",
      "➡️ 190/965 done for brown_spot\n",
      "➡️ 200/965 done for brown_spot\n",
      "➡️ 210/965 done for brown_spot\n",
      "➡️ 220/965 done for brown_spot\n",
      "➡️ 230/965 done for brown_spot\n",
      "➡️ 240/965 done for brown_spot\n",
      "➡️ 250/965 done for brown_spot\n",
      "➡️ 260/965 done for brown_spot\n",
      "➡️ 270/965 done for brown_spot\n",
      "➡️ 280/965 done for brown_spot\n",
      "➡️ 290/965 done for brown_spot\n",
      "➡️ 300/965 done for brown_spot\n",
      "➡️ 310/965 done for brown_spot\n",
      "➡️ 320/965 done for brown_spot\n",
      "➡️ 330/965 done for brown_spot\n",
      "➡️ 340/965 done for brown_spot\n",
      "➡️ 350/965 done for brown_spot\n",
      "➡️ 360/965 done for brown_spot\n",
      "➡️ 370/965 done for brown_spot\n",
      "➡️ 380/965 done for brown_spot\n",
      "➡️ 390/965 done for brown_spot\n",
      "➡️ 400/965 done for brown_spot\n",
      "➡️ 410/965 done for brown_spot\n",
      "➡️ 420/965 done for brown_spot\n",
      "➡️ 430/965 done for brown_spot\n",
      "➡️ 440/965 done for brown_spot\n",
      "➡️ 450/965 done for brown_spot\n",
      "➡️ 460/965 done for brown_spot\n",
      "➡️ 470/965 done for brown_spot\n",
      "➡️ 480/965 done for brown_spot\n",
      "➡️ 490/965 done for brown_spot\n",
      "➡️ 500/965 done for brown_spot\n",
      "➡️ 510/965 done for brown_spot\n",
      "➡️ 520/965 done for brown_spot\n",
      "➡️ 530/965 done for brown_spot\n",
      "➡️ 540/965 done for brown_spot\n",
      "➡️ 550/965 done for brown_spot\n",
      "➡️ 560/965 done for brown_spot\n",
      "➡️ 570/965 done for brown_spot\n",
      "➡️ 580/965 done for brown_spot\n",
      "➡️ 590/965 done for brown_spot\n",
      "➡️ 600/965 done for brown_spot\n",
      "➡️ 610/965 done for brown_spot\n",
      "➡️ 620/965 done for brown_spot\n",
      "➡️ 630/965 done for brown_spot\n",
      "➡️ 640/965 done for brown_spot\n",
      "➡️ 650/965 done for brown_spot\n",
      "➡️ 660/965 done for brown_spot\n",
      "➡️ 670/965 done for brown_spot\n",
      "➡️ 680/965 done for brown_spot\n",
      "➡️ 690/965 done for brown_spot\n",
      "➡️ 700/965 done for brown_spot\n",
      "➡️ 710/965 done for brown_spot\n",
      "➡️ 720/965 done for brown_spot\n",
      "➡️ 730/965 done for brown_spot\n",
      "➡️ 740/965 done for brown_spot\n",
      "➡️ 750/965 done for brown_spot\n",
      "➡️ 760/965 done for brown_spot\n",
      "➡️ 770/965 done for brown_spot\n",
      "➡️ 780/965 done for brown_spot\n",
      "➡️ 790/965 done for brown_spot\n",
      "➡️ 800/965 done for brown_spot\n",
      "➡️ 810/965 done for brown_spot\n",
      "➡️ 820/965 done for brown_spot\n",
      "➡️ 830/965 done for brown_spot\n",
      "➡️ 840/965 done for brown_spot\n",
      "➡️ 850/965 done for brown_spot\n",
      "➡️ 860/965 done for brown_spot\n",
      "➡️ 870/965 done for brown_spot\n",
      "➡️ 880/965 done for brown_spot\n",
      "➡️ 890/965 done for brown_spot\n",
      "➡️ 900/965 done for brown_spot\n",
      "➡️ 910/965 done for brown_spot\n",
      "➡️ 920/965 done for brown_spot\n",
      "➡️ 930/965 done for brown_spot\n",
      "➡️ 940/965 done for brown_spot\n",
      "➡️ 950/965 done for brown_spot\n",
      "➡️ 960/965 done for brown_spot\n",
      "🔍 leaf_blast: 1738 images\n",
      "➡️ 10/1738 done for leaf_blast\n",
      "➡️ 20/1738 done for leaf_blast\n",
      "➡️ 30/1738 done for leaf_blast\n",
      "➡️ 40/1738 done for leaf_blast\n",
      "➡️ 50/1738 done for leaf_blast\n",
      "➡️ 60/1738 done for leaf_blast\n",
      "➡️ 70/1738 done for leaf_blast\n",
      "➡️ 80/1738 done for leaf_blast\n",
      "➡️ 90/1738 done for leaf_blast\n",
      "➡️ 100/1738 done for leaf_blast\n",
      "➡️ 110/1738 done for leaf_blast\n",
      "➡️ 120/1738 done for leaf_blast\n",
      "➡️ 130/1738 done for leaf_blast\n",
      "➡️ 140/1738 done for leaf_blast\n",
      "➡️ 150/1738 done for leaf_blast\n",
      "➡️ 160/1738 done for leaf_blast\n",
      "➡️ 170/1738 done for leaf_blast\n",
      "➡️ 180/1738 done for leaf_blast\n",
      "➡️ 190/1738 done for leaf_blast\n",
      "➡️ 200/1738 done for leaf_blast\n",
      "➡️ 210/1738 done for leaf_blast\n",
      "➡️ 220/1738 done for leaf_blast\n",
      "➡️ 230/1738 done for leaf_blast\n",
      "➡️ 240/1738 done for leaf_blast\n",
      "➡️ 250/1738 done for leaf_blast\n",
      "➡️ 260/1738 done for leaf_blast\n",
      "➡️ 270/1738 done for leaf_blast\n",
      "➡️ 280/1738 done for leaf_blast\n",
      "➡️ 290/1738 done for leaf_blast\n",
      "➡️ 300/1738 done for leaf_blast\n",
      "➡️ 310/1738 done for leaf_blast\n",
      "➡️ 320/1738 done for leaf_blast\n",
      "➡️ 330/1738 done for leaf_blast\n",
      "➡️ 340/1738 done for leaf_blast\n",
      "➡️ 350/1738 done for leaf_blast\n",
      "➡️ 360/1738 done for leaf_blast\n",
      "➡️ 370/1738 done for leaf_blast\n",
      "➡️ 380/1738 done for leaf_blast\n",
      "➡️ 390/1738 done for leaf_blast\n",
      "➡️ 400/1738 done for leaf_blast\n",
      "➡️ 410/1738 done for leaf_blast\n",
      "➡️ 420/1738 done for leaf_blast\n",
      "➡️ 430/1738 done for leaf_blast\n",
      "➡️ 440/1738 done for leaf_blast\n",
      "➡️ 450/1738 done for leaf_blast\n",
      "➡️ 460/1738 done for leaf_blast\n",
      "➡️ 470/1738 done for leaf_blast\n",
      "➡️ 480/1738 done for leaf_blast\n",
      "➡️ 490/1738 done for leaf_blast\n",
      "➡️ 500/1738 done for leaf_blast\n",
      "➡️ 510/1738 done for leaf_blast\n",
      "➡️ 520/1738 done for leaf_blast\n",
      "➡️ 530/1738 done for leaf_blast\n",
      "➡️ 540/1738 done for leaf_blast\n",
      "➡️ 550/1738 done for leaf_blast\n",
      "➡️ 560/1738 done for leaf_blast\n",
      "➡️ 570/1738 done for leaf_blast\n",
      "➡️ 580/1738 done for leaf_blast\n",
      "➡️ 590/1738 done for leaf_blast\n",
      "➡️ 600/1738 done for leaf_blast\n",
      "➡️ 610/1738 done for leaf_blast\n",
      "➡️ 620/1738 done for leaf_blast\n",
      "➡️ 630/1738 done for leaf_blast\n",
      "➡️ 640/1738 done for leaf_blast\n",
      "➡️ 650/1738 done for leaf_blast\n",
      "➡️ 660/1738 done for leaf_blast\n",
      "➡️ 670/1738 done for leaf_blast\n",
      "➡️ 680/1738 done for leaf_blast\n",
      "➡️ 690/1738 done for leaf_blast\n",
      "➡️ 700/1738 done for leaf_blast\n",
      "➡️ 710/1738 done for leaf_blast\n",
      "➡️ 720/1738 done for leaf_blast\n",
      "➡️ 730/1738 done for leaf_blast\n",
      "➡️ 740/1738 done for leaf_blast\n",
      "➡️ 750/1738 done for leaf_blast\n",
      "➡️ 760/1738 done for leaf_blast\n",
      "➡️ 770/1738 done for leaf_blast\n",
      "➡️ 780/1738 done for leaf_blast\n",
      "➡️ 790/1738 done for leaf_blast\n",
      "➡️ 800/1738 done for leaf_blast\n",
      "➡️ 810/1738 done for leaf_blast\n",
      "➡️ 820/1738 done for leaf_blast\n",
      "➡️ 830/1738 done for leaf_blast\n",
      "➡️ 840/1738 done for leaf_blast\n",
      "➡️ 850/1738 done for leaf_blast\n",
      "➡️ 860/1738 done for leaf_blast\n",
      "➡️ 870/1738 done for leaf_blast\n",
      "➡️ 880/1738 done for leaf_blast\n",
      "➡️ 890/1738 done for leaf_blast\n",
      "➡️ 900/1738 done for leaf_blast\n",
      "➡️ 910/1738 done for leaf_blast\n",
      "➡️ 920/1738 done for leaf_blast\n",
      "➡️ 930/1738 done for leaf_blast\n",
      "➡️ 940/1738 done for leaf_blast\n",
      "➡️ 950/1738 done for leaf_blast\n",
      "➡️ 960/1738 done for leaf_blast\n",
      "➡️ 970/1738 done for leaf_blast\n",
      "➡️ 980/1738 done for leaf_blast\n",
      "➡️ 990/1738 done for leaf_blast\n",
      "➡️ 1000/1738 done for leaf_blast\n",
      "➡️ 1010/1738 done for leaf_blast\n",
      "➡️ 1020/1738 done for leaf_blast\n",
      "➡️ 1030/1738 done for leaf_blast\n",
      "➡️ 1040/1738 done for leaf_blast\n",
      "➡️ 1050/1738 done for leaf_blast\n",
      "➡️ 1060/1738 done for leaf_blast\n",
      "➡️ 1070/1738 done for leaf_blast\n",
      "➡️ 1080/1738 done for leaf_blast\n",
      "➡️ 1090/1738 done for leaf_blast\n",
      "➡️ 1100/1738 done for leaf_blast\n",
      "➡️ 1110/1738 done for leaf_blast\n",
      "➡️ 1120/1738 done for leaf_blast\n",
      "➡️ 1130/1738 done for leaf_blast\n",
      "➡️ 1140/1738 done for leaf_blast\n",
      "➡️ 1150/1738 done for leaf_blast\n",
      "➡️ 1160/1738 done for leaf_blast\n",
      "➡️ 1170/1738 done for leaf_blast\n",
      "➡️ 1180/1738 done for leaf_blast\n",
      "➡️ 1190/1738 done for leaf_blast\n",
      "➡️ 1200/1738 done for leaf_blast\n",
      "➡️ 1210/1738 done for leaf_blast\n",
      "➡️ 1220/1738 done for leaf_blast\n",
      "➡️ 1230/1738 done for leaf_blast\n",
      "➡️ 1240/1738 done for leaf_blast\n",
      "➡️ 1250/1738 done for leaf_blast\n",
      "➡️ 1260/1738 done for leaf_blast\n",
      "➡️ 1270/1738 done for leaf_blast\n",
      "➡️ 1280/1738 done for leaf_blast\n",
      "➡️ 1290/1738 done for leaf_blast\n",
      "➡️ 1300/1738 done for leaf_blast\n",
      "➡️ 1310/1738 done for leaf_blast\n",
      "➡️ 1320/1738 done for leaf_blast\n",
      "➡️ 1330/1738 done for leaf_blast\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📄 Summary file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 104\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mMAX_WORKERS) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    103\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [ex\u001b[38;5;241m.\u001b[39msubmit(process_one, \u001b[38;5;28mstr\u001b[39m(img), out_dir) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs]\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(as_completed(futures), \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m             res \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    248\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ===== CONFIG =====\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   # ✅ chỉ dùng GPU thứ 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"🚀 Using:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DATA_ROOT   = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice\"\n",
    "CKPT_PATH   = \"/home/bbsw/thong/deep_learning/tk1/data/runs_rice_leaf/yolov8n_leaf_disease_v2/weights/epoch40.pt\"\n",
    "OUTPUT_ROOT = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast\"\n",
    "CONF_THRESH = 0.4\n",
    "IOU_THRESH  = 0.5\n",
    "MAX_WORKERS = 4  # số luồng song song\n",
    "\n",
    "# ===== LOAD YOLO MODEL 1 LẦN DUY NHẤT =====\n",
    "print(\"📦 Loading YOLOv8 model...\")\n",
    "model = YOLO(CKPT_PATH)\n",
    "model.to(device)\n",
    "print(\"✅ Model loaded on\", device)\n",
    "\n",
    "# ===== UTILS =====\n",
    "def draw_boxes(image, boxes, names, color=(0,255,0)):\n",
    "    \"\"\"Vẽ bounding boxes lên ảnh\"\"\"\n",
    "    img = image.copy()\n",
    "    for *xyxy, conf, cls in boxes:\n",
    "        label = names[int(cls)]\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(img, f\"{label} {conf:.2f}\", (x1, y1 - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    return img\n",
    "\n",
    "def save_crop(image, box, out_dir, stem, label):\n",
    "    \"\"\"Cắt và lưu vùng phát hiện\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, box[:4])\n",
    "    crop = image[y1:y2, x1:x2]\n",
    "    crop_path = Path(out_dir) / f\"{stem}_{label}.png\"\n",
    "    cv2.imwrite(str(crop_path), crop)\n",
    "    return str(crop_path)\n",
    "\n",
    "# ===== WORKER =====\n",
    "def process_one(img_path: str, out_dir: Path):\n",
    "    img = cv2.imread(img_path)\n",
    "    stem = Path(img_path).stem\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    results = model.predict(\n",
    "        source=img,\n",
    "        conf=CONF_THRESH,\n",
    "        iou=IOU_THRESH,\n",
    "        imgsz=640,\n",
    "        device=device.index if device.type == \"cuda\" else \"cpu\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    res = results[0]\n",
    "    boxes = res.boxes.data.cpu().numpy() if len(res.boxes) else []\n",
    "    names = model.names\n",
    "    overlay = draw_boxes(img, boxes, names)\n",
    "\n",
    "    overlay_path = out_dir / f\"{stem}_overlay.jpg\"\n",
    "    cv2.imwrite(str(overlay_path), overlay)\n",
    "\n",
    "    crops = []\n",
    "    for box in boxes:\n",
    "        label = names[int(box[5])]\n",
    "        crop_path = save_crop(img, box, out_dir, stem, label)\n",
    "        crops.append({\"label\": label, \"path\": crop_path})\n",
    "\n",
    "    return {\n",
    "        \"image\": img_path,\n",
    "        \"detections\": len(boxes),\n",
    "        \"overlay\": str(overlay_path),\n",
    "        \"crops\": crops\n",
    "    }\n",
    "\n",
    "# ===== MAIN =====\n",
    "def main():\n",
    "    Path(OUTPUT_ROOT).mkdir(parents=True, exist_ok=True)\n",
    "    disease_dirs = [p for p in Path(DATA_ROOT).iterdir() if p.is_dir()]\n",
    "    print(f\"🧩 Found {len(disease_dirs)} classes:\", [d.name for d in disease_dirs])\n",
    "\n",
    "    all_results = []\n",
    "    for disease_dir in disease_dirs:\n",
    "        out_dir = Path(OUTPUT_ROOT) / disease_dir.name\n",
    "        imgs = [*disease_dir.glob(\"*.jpg\"), *disease_dir.glob(\"*.png\")]\n",
    "        if not imgs:\n",
    "            print(f\"⚠️ No images in {disease_dir.name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"🔍 {disease_dir.name}: {len(imgs)} images\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "            futures = [ex.submit(process_one, str(img), out_dir) for img in imgs]\n",
    "            for i, f in enumerate(as_completed(futures), 1):\n",
    "                try:\n",
    "                    res = f.result()\n",
    "                    all_results.append(res)\n",
    "                    if i % 10 == 0:\n",
    "                        print(f\"➡️ {i}/{len(imgs)} done for {disease_dir.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error: {e}\")\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    summary_path = Path(OUTPUT_ROOT) / \"summary.json\"\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n✅ Done! Results at {OUTPUT_ROOT}\")\n",
    "    print(f\"📄 Summary file: {summary_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fd2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using CUDA: NVIDIA GeForce RTX 4090\n",
      "📦 Loading YOLOv8 model...\n",
      "✅ Model loaded on device=0\n",
      "🧩 Found 4 classes: ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']\n",
      "🔍 brown_spot: 965 images\n",
      "➡️ 10/965 done for brown_spot\n",
      "➡️ 20/965 done for brown_spot\n",
      "➡️ 30/965 done for brown_spot\n",
      "➡️ 40/965 done for brown_spot\n",
      "➡️ 50/965 done for brown_spot\n",
      "➡️ 60/965 done for brown_spot\n",
      "➡️ 70/965 done for brown_spot\n",
      "➡️ 80/965 done for brown_spot\n",
      "➡️ 90/965 done for brown_spot\n",
      "➡️ 100/965 done for brown_spot\n",
      "➡️ 110/965 done for brown_spot\n",
      "➡️ 120/965 done for brown_spot\n",
      "➡️ 130/965 done for brown_spot\n",
      "➡️ 140/965 done for brown_spot\n",
      "➡️ 150/965 done for brown_spot\n",
      "➡️ 160/965 done for brown_spot\n",
      "➡️ 170/965 done for brown_spot\n",
      "➡️ 180/965 done for brown_spot\n",
      "➡️ 190/965 done for brown_spot\n",
      "➡️ 200/965 done for brown_spot\n",
      "➡️ 210/965 done for brown_spot\n",
      "➡️ 220/965 done for brown_spot\n",
      "➡️ 230/965 done for brown_spot\n",
      "➡️ 240/965 done for brown_spot\n",
      "➡️ 250/965 done for brown_spot\n",
      "➡️ 260/965 done for brown_spot\n",
      "➡️ 270/965 done for brown_spot\n",
      "➡️ 280/965 done for brown_spot\n",
      "➡️ 290/965 done for brown_spot\n",
      "➡️ 300/965 done for brown_spot\n",
      "➡️ 310/965 done for brown_spot\n",
      "➡️ 320/965 done for brown_spot\n",
      "➡️ 330/965 done for brown_spot\n",
      "➡️ 340/965 done for brown_spot\n",
      "➡️ 350/965 done for brown_spot\n",
      "➡️ 360/965 done for brown_spot\n",
      "➡️ 370/965 done for brown_spot\n",
      "➡️ 380/965 done for brown_spot\n",
      "➡️ 390/965 done for brown_spot\n",
      "➡️ 400/965 done for brown_spot\n",
      "➡️ 410/965 done for brown_spot\n",
      "➡️ 420/965 done for brown_spot\n",
      "➡️ 430/965 done for brown_spot\n",
      "➡️ 440/965 done for brown_spot\n",
      "➡️ 450/965 done for brown_spot\n",
      "➡️ 460/965 done for brown_spot\n",
      "➡️ 470/965 done for brown_spot\n",
      "➡️ 480/965 done for brown_spot\n",
      "➡️ 490/965 done for brown_spot\n",
      "➡️ 500/965 done for brown_spot\n",
      "➡️ 510/965 done for brown_spot\n",
      "➡️ 520/965 done for brown_spot\n",
      "➡️ 530/965 done for brown_spot\n",
      "➡️ 540/965 done for brown_spot\n",
      "➡️ 550/965 done for brown_spot\n",
      "➡️ 560/965 done for brown_spot\n",
      "➡️ 570/965 done for brown_spot\n",
      "➡️ 580/965 done for brown_spot\n",
      "➡️ 590/965 done for brown_spot\n",
      "➡️ 600/965 done for brown_spot\n",
      "➡️ 610/965 done for brown_spot\n",
      "➡️ 620/965 done for brown_spot\n",
      "➡️ 630/965 done for brown_spot\n",
      "➡️ 640/965 done for brown_spot\n",
      "➡️ 650/965 done for brown_spot\n",
      "➡️ 660/965 done for brown_spot\n",
      "➡️ 670/965 done for brown_spot\n",
      "➡️ 680/965 done for brown_spot\n",
      "➡️ 690/965 done for brown_spot\n",
      "➡️ 700/965 done for brown_spot\n",
      "➡️ 710/965 done for brown_spot\n",
      "➡️ 720/965 done for brown_spot\n",
      "➡️ 730/965 done for brown_spot\n",
      "➡️ 740/965 done for brown_spot\n",
      "➡️ 750/965 done for brown_spot\n",
      "➡️ 760/965 done for brown_spot\n",
      "➡️ 770/965 done for brown_spot\n",
      "➡️ 780/965 done for brown_spot\n",
      "➡️ 790/965 done for brown_spot\n",
      "➡️ 800/965 done for brown_spot\n",
      "➡️ 810/965 done for brown_spot\n",
      "➡️ 820/965 done for brown_spot\n",
      "➡️ 830/965 done for brown_spot\n",
      "➡️ 840/965 done for brown_spot\n",
      "➡️ 850/965 done for brown_spot\n",
      "➡️ 860/965 done for brown_spot\n",
      "➡️ 870/965 done for brown_spot\n",
      "➡️ 880/965 done for brown_spot\n",
      "➡️ 890/965 done for brown_spot\n",
      "➡️ 900/965 done for brown_spot\n",
      "➡️ 910/965 done for brown_spot\n",
      "➡️ 920/965 done for brown_spot\n",
      "➡️ 930/965 done for brown_spot\n",
      "➡️ 940/965 done for brown_spot\n",
      "➡️ 950/965 done for brown_spot\n",
      "➡️ 960/965 done for brown_spot\n",
      "🔍 leaf_blast: 1738 images\n",
      "➡️ 10/1738 done for leaf_blast\n",
      "➡️ 20/1738 done for leaf_blast\n",
      "➡️ 30/1738 done for leaf_blast\n",
      "➡️ 40/1738 done for leaf_blast\n",
      "➡️ 50/1738 done for leaf_blast\n",
      "➡️ 60/1738 done for leaf_blast\n",
      "➡️ 70/1738 done for leaf_blast\n",
      "➡️ 80/1738 done for leaf_blast\n",
      "➡️ 90/1738 done for leaf_blast\n",
      "➡️ 100/1738 done for leaf_blast\n",
      "➡️ 110/1738 done for leaf_blast\n",
      "➡️ 120/1738 done for leaf_blast\n",
      "➡️ 130/1738 done for leaf_blast\n",
      "➡️ 140/1738 done for leaf_blast\n",
      "➡️ 150/1738 done for leaf_blast\n",
      "➡️ 160/1738 done for leaf_blast\n",
      "➡️ 170/1738 done for leaf_blast\n",
      "➡️ 180/1738 done for leaf_blast\n",
      "➡️ 190/1738 done for leaf_blast\n",
      "➡️ 200/1738 done for leaf_blast\n",
      "➡️ 210/1738 done for leaf_blast\n",
      "➡️ 220/1738 done for leaf_blast\n",
      "➡️ 230/1738 done for leaf_blast\n",
      "➡️ 240/1738 done for leaf_blast\n",
      "➡️ 250/1738 done for leaf_blast\n",
      "➡️ 260/1738 done for leaf_blast\n",
      "➡️ 270/1738 done for leaf_blast\n",
      "➡️ 280/1738 done for leaf_blast\n",
      "➡️ 290/1738 done for leaf_blast\n",
      "➡️ 300/1738 done for leaf_blast\n",
      "➡️ 310/1738 done for leaf_blast\n",
      "➡️ 320/1738 done for leaf_blast\n",
      "➡️ 330/1738 done for leaf_blast\n",
      "➡️ 340/1738 done for leaf_blast\n",
      "➡️ 350/1738 done for leaf_blast\n",
      "➡️ 360/1738 done for leaf_blast\n",
      "➡️ 370/1738 done for leaf_blast\n",
      "➡️ 380/1738 done for leaf_blast\n",
      "➡️ 390/1738 done for leaf_blast\n",
      "➡️ 400/1738 done for leaf_blast\n",
      "➡️ 410/1738 done for leaf_blast\n",
      "➡️ 420/1738 done for leaf_blast\n",
      "➡️ 430/1738 done for leaf_blast\n",
      "➡️ 440/1738 done for leaf_blast\n",
      "➡️ 450/1738 done for leaf_blast\n",
      "➡️ 460/1738 done for leaf_blast\n",
      "➡️ 470/1738 done for leaf_blast\n",
      "➡️ 480/1738 done for leaf_blast\n",
      "➡️ 490/1738 done for leaf_blast\n",
      "➡️ 500/1738 done for leaf_blast\n",
      "➡️ 510/1738 done for leaf_blast\n",
      "➡️ 520/1738 done for leaf_blast\n",
      "➡️ 530/1738 done for leaf_blast\n",
      "➡️ 540/1738 done for leaf_blast\n",
      "➡️ 550/1738 done for leaf_blast\n",
      "➡️ 560/1738 done for leaf_blast\n",
      "➡️ 570/1738 done for leaf_blast\n",
      "➡️ 580/1738 done for leaf_blast\n",
      "➡️ 590/1738 done for leaf_blast\n",
      "➡️ 600/1738 done for leaf_blast\n",
      "➡️ 610/1738 done for leaf_blast\n",
      "➡️ 620/1738 done for leaf_blast\n",
      "➡️ 630/1738 done for leaf_blast\n",
      "➡️ 640/1738 done for leaf_blast\n",
      "➡️ 650/1738 done for leaf_blast\n",
      "➡️ 660/1738 done for leaf_blast\n",
      "➡️ 670/1738 done for leaf_blast\n",
      "➡️ 680/1738 done for leaf_blast\n",
      "➡️ 690/1738 done for leaf_blast\n",
      "➡️ 700/1738 done for leaf_blast\n",
      "➡️ 710/1738 done for leaf_blast\n",
      "➡️ 720/1738 done for leaf_blast\n",
      "➡️ 730/1738 done for leaf_blast\n",
      "➡️ 740/1738 done for leaf_blast\n",
      "➡️ 750/1738 done for leaf_blast\n",
      "➡️ 760/1738 done for leaf_blast\n",
      "➡️ 770/1738 done for leaf_blast\n",
      "➡️ 780/1738 done for leaf_blast\n",
      "➡️ 790/1738 done for leaf_blast\n",
      "➡️ 800/1738 done for leaf_blast\n",
      "➡️ 810/1738 done for leaf_blast\n",
      "➡️ 820/1738 done for leaf_blast\n",
      "➡️ 830/1738 done for leaf_blast\n",
      "➡️ 840/1738 done for leaf_blast\n",
      "➡️ 850/1738 done for leaf_blast\n",
      "➡️ 860/1738 done for leaf_blast\n",
      "➡️ 870/1738 done for leaf_blast\n",
      "➡️ 880/1738 done for leaf_blast\n",
      "➡️ 890/1738 done for leaf_blast\n",
      "➡️ 900/1738 done for leaf_blast\n",
      "➡️ 910/1738 done for leaf_blast\n",
      "➡️ 920/1738 done for leaf_blast\n",
      "➡️ 930/1738 done for leaf_blast\n",
      "➡️ 940/1738 done for leaf_blast\n",
      "➡️ 950/1738 done for leaf_blast\n",
      "➡️ 960/1738 done for leaf_blast\n",
      "➡️ 970/1738 done for leaf_blast\n",
      "➡️ 980/1738 done for leaf_blast\n",
      "➡️ 990/1738 done for leaf_blast\n",
      "➡️ 1000/1738 done for leaf_blast\n",
      "➡️ 1010/1738 done for leaf_blast\n",
      "➡️ 1020/1738 done for leaf_blast\n",
      "➡️ 1030/1738 done for leaf_blast\n",
      "➡️ 1040/1738 done for leaf_blast\n",
      "➡️ 1050/1738 done for leaf_blast\n",
      "➡️ 1060/1738 done for leaf_blast\n",
      "➡️ 1070/1738 done for leaf_blast\n",
      "➡️ 1080/1738 done for leaf_blast\n",
      "➡️ 1090/1738 done for leaf_blast\n",
      "➡️ 1100/1738 done for leaf_blast\n",
      "➡️ 1110/1738 done for leaf_blast\n",
      "➡️ 1120/1738 done for leaf_blast\n",
      "➡️ 1130/1738 done for leaf_blast\n",
      "➡️ 1140/1738 done for leaf_blast\n",
      "➡️ 1150/1738 done for leaf_blast\n",
      "➡️ 1160/1738 done for leaf_blast\n",
      "➡️ 1170/1738 done for leaf_blast\n",
      "➡️ 1180/1738 done for leaf_blast\n",
      "➡️ 1190/1738 done for leaf_blast\n",
      "➡️ 1200/1738 done for leaf_blast\n",
      "➡️ 1210/1738 done for leaf_blast\n",
      "➡️ 1220/1738 done for leaf_blast\n",
      "➡️ 1230/1738 done for leaf_blast\n",
      "➡️ 1240/1738 done for leaf_blast\n",
      "➡️ 1250/1738 done for leaf_blast\n",
      "➡️ 1260/1738 done for leaf_blast\n",
      "➡️ 1270/1738 done for leaf_blast\n",
      "➡️ 1280/1738 done for leaf_blast\n",
      "➡️ 1290/1738 done for leaf_blast\n",
      "➡️ 1300/1738 done for leaf_blast\n",
      "➡️ 1310/1738 done for leaf_blast\n",
      "➡️ 1320/1738 done for leaf_blast\n",
      "➡️ 1330/1738 done for leaf_blast\n",
      "➡️ 1340/1738 done for leaf_blast\n",
      "➡️ 1350/1738 done for leaf_blast\n",
      "➡️ 1360/1738 done for leaf_blast\n",
      "➡️ 1370/1738 done for leaf_blast\n",
      "➡️ 1380/1738 done for leaf_blast\n",
      "➡️ 1390/1738 done for leaf_blast\n",
      "➡️ 1400/1738 done for leaf_blast\n",
      "➡️ 1410/1738 done for leaf_blast\n",
      "➡️ 1420/1738 done for leaf_blast\n",
      "➡️ 1430/1738 done for leaf_blast\n",
      "➡️ 1440/1738 done for leaf_blast\n",
      "➡️ 1450/1738 done for leaf_blast\n",
      "➡️ 1460/1738 done for leaf_blast\n",
      "➡️ 1470/1738 done for leaf_blast\n",
      "➡️ 1480/1738 done for leaf_blast\n",
      "➡️ 1490/1738 done for leaf_blast\n",
      "➡️ 1500/1738 done for leaf_blast\n",
      "➡️ 1510/1738 done for leaf_blast\n",
      "➡️ 1520/1738 done for leaf_blast\n",
      "➡️ 1530/1738 done for leaf_blast\n",
      "➡️ 1540/1738 done for leaf_blast\n",
      "➡️ 1550/1738 done for leaf_blast\n",
      "➡️ 1560/1738 done for leaf_blast\n",
      "➡️ 1570/1738 done for leaf_blast\n",
      "➡️ 1580/1738 done for leaf_blast\n",
      "➡️ 1590/1738 done for leaf_blast\n",
      "➡️ 1600/1738 done for leaf_blast\n",
      "➡️ 1610/1738 done for leaf_blast\n",
      "➡️ 1620/1738 done for leaf_blast\n",
      "➡️ 1630/1738 done for leaf_blast\n",
      "➡️ 1640/1738 done for leaf_blast\n",
      "➡️ 1650/1738 done for leaf_blast\n",
      "➡️ 1660/1738 done for leaf_blast\n",
      "➡️ 1670/1738 done for leaf_blast\n",
      "➡️ 1680/1738 done for leaf_blast\n",
      "➡️ 1690/1738 done for leaf_blast\n",
      "➡️ 1700/1738 done for leaf_blast\n",
      "➡️ 1710/1738 done for leaf_blast\n",
      "➡️ 1720/1738 done for leaf_blast\n",
      "➡️ 1730/1738 done for leaf_blast\n",
      "🔍 leaf_blight: 479 images\n",
      "➡️ 10/479 done for leaf_blight\n",
      "➡️ 20/479 done for leaf_blight\n",
      "➡️ 30/479 done for leaf_blight\n",
      "➡️ 40/479 done for leaf_blight\n",
      "➡️ 50/479 done for leaf_blight\n",
      "➡️ 60/479 done for leaf_blight\n",
      "➡️ 70/479 done for leaf_blight\n",
      "➡️ 80/479 done for leaf_blight\n",
      "➡️ 90/479 done for leaf_blight\n",
      "➡️ 100/479 done for leaf_blight\n",
      "➡️ 110/479 done for leaf_blight\n",
      "➡️ 120/479 done for leaf_blight\n",
      "➡️ 130/479 done for leaf_blight\n",
      "➡️ 140/479 done for leaf_blight\n",
      "➡️ 150/479 done for leaf_blight\n",
      "➡️ 160/479 done for leaf_blight\n",
      "➡️ 170/479 done for leaf_blight\n",
      "➡️ 180/479 done for leaf_blight\n",
      "➡️ 190/479 done for leaf_blight\n",
      "➡️ 200/479 done for leaf_blight\n",
      "➡️ 210/479 done for leaf_blight\n",
      "➡️ 220/479 done for leaf_blight\n",
      "➡️ 230/479 done for leaf_blight\n",
      "➡️ 240/479 done for leaf_blight\n",
      "➡️ 250/479 done for leaf_blight\n",
      "➡️ 260/479 done for leaf_blight\n",
      "➡️ 270/479 done for leaf_blight\n",
      "➡️ 280/479 done for leaf_blight\n",
      "➡️ 290/479 done for leaf_blight\n",
      "➡️ 300/479 done for leaf_blight\n",
      "➡️ 310/479 done for leaf_blight\n",
      "➡️ 320/479 done for leaf_blight\n",
      "➡️ 330/479 done for leaf_blight\n",
      "➡️ 340/479 done for leaf_blight\n",
      "➡️ 350/479 done for leaf_blight\n",
      "➡️ 360/479 done for leaf_blight\n",
      "➡️ 370/479 done for leaf_blight\n",
      "➡️ 380/479 done for leaf_blight\n",
      "➡️ 390/479 done for leaf_blight\n",
      "➡️ 400/479 done for leaf_blight\n",
      "➡️ 410/479 done for leaf_blight\n",
      "➡️ 420/479 done for leaf_blight\n",
      "➡️ 430/479 done for leaf_blight\n",
      "➡️ 440/479 done for leaf_blight\n",
      "➡️ 450/479 done for leaf_blight\n",
      "➡️ 460/479 done for leaf_blight\n",
      "➡️ 470/479 done for leaf_blight\n",
      "🔍 healthy: 1764 images\n",
      "➡️ 10/1764 done for healthy\n",
      "➡️ 20/1764 done for healthy\n",
      "➡️ 30/1764 done for healthy\n",
      "➡️ 40/1764 done for healthy\n",
      "➡️ 50/1764 done for healthy\n",
      "➡️ 60/1764 done for healthy\n",
      "➡️ 70/1764 done for healthy\n",
      "➡️ 80/1764 done for healthy\n",
      "➡️ 90/1764 done for healthy\n",
      "➡️ 100/1764 done for healthy\n",
      "➡️ 110/1764 done for healthy\n",
      "➡️ 120/1764 done for healthy\n",
      "➡️ 130/1764 done for healthy\n",
      "➡️ 140/1764 done for healthy\n",
      "➡️ 150/1764 done for healthy\n",
      "➡️ 160/1764 done for healthy\n",
      "➡️ 170/1764 done for healthy\n",
      "➡️ 180/1764 done for healthy\n",
      "➡️ 190/1764 done for healthy\n",
      "➡️ 200/1764 done for healthy\n",
      "➡️ 210/1764 done for healthy\n",
      "➡️ 220/1764 done for healthy\n",
      "➡️ 230/1764 done for healthy\n",
      "➡️ 240/1764 done for healthy\n",
      "➡️ 250/1764 done for healthy\n",
      "➡️ 260/1764 done for healthy\n",
      "➡️ 270/1764 done for healthy\n",
      "➡️ 280/1764 done for healthy\n",
      "➡️ 290/1764 done for healthy\n",
      "➡️ 300/1764 done for healthy\n",
      "➡️ 310/1764 done for healthy\n",
      "➡️ 320/1764 done for healthy\n",
      "➡️ 330/1764 done for healthy\n",
      "➡️ 340/1764 done for healthy\n",
      "➡️ 350/1764 done for healthy\n",
      "➡️ 360/1764 done for healthy\n",
      "➡️ 370/1764 done for healthy\n",
      "➡️ 380/1764 done for healthy\n",
      "➡️ 390/1764 done for healthy\n",
      "➡️ 400/1764 done for healthy\n",
      "➡️ 410/1764 done for healthy\n",
      "➡️ 420/1764 done for healthy\n",
      "➡️ 430/1764 done for healthy\n",
      "➡️ 440/1764 done for healthy\n",
      "➡️ 450/1764 done for healthy\n",
      "➡️ 460/1764 done for healthy\n",
      "➡️ 470/1764 done for healthy\n",
      "➡️ 480/1764 done for healthy\n",
      "➡️ 490/1764 done for healthy\n",
      "➡️ 500/1764 done for healthy\n",
      "➡️ 510/1764 done for healthy\n",
      "➡️ 520/1764 done for healthy\n",
      "➡️ 530/1764 done for healthy\n",
      "➡️ 540/1764 done for healthy\n",
      "➡️ 550/1764 done for healthy\n",
      "➡️ 560/1764 done for healthy\n",
      "➡️ 570/1764 done for healthy\n",
      "➡️ 580/1764 done for healthy\n",
      "➡️ 590/1764 done for healthy\n",
      "➡️ 600/1764 done for healthy\n",
      "➡️ 610/1764 done for healthy\n",
      "➡️ 620/1764 done for healthy\n",
      "➡️ 630/1764 done for healthy\n",
      "➡️ 640/1764 done for healthy\n",
      "➡️ 650/1764 done for healthy\n",
      "➡️ 660/1764 done for healthy\n",
      "➡️ 670/1764 done for healthy\n",
      "➡️ 680/1764 done for healthy\n",
      "➡️ 690/1764 done for healthy\n",
      "➡️ 700/1764 done for healthy\n",
      "➡️ 710/1764 done for healthy\n",
      "➡️ 720/1764 done for healthy\n",
      "➡️ 730/1764 done for healthy\n",
      "➡️ 740/1764 done for healthy\n",
      "➡️ 750/1764 done for healthy\n",
      "➡️ 760/1764 done for healthy\n",
      "➡️ 770/1764 done for healthy\n",
      "➡️ 780/1764 done for healthy\n",
      "➡️ 790/1764 done for healthy\n",
      "➡️ 800/1764 done for healthy\n",
      "➡️ 810/1764 done for healthy\n",
      "➡️ 820/1764 done for healthy\n",
      "➡️ 830/1764 done for healthy\n",
      "➡️ 840/1764 done for healthy\n",
      "➡️ 850/1764 done for healthy\n",
      "➡️ 860/1764 done for healthy\n",
      "➡️ 870/1764 done for healthy\n",
      "➡️ 880/1764 done for healthy\n",
      "➡️ 890/1764 done for healthy\n",
      "➡️ 900/1764 done for healthy\n",
      "➡️ 910/1764 done for healthy\n",
      "➡️ 920/1764 done for healthy\n",
      "➡️ 930/1764 done for healthy\n",
      "➡️ 940/1764 done for healthy\n",
      "➡️ 950/1764 done for healthy\n",
      "➡️ 960/1764 done for healthy\n",
      "➡️ 970/1764 done for healthy\n",
      "➡️ 980/1764 done for healthy\n",
      "➡️ 990/1764 done for healthy\n",
      "➡️ 1000/1764 done for healthy\n",
      "➡️ 1010/1764 done for healthy\n",
      "➡️ 1020/1764 done for healthy\n",
      "➡️ 1030/1764 done for healthy\n",
      "➡️ 1040/1764 done for healthy\n",
      "➡️ 1050/1764 done for healthy\n",
      "➡️ 1060/1764 done for healthy\n",
      "➡️ 1070/1764 done for healthy\n",
      "➡️ 1080/1764 done for healthy\n",
      "➡️ 1090/1764 done for healthy\n",
      "➡️ 1100/1764 done for healthy\n",
      "➡️ 1110/1764 done for healthy\n",
      "➡️ 1120/1764 done for healthy\n",
      "➡️ 1130/1764 done for healthy\n",
      "➡️ 1140/1764 done for healthy\n",
      "➡️ 1150/1764 done for healthy\n",
      "➡️ 1160/1764 done for healthy\n",
      "➡️ 1170/1764 done for healthy\n",
      "➡️ 1180/1764 done for healthy\n",
      "➡️ 1190/1764 done for healthy\n",
      "➡️ 1200/1764 done for healthy\n",
      "➡️ 1210/1764 done for healthy\n",
      "➡️ 1220/1764 done for healthy\n",
      "➡️ 1230/1764 done for healthy\n",
      "➡️ 1240/1764 done for healthy\n",
      "➡️ 1250/1764 done for healthy\n",
      "➡️ 1260/1764 done for healthy\n",
      "➡️ 1270/1764 done for healthy\n",
      "➡️ 1280/1764 done for healthy\n",
      "➡️ 1290/1764 done for healthy\n",
      "➡️ 1300/1764 done for healthy\n",
      "➡️ 1310/1764 done for healthy\n",
      "➡️ 1320/1764 done for healthy\n",
      "➡️ 1330/1764 done for healthy\n",
      "➡️ 1340/1764 done for healthy\n",
      "➡️ 1350/1764 done for healthy\n",
      "➡️ 1360/1764 done for healthy\n",
      "➡️ 1370/1764 done for healthy\n",
      "➡️ 1380/1764 done for healthy\n",
      "➡️ 1390/1764 done for healthy\n",
      "➡️ 1400/1764 done for healthy\n",
      "➡️ 1410/1764 done for healthy\n",
      "➡️ 1420/1764 done for healthy\n",
      "➡️ 1430/1764 done for healthy\n",
      "➡️ 1440/1764 done for healthy\n",
      "➡️ 1450/1764 done for healthy\n",
      "➡️ 1460/1764 done for healthy\n",
      "➡️ 1470/1764 done for healthy\n",
      "➡️ 1480/1764 done for healthy\n",
      "➡️ 1490/1764 done for healthy\n",
      "➡️ 1500/1764 done for healthy\n",
      "➡️ 1510/1764 done for healthy\n",
      "➡️ 1520/1764 done for healthy\n",
      "➡️ 1530/1764 done for healthy\n",
      "➡️ 1540/1764 done for healthy\n",
      "➡️ 1550/1764 done for healthy\n",
      "➡️ 1560/1764 done for healthy\n",
      "➡️ 1570/1764 done for healthy\n",
      "➡️ 1580/1764 done for healthy\n",
      "➡️ 1590/1764 done for healthy\n",
      "➡️ 1600/1764 done for healthy\n",
      "➡️ 1610/1764 done for healthy\n",
      "➡️ 1620/1764 done for healthy\n",
      "➡️ 1630/1764 done for healthy\n",
      "➡️ 1640/1764 done for healthy\n",
      "➡️ 1650/1764 done for healthy\n",
      "➡️ 1660/1764 done for healthy\n",
      "➡️ 1670/1764 done for healthy\n",
      "➡️ 1680/1764 done for healthy\n",
      "➡️ 1690/1764 done for healthy\n",
      "➡️ 1700/1764 done for healthy\n",
      "➡️ 1710/1764 done for healthy\n",
      "➡️ 1720/1764 done for healthy\n",
      "➡️ 1730/1764 done for healthy\n",
      "➡️ 1740/1764 done for healthy\n",
      "➡️ 1750/1764 done for healthy\n",
      "➡️ 1760/1764 done for healthy\n",
      "\n",
      "✅ Done! Results at /home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast\n",
      "📄 Summary file: /home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast/summary.json\n",
      "⚠️ Error log: /home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast/errors.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from typing import List\n",
    "\n",
    "# ============ CONFIG ============\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"      # chỉ expose GPU index=1 ra môi trường\n",
    "\n",
    "DATA_ROOT    = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice\"\n",
    "CKPT_PATH    = \"/home/bbsw/thong/deep_learning/tk1/data/runs_rice_leaf/yolov8n_leaf_disease_v2/weights/best.pt\"\n",
    "OUTPUT_ROOT  = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast\"\n",
    "CONF_THRESH  = 0.4\n",
    "IOU_THRESH   = 0.5\n",
    "IMG_SIZE     = 640\n",
    "BATCH_SIZE   = 16            # tăng/giảm tùy VRAM\n",
    "MAX_DET      = 300\n",
    "OVERLAY_EVERY = 1            # =1 lưu overlay mọi ảnh; tăng lên nếu muốn giảm I/O\n",
    "ERROR_LOG    = \"errors.jsonl\"\n",
    "\n",
    "# ============ DEVICE ============\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    # Chú ý: sau khi set CUDA_VISIBLE_DEVICES=\"1\", GPU hiển thị sẽ là index 0 đối với tiến trình này\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"🚀 Using CUDA: {gpu_name}\")\n",
    "    yolo_device = 0\n",
    "else:\n",
    "    print(\"🚀 Using CPU\")\n",
    "    yolo_device = \"cpu\"\n",
    "\n",
    "# ============ HELPERS ============\n",
    "VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def is_image_file(p: Path) -> bool:\n",
    "    return p.suffix.lower() in VALID_EXTS\n",
    "\n",
    "def sanitize_filename(text: str) -> str:\n",
    "    # loại bỏ ký tự có thể gây lỗi filesystem\n",
    "    bad = ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', '\\n', '\\r', '\\t']\n",
    "    for b in bad:\n",
    "        text = text.replace(b, '_')\n",
    "    return text.strip() or \"unk\"\n",
    "\n",
    "def draw_boxes(image_bgr: np.ndarray, boxes: np.ndarray, names: dict) -> np.ndarray:\n",
    "    img = image_bgr.copy()\n",
    "    for *xyxy, conf, cls in boxes:\n",
    "        label = names.get(int(cls), f\"id{int(cls)}\")\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        x1 = max(0, min(x1, img.shape[1]-1))\n",
    "        x2 = max(0, min(x2, img.shape[1]-1))\n",
    "        y1 = max(0, min(y1, img.shape[0]-1))\n",
    "        y2 = max(0, min(y2, img.shape[0]-1))\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        txt = f\"{label} {float(conf):.2f}\"\n",
    "        cv2.putText(img, txt, (x1, max(0, y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    return img\n",
    "\n",
    "def save_crop(image_bgr: np.ndarray, box: np.ndarray, out_dir: Path, stem: str, label: str) -> str:\n",
    "    x1, y1, x2, y2 = map(int, box[:4])\n",
    "    H, W = image_bgr.shape[:2]\n",
    "    x1 = max(0, min(x1, W-1)); x2 = max(0, min(x2, W-1))\n",
    "    y1 = max(0, min(y1, H-1)); y2 = max(0, min(y2, H-1))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return \"\"\n",
    "    crop = image_bgr[y1:y2, x1:x2]\n",
    "    if crop.size == 0:\n",
    "        return \"\"\n",
    "    stem_s = sanitize_filename(stem)\n",
    "    label_s = sanitize_filename(label)\n",
    "    crop_path = out_dir / f\"{stem_s}_{label_s}.png\"\n",
    "    ok = cv2.imwrite(str(crop_path), crop)\n",
    "    return str(crop_path) if ok else \"\"\n",
    "\n",
    "def chunk_list(items: List[Path], n: int) -> List[List[Path]]:\n",
    "    return [items[i:i+n] for i in range(0, len(items), n)]\n",
    "\n",
    "def write_err(err_path: Path, payload: dict):\n",
    "    with open(err_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# ============ LOAD MODEL ============\n",
    "print(\"📦 Loading YOLOv8 model...\")\n",
    "model = YOLO(CKPT_PATH)\n",
    "model.to(yolo_device)\n",
    "names = model.names\n",
    "print(f\"✅ Model loaded on device={yolo_device}\")\n",
    "\n",
    "# ============ MAIN ============\n",
    "def main():\n",
    "    out_root = Path(OUTPUT_ROOT)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "    err_file = out_root / ERROR_LOG\n",
    "    if err_file.exists():\n",
    "        err_file.unlink()  # clear old\n",
    "\n",
    "    disease_dirs = [p for p in Path(DATA_ROOT).iterdir() if p.is_dir()]\n",
    "    print(f\"🧩 Found {len(disease_dirs)} classes:\", [d.name for d in disease_dirs])\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for disease_dir in disease_dirs:\n",
    "        imgs = [p for p in disease_dir.iterdir() if p.is_file() and is_image_file(p)]\n",
    "        if not imgs:\n",
    "            print(f\"⚠️ No images in {disease_dir.name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"🔍 {disease_dir.name}: {len(imgs)} images\")\n",
    "        out_dir = out_root / disease_dir.name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Predict theo lô để ổn định GPU (không dùng multi-thread)\n",
    "        batches = chunk_list(imgs, BATCH_SIZE)\n",
    "        done = 0\n",
    "        for bi, batch_paths in enumerate(batches, 1):\n",
    "            # Ultralytics hỗ trợ truyền list đường dẫn trực tiếp\n",
    "            try:\n",
    "                results = model.predict(\n",
    "                    source=[str(p) for p in batch_paths],\n",
    "                    conf=CONF_THRESH,\n",
    "                    iou=IOU_THRESH,\n",
    "                    imgsz=IMG_SIZE,\n",
    "                    device=yolo_device,\n",
    "                    max_det=MAX_DET,\n",
    "                    verbose=False,\n",
    "                    batch=BATCH_SIZE\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # Log lỗi lô, sau đó xử từng ảnh để bỏ qua ảnh hỏng\n",
    "                write_err(err_file, {\"stage\": \"batch_predict\", \"class\": disease_dir.name, \"error\": str(e)})\n",
    "                # fallback: xử lý từng ảnh để xác định ảnh lỗi\n",
    "                for p in batch_paths:\n",
    "                    try:\n",
    "                        _ = model.predict(\n",
    "                            source=str(p),\n",
    "                            conf=CONF_THRESH,\n",
    "                            iou=IOU_THRESH,\n",
    "                            imgsz=IMG_SIZE,\n",
    "                            device=yolo_device,\n",
    "                            max_det=MAX_DET,\n",
    "                            verbose=False\n",
    "                        )\n",
    "                    except Exception as e1:\n",
    "                        write_err(err_file, {\"stage\": \"single_predict\", \"class\": disease_dir.name, \"image\": str(p), \"error\": str(e1)})\n",
    "                # tiếp tục batch tiếp theo\n",
    "                continue\n",
    "\n",
    "            # Hậu xử lý từng kết quả trong batch\n",
    "            for p, res in zip(batch_paths, results):\n",
    "                try:\n",
    "                    img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "                    if img is None:\n",
    "                        raise ValueError(\"cv2.imread returned None (unreadable/corrupted file)\")\n",
    "                    stem = p.stem\n",
    "                    det = res.boxes\n",
    "                    boxes = det.data.cpu().numpy() if det is not None and len(det) else np.empty((0, 6), dtype=float)\n",
    "\n",
    "                    # Lưu overlay tùy chính sách\n",
    "                    if OVERLAY_EVERY and (done % OVERLAY_EVERY == 0):\n",
    "                        overlay = draw_boxes(img, boxes, names)\n",
    "                        ov_path = out_dir / f\"{sanitize_filename(stem)}_overlay.jpg\"\n",
    "                        cv2.imwrite(str(ov_path))\n",
    "                        overlay_path = str(ov_path)\n",
    "                    else:\n",
    "                        overlay_path = \"\"\n",
    "\n",
    "                    # Lưu crop theo từng box\n",
    "                    crops = []\n",
    "                    for box in boxes:\n",
    "                        cls_id = int(box[5]) if len(box) >= 6 else 0\n",
    "                        label = names.get(cls_id, f\"id{cls_id}\")\n",
    "                        cpath = save_crop(img, box, out_dir, stem, label)\n",
    "                        if cpath:\n",
    "                            crops.append({\"label\": label, \"path\": cpath})\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"image\": str(p),\n",
    "                        \"class_dir\": disease_dir.name,\n",
    "                        \"detections\": int(len(boxes)),\n",
    "                        \"overlay\": overlay_path,\n",
    "                        \"crops\": crops\n",
    "                    })\n",
    "\n",
    "                except Exception as eimg:\n",
    "                    write_err(err_file, {\"stage\": \"postprocess\", \"class\": disease_dir.name, \"image\": str(p), \"error\": str(eimg)})\n",
    "\n",
    "                done += 1\n",
    "                if done % 10 == 0:\n",
    "                    print(f\"➡️ {done}/{len(imgs)} done for {disease_dir.name}\")\n",
    "\n",
    "            # Thu dọn VRAM sau mỗi batch\n",
    "            del results\n",
    "            torch.cuda.empty_cache() if use_cuda else None\n",
    "            gc.collect()\n",
    "\n",
    "    # Ghi tổng kết\n",
    "    summary_path = Path(OUTPUT_ROOT) / \"summary.json\"\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n✅ Done! Results at {OUTPUT_ROOT}\")\n",
    "    print(f\"📄 Summary file: {summary_path}\")\n",
    "    if (Path(OUTPUT_ROOT)/ERROR_LOG).exists():\n",
    "        print(f\"⚠️ Error log: {Path(OUTPUT_ROOT)/ERROR_LOG}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4565a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using CUDA: NVIDIA GeForce RTX 4090\n",
      "📦 Loading YOLOv8 model...\n",
      "✅ Model loaded on device=0\n",
      "🧩 Found 4 classes: ['brown_spot', 'leaf_blast', 'leaf_blight', 'healthy']\n",
      "🔍 brown_spot: 965 images\n",
      "➡️ 10/965 done for brown_spot\n",
      "➡️ 20/965 done for brown_spot\n",
      "➡️ 30/965 done for brown_spot\n",
      "➡️ 40/965 done for brown_spot\n",
      "➡️ 50/965 done for brown_spot\n",
      "➡️ 60/965 done for brown_spot\n",
      "➡️ 70/965 done for brown_spot\n",
      "➡️ 80/965 done for brown_spot\n",
      "➡️ 90/965 done for brown_spot\n",
      "➡️ 100/965 done for brown_spot\n",
      "➡️ 110/965 done for brown_spot\n",
      "➡️ 120/965 done for brown_spot\n",
      "➡️ 130/965 done for brown_spot\n",
      "➡️ 140/965 done for brown_spot\n",
      "➡️ 150/965 done for brown_spot\n",
      "➡️ 160/965 done for brown_spot\n",
      "➡️ 170/965 done for brown_spot\n",
      "➡️ 180/965 done for brown_spot\n",
      "➡️ 190/965 done for brown_spot\n",
      "➡️ 200/965 done for brown_spot\n",
      "➡️ 210/965 done for brown_spot\n",
      "➡️ 220/965 done for brown_spot\n",
      "➡️ 230/965 done for brown_spot\n",
      "➡️ 240/965 done for brown_spot\n",
      "➡️ 250/965 done for brown_spot\n",
      "➡️ 260/965 done for brown_spot\n",
      "➡️ 270/965 done for brown_spot\n",
      "➡️ 280/965 done for brown_spot\n",
      "➡️ 290/965 done for brown_spot\n",
      "➡️ 300/965 done for brown_spot\n",
      "➡️ 310/965 done for brown_spot\n",
      "➡️ 320/965 done for brown_spot\n",
      "➡️ 330/965 done for brown_spot\n",
      "➡️ 340/965 done for brown_spot\n",
      "➡️ 350/965 done for brown_spot\n",
      "➡️ 360/965 done for brown_spot\n",
      "➡️ 370/965 done for brown_spot\n",
      "➡️ 380/965 done for brown_spot\n",
      "➡️ 390/965 done for brown_spot\n",
      "➡️ 400/965 done for brown_spot\n",
      "➡️ 410/965 done for brown_spot\n",
      "➡️ 420/965 done for brown_spot\n",
      "➡️ 430/965 done for brown_spot\n",
      "➡️ 440/965 done for brown_spot\n",
      "➡️ 450/965 done for brown_spot\n",
      "➡️ 460/965 done for brown_spot\n",
      "➡️ 470/965 done for brown_spot\n",
      "➡️ 480/965 done for brown_spot\n",
      "➡️ 490/965 done for brown_spot\n",
      "➡️ 500/965 done for brown_spot\n",
      "➡️ 510/965 done for brown_spot\n",
      "➡️ 520/965 done for brown_spot\n",
      "➡️ 530/965 done for brown_spot\n",
      "➡️ 540/965 done for brown_spot\n",
      "➡️ 550/965 done for brown_spot\n",
      "➡️ 560/965 done for brown_spot\n",
      "➡️ 570/965 done for brown_spot\n",
      "➡️ 580/965 done for brown_spot\n",
      "➡️ 590/965 done for brown_spot\n",
      "➡️ 600/965 done for brown_spot\n",
      "➡️ 610/965 done for brown_spot\n",
      "➡️ 620/965 done for brown_spot\n",
      "➡️ 630/965 done for brown_spot\n",
      "➡️ 640/965 done for brown_spot\n",
      "➡️ 650/965 done for brown_spot\n",
      "➡️ 660/965 done for brown_spot\n",
      "➡️ 670/965 done for brown_spot\n",
      "➡️ 680/965 done for brown_spot\n",
      "➡️ 690/965 done for brown_spot\n",
      "➡️ 700/965 done for brown_spot\n",
      "➡️ 710/965 done for brown_spot\n",
      "➡️ 720/965 done for brown_spot\n",
      "➡️ 730/965 done for brown_spot\n",
      "➡️ 740/965 done for brown_spot\n",
      "➡️ 750/965 done for brown_spot\n",
      "➡️ 760/965 done for brown_spot\n",
      "➡️ 770/965 done for brown_spot\n",
      "➡️ 780/965 done for brown_spot\n",
      "➡️ 790/965 done for brown_spot\n",
      "➡️ 800/965 done for brown_spot\n",
      "➡️ 810/965 done for brown_spot\n",
      "➡️ 820/965 done for brown_spot\n",
      "➡️ 830/965 done for brown_spot\n",
      "➡️ 840/965 done for brown_spot\n",
      "➡️ 850/965 done for brown_spot\n",
      "➡️ 860/965 done for brown_spot\n",
      "➡️ 870/965 done for brown_spot\n",
      "➡️ 880/965 done for brown_spot\n",
      "➡️ 890/965 done for brown_spot\n",
      "➡️ 900/965 done for brown_spot\n",
      "➡️ 910/965 done for brown_spot\n",
      "➡️ 920/965 done for brown_spot\n",
      "➡️ 930/965 done for brown_spot\n",
      "➡️ 940/965 done for brown_spot\n",
      "➡️ 950/965 done for brown_spot\n",
      "➡️ 960/965 done for brown_spot\n",
      "🔍 leaf_blast: 1738 images\n",
      "➡️ 10/1738 done for leaf_blast\n",
      "➡️ 20/1738 done for leaf_blast\n",
      "➡️ 30/1738 done for leaf_blast\n",
      "➡️ 40/1738 done for leaf_blast\n",
      "➡️ 50/1738 done for leaf_blast\n",
      "➡️ 60/1738 done for leaf_blast\n",
      "➡️ 70/1738 done for leaf_blast\n",
      "➡️ 80/1738 done for leaf_blast\n",
      "➡️ 90/1738 done for leaf_blast\n",
      "➡️ 100/1738 done for leaf_blast\n",
      "➡️ 110/1738 done for leaf_blast\n",
      "➡️ 120/1738 done for leaf_blast\n",
      "➡️ 130/1738 done for leaf_blast\n",
      "➡️ 140/1738 done for leaf_blast\n",
      "➡️ 150/1738 done for leaf_blast\n",
      "➡️ 160/1738 done for leaf_blast\n",
      "➡️ 170/1738 done for leaf_blast\n",
      "➡️ 180/1738 done for leaf_blast\n",
      "➡️ 190/1738 done for leaf_blast\n",
      "➡️ 200/1738 done for leaf_blast\n",
      "➡️ 210/1738 done for leaf_blast\n",
      "➡️ 220/1738 done for leaf_blast\n",
      "➡️ 230/1738 done for leaf_blast\n",
      "➡️ 240/1738 done for leaf_blast\n",
      "➡️ 250/1738 done for leaf_blast\n",
      "➡️ 260/1738 done for leaf_blast\n",
      "➡️ 270/1738 done for leaf_blast\n",
      "➡️ 280/1738 done for leaf_blast\n",
      "➡️ 290/1738 done for leaf_blast\n",
      "➡️ 300/1738 done for leaf_blast\n",
      "➡️ 310/1738 done for leaf_blast\n",
      "➡️ 320/1738 done for leaf_blast\n",
      "➡️ 330/1738 done for leaf_blast\n",
      "➡️ 340/1738 done for leaf_blast\n",
      "➡️ 350/1738 done for leaf_blast\n",
      "➡️ 360/1738 done for leaf_blast\n",
      "➡️ 370/1738 done for leaf_blast\n",
      "➡️ 380/1738 done for leaf_blast\n",
      "➡️ 390/1738 done for leaf_blast\n",
      "➡️ 400/1738 done for leaf_blast\n",
      "➡️ 410/1738 done for leaf_blast\n",
      "➡️ 420/1738 done for leaf_blast\n",
      "➡️ 430/1738 done for leaf_blast\n",
      "➡️ 440/1738 done for leaf_blast\n",
      "➡️ 450/1738 done for leaf_blast\n",
      "➡️ 460/1738 done for leaf_blast\n",
      "➡️ 470/1738 done for leaf_blast\n",
      "➡️ 480/1738 done for leaf_blast\n",
      "➡️ 490/1738 done for leaf_blast\n",
      "➡️ 500/1738 done for leaf_blast\n",
      "➡️ 510/1738 done for leaf_blast\n",
      "➡️ 520/1738 done for leaf_blast\n",
      "➡️ 530/1738 done for leaf_blast\n",
      "➡️ 540/1738 done for leaf_blast\n",
      "➡️ 550/1738 done for leaf_blast\n",
      "➡️ 560/1738 done for leaf_blast\n",
      "➡️ 570/1738 done for leaf_blast\n",
      "➡️ 580/1738 done for leaf_blast\n",
      "➡️ 590/1738 done for leaf_blast\n",
      "➡️ 600/1738 done for leaf_blast\n",
      "➡️ 610/1738 done for leaf_blast\n",
      "➡️ 620/1738 done for leaf_blast\n",
      "➡️ 630/1738 done for leaf_blast\n",
      "➡️ 640/1738 done for leaf_blast\n",
      "➡️ 650/1738 done for leaf_blast\n",
      "➡️ 660/1738 done for leaf_blast\n",
      "➡️ 670/1738 done for leaf_blast\n",
      "➡️ 680/1738 done for leaf_blast\n",
      "➡️ 690/1738 done for leaf_blast\n",
      "➡️ 700/1738 done for leaf_blast\n",
      "➡️ 710/1738 done for leaf_blast\n",
      "➡️ 720/1738 done for leaf_blast\n",
      "➡️ 730/1738 done for leaf_blast\n",
      "➡️ 740/1738 done for leaf_blast\n",
      "➡️ 750/1738 done for leaf_blast\n",
      "➡️ 760/1738 done for leaf_blast\n",
      "➡️ 770/1738 done for leaf_blast\n",
      "➡️ 780/1738 done for leaf_blast\n",
      "➡️ 790/1738 done for leaf_blast\n",
      "➡️ 800/1738 done for leaf_blast\n",
      "➡️ 810/1738 done for leaf_blast\n",
      "➡️ 820/1738 done for leaf_blast\n",
      "➡️ 830/1738 done for leaf_blast\n",
      "➡️ 840/1738 done for leaf_blast\n",
      "➡️ 850/1738 done for leaf_blast\n",
      "➡️ 860/1738 done for leaf_blast\n",
      "➡️ 870/1738 done for leaf_blast\n",
      "➡️ 880/1738 done for leaf_blast\n",
      "➡️ 890/1738 done for leaf_blast\n",
      "➡️ 900/1738 done for leaf_blast\n",
      "➡️ 910/1738 done for leaf_blast\n",
      "➡️ 920/1738 done for leaf_blast\n",
      "➡️ 930/1738 done for leaf_blast\n",
      "➡️ 940/1738 done for leaf_blast\n",
      "➡️ 950/1738 done for leaf_blast\n",
      "➡️ 960/1738 done for leaf_blast\n",
      "➡️ 970/1738 done for leaf_blast\n",
      "➡️ 980/1738 done for leaf_blast\n",
      "➡️ 990/1738 done for leaf_blast\n",
      "➡️ 1000/1738 done for leaf_blast\n",
      "➡️ 1010/1738 done for leaf_blast\n",
      "➡️ 1020/1738 done for leaf_blast\n",
      "➡️ 1030/1738 done for leaf_blast\n",
      "➡️ 1040/1738 done for leaf_blast\n",
      "➡️ 1050/1738 done for leaf_blast\n",
      "➡️ 1060/1738 done for leaf_blast\n",
      "➡️ 1070/1738 done for leaf_blast\n",
      "➡️ 1080/1738 done for leaf_blast\n",
      "➡️ 1090/1738 done for leaf_blast\n",
      "➡️ 1100/1738 done for leaf_blast\n",
      "➡️ 1110/1738 done for leaf_blast\n",
      "➡️ 1120/1738 done for leaf_blast\n",
      "➡️ 1130/1738 done for leaf_blast\n",
      "➡️ 1140/1738 done for leaf_blast\n",
      "➡️ 1150/1738 done for leaf_blast\n",
      "➡️ 1160/1738 done for leaf_blast\n",
      "➡️ 1170/1738 done for leaf_blast\n",
      "➡️ 1180/1738 done for leaf_blast\n",
      "➡️ 1190/1738 done for leaf_blast\n",
      "➡️ 1200/1738 done for leaf_blast\n",
      "➡️ 1210/1738 done for leaf_blast\n",
      "➡️ 1220/1738 done for leaf_blast\n",
      "➡️ 1230/1738 done for leaf_blast\n",
      "➡️ 1240/1738 done for leaf_blast\n",
      "➡️ 1250/1738 done for leaf_blast\n",
      "➡️ 1260/1738 done for leaf_blast\n",
      "➡️ 1270/1738 done for leaf_blast\n",
      "➡️ 1280/1738 done for leaf_blast\n",
      "➡️ 1290/1738 done for leaf_blast\n",
      "➡️ 1300/1738 done for leaf_blast\n",
      "➡️ 1310/1738 done for leaf_blast\n",
      "➡️ 1320/1738 done for leaf_blast\n",
      "➡️ 1330/1738 done for leaf_blast\n",
      "➡️ 1340/1738 done for leaf_blast\n",
      "➡️ 1350/1738 done for leaf_blast\n",
      "➡️ 1360/1738 done for leaf_blast\n",
      "➡️ 1370/1738 done for leaf_blast\n",
      "➡️ 1380/1738 done for leaf_blast\n",
      "➡️ 1390/1738 done for leaf_blast\n",
      "➡️ 1400/1738 done for leaf_blast\n",
      "➡️ 1410/1738 done for leaf_blast\n",
      "➡️ 1420/1738 done for leaf_blast\n",
      "➡️ 1430/1738 done for leaf_blast\n",
      "➡️ 1440/1738 done for leaf_blast\n",
      "➡️ 1450/1738 done for leaf_blast\n",
      "➡️ 1460/1738 done for leaf_blast\n",
      "➡️ 1470/1738 done for leaf_blast\n",
      "➡️ 1480/1738 done for leaf_blast\n",
      "➡️ 1490/1738 done for leaf_blast\n",
      "➡️ 1500/1738 done for leaf_blast\n",
      "➡️ 1510/1738 done for leaf_blast\n",
      "➡️ 1520/1738 done for leaf_blast\n",
      "➡️ 1530/1738 done for leaf_blast\n",
      "➡️ 1540/1738 done for leaf_blast\n",
      "➡️ 1550/1738 done for leaf_blast\n",
      "➡️ 1560/1738 done for leaf_blast\n",
      "➡️ 1570/1738 done for leaf_blast\n",
      "➡️ 1580/1738 done for leaf_blast\n",
      "➡️ 1590/1738 done for leaf_blast\n",
      "➡️ 1600/1738 done for leaf_blast\n",
      "➡️ 1610/1738 done for leaf_blast\n",
      "➡️ 1620/1738 done for leaf_blast\n",
      "➡️ 1630/1738 done for leaf_blast\n",
      "➡️ 1640/1738 done for leaf_blast\n",
      "➡️ 1650/1738 done for leaf_blast\n",
      "➡️ 1660/1738 done for leaf_blast\n",
      "➡️ 1670/1738 done for leaf_blast\n",
      "➡️ 1680/1738 done for leaf_blast\n",
      "➡️ 1690/1738 done for leaf_blast\n",
      "➡️ 1700/1738 done for leaf_blast\n",
      "➡️ 1710/1738 done for leaf_blast\n",
      "➡️ 1720/1738 done for leaf_blast\n",
      "➡️ 1730/1738 done for leaf_blast\n",
      "🔍 leaf_blight: 479 images\n",
      "➡️ 10/479 done for leaf_blight\n",
      "➡️ 20/479 done for leaf_blight\n",
      "➡️ 30/479 done for leaf_blight\n",
      "➡️ 40/479 done for leaf_blight\n",
      "➡️ 50/479 done for leaf_blight\n",
      "➡️ 60/479 done for leaf_blight\n",
      "➡️ 70/479 done for leaf_blight\n",
      "➡️ 80/479 done for leaf_blight\n",
      "➡️ 90/479 done for leaf_blight\n",
      "➡️ 100/479 done for leaf_blight\n",
      "➡️ 110/479 done for leaf_blight\n",
      "➡️ 120/479 done for leaf_blight\n",
      "➡️ 130/479 done for leaf_blight\n",
      "➡️ 140/479 done for leaf_blight\n",
      "➡️ 150/479 done for leaf_blight\n",
      "➡️ 160/479 done for leaf_blight\n",
      "➡️ 170/479 done for leaf_blight\n",
      "➡️ 180/479 done for leaf_blight\n",
      "➡️ 190/479 done for leaf_blight\n",
      "➡️ 200/479 done for leaf_blight\n",
      "➡️ 210/479 done for leaf_blight\n",
      "➡️ 220/479 done for leaf_blight\n",
      "➡️ 230/479 done for leaf_blight\n",
      "➡️ 240/479 done for leaf_blight\n",
      "➡️ 250/479 done for leaf_blight\n",
      "➡️ 260/479 done for leaf_blight\n",
      "➡️ 270/479 done for leaf_blight\n",
      "➡️ 280/479 done for leaf_blight\n",
      "➡️ 290/479 done for leaf_blight\n",
      "➡️ 300/479 done for leaf_blight\n",
      "➡️ 310/479 done for leaf_blight\n",
      "➡️ 320/479 done for leaf_blight\n",
      "➡️ 330/479 done for leaf_blight\n",
      "➡️ 340/479 done for leaf_blight\n",
      "➡️ 350/479 done for leaf_blight\n",
      "➡️ 360/479 done for leaf_blight\n",
      "➡️ 370/479 done for leaf_blight\n",
      "➡️ 380/479 done for leaf_blight\n",
      "➡️ 390/479 done for leaf_blight\n",
      "➡️ 400/479 done for leaf_blight\n",
      "➡️ 410/479 done for leaf_blight\n",
      "➡️ 420/479 done for leaf_blight\n",
      "➡️ 430/479 done for leaf_blight\n",
      "➡️ 440/479 done for leaf_blight\n",
      "➡️ 450/479 done for leaf_blight\n",
      "➡️ 460/479 done for leaf_blight\n",
      "➡️ 470/479 done for leaf_blight\n",
      "🔍 healthy: 1764 images\n",
      "➡️ 10/1764 done for healthy\n",
      "➡️ 20/1764 done for healthy\n",
      "➡️ 30/1764 done for healthy\n",
      "➡️ 40/1764 done for healthy\n",
      "➡️ 50/1764 done for healthy\n",
      "➡️ 60/1764 done for healthy\n",
      "➡️ 70/1764 done for healthy\n",
      "➡️ 80/1764 done for healthy\n",
      "➡️ 90/1764 done for healthy\n",
      "➡️ 100/1764 done for healthy\n",
      "➡️ 110/1764 done for healthy\n",
      "➡️ 120/1764 done for healthy\n",
      "➡️ 130/1764 done for healthy\n",
      "➡️ 140/1764 done for healthy\n",
      "➡️ 150/1764 done for healthy\n",
      "➡️ 160/1764 done for healthy\n",
      "➡️ 170/1764 done for healthy\n",
      "➡️ 180/1764 done for healthy\n",
      "➡️ 190/1764 done for healthy\n",
      "➡️ 200/1764 done for healthy\n",
      "➡️ 210/1764 done for healthy\n",
      "➡️ 220/1764 done for healthy\n",
      "➡️ 230/1764 done for healthy\n",
      "➡️ 240/1764 done for healthy\n",
      "➡️ 250/1764 done for healthy\n",
      "➡️ 260/1764 done for healthy\n",
      "➡️ 270/1764 done for healthy\n",
      "➡️ 280/1764 done for healthy\n",
      "➡️ 290/1764 done for healthy\n",
      "➡️ 300/1764 done for healthy\n",
      "➡️ 310/1764 done for healthy\n",
      "➡️ 320/1764 done for healthy\n",
      "➡️ 330/1764 done for healthy\n",
      "➡️ 340/1764 done for healthy\n",
      "➡️ 350/1764 done for healthy\n",
      "➡️ 360/1764 done for healthy\n",
      "➡️ 370/1764 done for healthy\n",
      "➡️ 380/1764 done for healthy\n",
      "➡️ 390/1764 done for healthy\n",
      "➡️ 400/1764 done for healthy\n",
      "➡️ 410/1764 done for healthy\n",
      "➡️ 420/1764 done for healthy\n",
      "➡️ 430/1764 done for healthy\n",
      "➡️ 440/1764 done for healthy\n",
      "➡️ 450/1764 done for healthy\n",
      "➡️ 460/1764 done for healthy\n",
      "➡️ 470/1764 done for healthy\n",
      "➡️ 480/1764 done for healthy\n",
      "➡️ 490/1764 done for healthy\n",
      "➡️ 500/1764 done for healthy\n",
      "➡️ 510/1764 done for healthy\n",
      "➡️ 520/1764 done for healthy\n",
      "➡️ 530/1764 done for healthy\n",
      "➡️ 540/1764 done for healthy\n",
      "➡️ 550/1764 done for healthy\n",
      "➡️ 560/1764 done for healthy\n",
      "➡️ 570/1764 done for healthy\n",
      "➡️ 580/1764 done for healthy\n",
      "➡️ 590/1764 done for healthy\n",
      "➡️ 600/1764 done for healthy\n",
      "➡️ 610/1764 done for healthy\n",
      "➡️ 620/1764 done for healthy\n",
      "➡️ 630/1764 done for healthy\n",
      "➡️ 640/1764 done for healthy\n",
      "➡️ 650/1764 done for healthy\n",
      "➡️ 660/1764 done for healthy\n",
      "➡️ 670/1764 done for healthy\n",
      "➡️ 680/1764 done for healthy\n",
      "➡️ 690/1764 done for healthy\n",
      "➡️ 700/1764 done for healthy\n",
      "➡️ 710/1764 done for healthy\n",
      "➡️ 720/1764 done for healthy\n",
      "➡️ 730/1764 done for healthy\n",
      "➡️ 740/1764 done for healthy\n",
      "➡️ 750/1764 done for healthy\n",
      "➡️ 760/1764 done for healthy\n",
      "➡️ 770/1764 done for healthy\n",
      "➡️ 780/1764 done for healthy\n",
      "➡️ 790/1764 done for healthy\n",
      "➡️ 800/1764 done for healthy\n",
      "➡️ 810/1764 done for healthy\n",
      "➡️ 820/1764 done for healthy\n",
      "➡️ 830/1764 done for healthy\n",
      "➡️ 840/1764 done for healthy\n",
      "➡️ 850/1764 done for healthy\n",
      "➡️ 860/1764 done for healthy\n",
      "➡️ 870/1764 done for healthy\n",
      "➡️ 880/1764 done for healthy\n",
      "➡️ 890/1764 done for healthy\n",
      "➡️ 900/1764 done for healthy\n",
      "➡️ 910/1764 done for healthy\n",
      "➡️ 920/1764 done for healthy\n",
      "➡️ 930/1764 done for healthy\n",
      "➡️ 940/1764 done for healthy\n",
      "➡️ 950/1764 done for healthy\n",
      "➡️ 960/1764 done for healthy\n",
      "➡️ 970/1764 done for healthy\n",
      "➡️ 980/1764 done for healthy\n",
      "➡️ 990/1764 done for healthy\n",
      "➡️ 1000/1764 done for healthy\n",
      "➡️ 1010/1764 done for healthy\n",
      "➡️ 1020/1764 done for healthy\n",
      "➡️ 1030/1764 done for healthy\n",
      "➡️ 1040/1764 done for healthy\n",
      "➡️ 1050/1764 done for healthy\n",
      "➡️ 1060/1764 done for healthy\n",
      "➡️ 1070/1764 done for healthy\n",
      "➡️ 1080/1764 done for healthy\n",
      "➡️ 1090/1764 done for healthy\n",
      "➡️ 1100/1764 done for healthy\n",
      "➡️ 1110/1764 done for healthy\n",
      "➡️ 1120/1764 done for healthy\n",
      "➡️ 1130/1764 done for healthy\n",
      "➡️ 1140/1764 done for healthy\n",
      "➡️ 1150/1764 done for healthy\n",
      "➡️ 1160/1764 done for healthy\n",
      "➡️ 1170/1764 done for healthy\n",
      "➡️ 1180/1764 done for healthy\n",
      "➡️ 1190/1764 done for healthy\n",
      "➡️ 1200/1764 done for healthy\n",
      "➡️ 1210/1764 done for healthy\n",
      "➡️ 1220/1764 done for healthy\n",
      "➡️ 1230/1764 done for healthy\n",
      "➡️ 1240/1764 done for healthy\n",
      "➡️ 1250/1764 done for healthy\n",
      "➡️ 1260/1764 done for healthy\n",
      "➡️ 1270/1764 done for healthy\n",
      "➡️ 1280/1764 done for healthy\n",
      "➡️ 1290/1764 done for healthy\n",
      "➡️ 1300/1764 done for healthy\n",
      "➡️ 1310/1764 done for healthy\n",
      "➡️ 1320/1764 done for healthy\n",
      "➡️ 1330/1764 done for healthy\n",
      "➡️ 1340/1764 done for healthy\n",
      "➡️ 1350/1764 done for healthy\n",
      "➡️ 1360/1764 done for healthy\n",
      "➡️ 1370/1764 done for healthy\n",
      "➡️ 1380/1764 done for healthy\n",
      "➡️ 1390/1764 done for healthy\n",
      "➡️ 1400/1764 done for healthy\n",
      "➡️ 1410/1764 done for healthy\n",
      "➡️ 1420/1764 done for healthy\n",
      "➡️ 1430/1764 done for healthy\n",
      "➡️ 1440/1764 done for healthy\n",
      "➡️ 1450/1764 done for healthy\n",
      "➡️ 1460/1764 done for healthy\n",
      "➡️ 1470/1764 done for healthy\n",
      "➡️ 1480/1764 done for healthy\n",
      "➡️ 1490/1764 done for healthy\n",
      "➡️ 1500/1764 done for healthy\n",
      "➡️ 1510/1764 done for healthy\n",
      "➡️ 1520/1764 done for healthy\n",
      "➡️ 1530/1764 done for healthy\n",
      "➡️ 1540/1764 done for healthy\n",
      "➡️ 1550/1764 done for healthy\n",
      "➡️ 1560/1764 done for healthy\n",
      "➡️ 1570/1764 done for healthy\n",
      "➡️ 1580/1764 done for healthy\n",
      "➡️ 1590/1764 done for healthy\n",
      "➡️ 1600/1764 done for healthy\n",
      "➡️ 1610/1764 done for healthy\n",
      "➡️ 1620/1764 done for healthy\n",
      "➡️ 1630/1764 done for healthy\n",
      "➡️ 1640/1764 done for healthy\n",
      "➡️ 1650/1764 done for healthy\n",
      "➡️ 1660/1764 done for healthy\n",
      "➡️ 1670/1764 done for healthy\n",
      "➡️ 1680/1764 done for healthy\n",
      "➡️ 1690/1764 done for healthy\n",
      "➡️ 1700/1764 done for healthy\n",
      "➡️ 1710/1764 done for healthy\n",
      "➡️ 1720/1764 done for healthy\n",
      "➡️ 1730/1764 done for healthy\n",
      "➡️ 1740/1764 done for healthy\n",
      "➡️ 1750/1764 done for healthy\n",
      "➡️ 1760/1764 done for healthy\n",
      "\n",
      "✅ Done! Results at /home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast\n",
      "📄 Summary file: /home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast/summary.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from typing import List\n",
    "\n",
    "# ============ CONFIG ============\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"      # chỉ expose GPU index=1 ra môi trường\n",
    "\n",
    "DATA_ROOT    = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice\"\n",
    "CKPT_PATH    = \"/home/bbsw/thong/deep_learning/tk1/data/runs_rice_leaf/yolov8n_leaf_disease_v2/weights/best.pt\"\n",
    "OUTPUT_ROOT  = \"/home/bbsw/thong/deep_learning/tk1/data/new_data_field_rice_detected/yolo_gpu1_fast\"\n",
    "CONF_THRESH  = 0.4\n",
    "IOU_THRESH   = 0.5\n",
    "IMG_SIZE     = 640\n",
    "BATCH_SIZE   = 16\n",
    "MAX_DET      = 300\n",
    "OVERLAY_EVERY = 1            # =1: lưu overlay mọi ảnh\n",
    "ERROR_LOG    = \"errors.jsonl\"\n",
    "\n",
    "# ============ DEVICE ============\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu_name = torch.cuda.get_device_name(0)  # sau khi set CUDA_VISIBLE_DEVICES=\"1\" → chỉ còn 1 GPU (index 0)\n",
    "    print(f\"🚀 Using CUDA: {gpu_name}\")\n",
    "    yolo_device = 0\n",
    "else:\n",
    "    print(\"🚀 Using CPU\")\n",
    "    yolo_device = \"cpu\"\n",
    "\n",
    "# ============ HELPERS ============\n",
    "VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def is_image_file(p: Path) -> bool:\n",
    "    return p.suffix.lower() in VALID_EXTS\n",
    "\n",
    "def sanitize_text(text: str) -> str:\n",
    "    bad = ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', '\\n', '\\r', '\\t']\n",
    "    for b in bad:\n",
    "        text = text.replace(b, '_')\n",
    "    return text.strip() or \"unk\"\n",
    "\n",
    "def save_image(path: Path, img: np.ndarray, err_file: Path, stage: str) -> bool:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = np.ascontiguousarray(img)\n",
    "    ok = False\n",
    "    try:\n",
    "        ok = cv2.imwrite(str(path), img)\n",
    "    except Exception as e:\n",
    "        with open(err_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"stage\": stage, \"path\": str(path), \"error\": str(e)}, ensure_ascii=False) + \"\\n\")\n",
    "        return False\n",
    "    if not ok:\n",
    "        with open(err_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"stage\": stage, \"path\": str(path), \"error\": \"cv2.imwrite returned False\"}, ensure_ascii=False) + \"\\n\")\n",
    "    return ok\n",
    "\n",
    "def draw_boxes(image_bgr: np.ndarray, boxes: np.ndarray, names: dict) -> np.ndarray:\n",
    "    img = image_bgr.copy()\n",
    "    H, W = img.shape[:2]\n",
    "    for *xyxy, conf, cls in boxes:\n",
    "        label = names.get(int(cls), f\"id{int(cls)}\")\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        x1 = max(0, min(x1, W-1)); x2 = max(0, min(x2, W-1))\n",
    "        y1 = max(0, min(y1, H-1)); y2 = max(0, min(y2, H-1))\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "        txt = f\"{label} {float(conf):.2f}\"\n",
    "        cv2.putText(img, txt, (x1, max(0, y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "    return img\n",
    "\n",
    "def save_crop(image_bgr: np.ndarray, box: np.ndarray, out_dir: Path,\n",
    "              stem: str, label: str, idx: int, conf: float, err_file: Path) -> str:\n",
    "    H, W = image_bgr.shape[:2]\n",
    "    x1, y1, x2, y2 = map(int, box[:4])\n",
    "    x1 = max(0, min(x1, W-1)); x2 = max(0, min(x2, W-1))\n",
    "    y1 = max(0, min(y1, H-1)); y2 = max(0, min(y2, H-1))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return \"\"\n",
    "    crop = image_bgr[y1:y2, x1:x2]\n",
    "    if crop.size == 0:\n",
    "        return \"\"\n",
    "    stem_s  = sanitize_text(stem)\n",
    "    label_s = sanitize_text(label)\n",
    "    conf_s  = f\"{conf:.2f}\".replace('.', '')\n",
    "    # thêm idx + conf để tránh ghi đè\n",
    "    crop_path = out_dir / f\"{stem_s}_{label_s}_{idx:02d}_{conf_s}.png\"\n",
    "    ok = save_image(crop_path, crop, err_file, stage=\"save_crop\")\n",
    "    return str(crop_path) if ok else \"\"\n",
    "\n",
    "def chunk_list(items: List[Path], n: int) -> List[List[Path]]:\n",
    "    return [items[i:i+n] for i in range(0, len(items), n)]\n",
    "\n",
    "def write_err(err_path: Path, payload: dict):\n",
    "    with open(err_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# ============ LOAD MODEL ============\n",
    "print(\"📦 Loading YOLOv8 model...\")\n",
    "model = YOLO(CKPT_PATH)\n",
    "model.to(yolo_device)\n",
    "names = model.names\n",
    "print(f\"✅ Model loaded on device={yolo_device}\")\n",
    "\n",
    "# ============ MAIN ============\n",
    "def main():\n",
    "    out_root = Path(OUTPUT_ROOT)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "    err_file = out_root / ERROR_LOG\n",
    "    if err_file.exists():\n",
    "        err_file.unlink()  # clear old\n",
    "\n",
    "    disease_dirs = [p for p in Path(DATA_ROOT).iterdir() if p.is_dir()]\n",
    "    print(f\"🧩 Found {len(disease_dirs)} classes:\", [d.name for d in disease_dirs])\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for disease_dir in disease_dirs:\n",
    "        imgs = [p for p in disease_dir.iterdir() if p.is_file() and is_image_file(p)]\n",
    "        if not imgs:\n",
    "            print(f\"⚠️ No images in {disease_dir.name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"🔍 {disease_dir.name}: {len(imgs)} images\")\n",
    "        out_dir = out_root / disease_dir.name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        batches = chunk_list(imgs, BATCH_SIZE)\n",
    "        done = 0\n",
    "        for bi, batch_paths in enumerate(batches, 1):\n",
    "            try:\n",
    "                results = model.predict(\n",
    "                    source=[str(p) for p in batch_paths],\n",
    "                    conf=CONF_THRESH,\n",
    "                    iou=IOU_THRESH,\n",
    "                    imgsz=IMG_SIZE,\n",
    "                    device=yolo_device,\n",
    "                    max_det=MAX_DET,\n",
    "                    verbose=False,\n",
    "                    batch=BATCH_SIZE\n",
    "                )\n",
    "            except Exception as e:\n",
    "                write_err(err_file, {\"stage\": \"batch_predict\", \"class\": disease_dir.name, \"error\": str(e)})\n",
    "                # fallback từng ảnh để ghi log file lỗi cụ thể\n",
    "                for p in batch_paths:\n",
    "                    try:\n",
    "                        _ = model.predict(\n",
    "                            source=str(p),\n",
    "                            conf=CONF_THRESH,\n",
    "                            iou=IOU_THRESH,\n",
    "                            imgsz=IMG_SIZE,\n",
    "                            device=yolo_device,\n",
    "                            max_det=MAX_DET,\n",
    "                            verbose=False\n",
    "                        )\n",
    "                    except Exception as e1:\n",
    "                        write_err(err_file, {\"stage\": \"single_predict\", \"class\": disease_dir.name, \"image\": str(p), \"error\": str(e1)})\n",
    "                continue\n",
    "\n",
    "            # Hậu xử lý từng kết quả trong batch\n",
    "            for p, res in zip(batch_paths, results):\n",
    "                try:\n",
    "                    img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "                    if img is None:\n",
    "                        raise ValueError(\"cv2.imread returned None (unreadable/corrupted file)\")\n",
    "                    stem = p.stem\n",
    "                    det = res.boxes\n",
    "                    boxes = det.data.cpu().numpy() if det is not None and len(det) else np.empty((0, 6), dtype=float)\n",
    "\n",
    "                    # Overlay\n",
    "                    overlay_path = \"\"\n",
    "                    if OVERLAY_EVERY and (done % OVERLAY_EVERY == 0):\n",
    "                        overlay = draw_boxes(img, boxes, names)\n",
    "                        ov_path = out_dir / f\"{sanitize_text(stem)}_overlay.jpg\"\n",
    "                        save_image(ov_path, overlay, err_file, stage=\"save_overlay\")\n",
    "                        overlay_path = str(ov_path)\n",
    "\n",
    "                    # Lưu từng crop\n",
    "                    crops = []\n",
    "                    for idx, box in enumerate(boxes, start=1):\n",
    "                        cls_id = int(box[5]) if len(box) >= 6 else 0\n",
    "                        label = names.get(cls_id, f\"id{cls_id}\")\n",
    "                        conf  = float(box[4]) if len(box) >= 5 else 0.0\n",
    "                        cpath = save_crop(img, box, out_dir, stem, label, idx, conf, err_file)\n",
    "                        if cpath:\n",
    "                            crops.append({\"label\": label, \"conf\": conf, \"path\": cpath})\n",
    "\n",
    "                    all_results.append({\n",
    "                        \"image\": str(p),\n",
    "                        \"class_dir\": disease_dir.name,\n",
    "                        \"detections\": int(len(boxes)),\n",
    "                        \"overlay\": overlay_path,\n",
    "                        \"crops\": crops\n",
    "                    })\n",
    "\n",
    "                except Exception as eimg:\n",
    "                    write_err(err_file, {\"stage\": \"postprocess\", \"class\": disease_dir.name, \"image\": str(p), \"error\": str(eimg)})\n",
    "\n",
    "                done += 1\n",
    "                if done % 10 == 0:\n",
    "                    print(f\"➡️ {done}/{len(imgs)} done for {disease_dir.name}\")\n",
    "\n",
    "            # Thu dọn VRAM sau mỗi batch\n",
    "            del results\n",
    "            if use_cuda:\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    # Ghi tổng kết\n",
    "    summary_path = Path(OUTPUT_ROOT) / \"summary.json\"\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n✅ Done! Results at {OUTPUT_ROOT}\")\n",
    "    print(f\"📄 Summary file: {summary_path}\")\n",
    "    if (Path(OUTPUT_ROOT)/ERROR_LOG).exists():\n",
    "        print(f\"⚠️ Error log: {Path(OUTPUT_ROOT)/ERROR_LOG}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d19ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (truong .venv)",
   "language": "python",
   "name": "truong-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
